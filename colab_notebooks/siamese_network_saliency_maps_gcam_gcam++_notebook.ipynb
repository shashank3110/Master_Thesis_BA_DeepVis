{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "siamese_network_saliency_maps_gcam_gcam++_notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1IwE5Y2g7afZDpCVWcfS8FCBV9-oJMyGa",
      "authorship_tag": "ABX9TyO5dDNQ4iTwNPQdH5sVrijo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shashank3110/Master_Thesis_BA_DeepVis/blob/master/colab_notebooks/siamese_network_saliency_maps_gcam_gcam%2B%2B_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuM4VvCQ1UD3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "50ae5092-9ebc-4148-d6c6-025e569050a7"
      },
      "source": [
        "!git clone https://github.com/LLNL/fastcam.git\n",
        "\n",
        "!pip install pytorch_gradcam\n",
        "!pip install Cython\n",
        "!pip install torch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'fastcam'...\n",
            "remote: Enumerating objects: 184, done.\u001b[K\n",
            "remote: Counting objects: 100% (184/184), done.\u001b[K\n",
            "remote: Compressing objects: 100% (113/113), done.\u001b[K\n",
            "remote: Total 598 (delta 113), reused 130 (delta 70), pack-reused 414\u001b[K\n",
            "Receiving objects: 100% (598/598), 18.54 MiB | 10.86 MiB/s, done.\n",
            "Resolving deltas: 100% (353/353), done.\n",
            "Collecting pytorch_gradcam\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e6/0a/55251f7cbea464581c6fb831813d38a41fdeb78f3dd8193522248cb98744/pytorch-gradcam-0.2.1.tar.gz (6.0MB)\n",
            "\u001b[K     |████████████████████████████████| 6.0MB 6.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from pytorch_gradcam) (4.1.2.30)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_gradcam) (1.18.5)\n",
            "Building wheels for collected packages: pytorch-gradcam\n",
            "  Building wheel for pytorch-gradcam (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytorch-gradcam: filename=pytorch_gradcam-0.2.1-cp36-none-any.whl size=5270 sha256=f543b8204bc6e8b87a4165ed41c3ef5db04c9e05642607473fdd1d040f3acd80\n",
            "  Stored in directory: /root/.cache/pip/wheels/e8/1e/35/d24150a078a90ce0ad093586814d4665e945466baa89907300\n",
            "Successfully built pytorch-gradcam\n",
            "Installing collected packages: pytorch-gradcam\n",
            "Successfully installed pytorch-gradcam-0.2.1\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (0.29.21)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.6.0+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-M6MRbbNGbhW",
        "colab_type": "text"
      },
      "source": [
        "#**Compute Saliency,Gradcam,Gradcam++ modules**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4O2sCIFpzeH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d3f74d1c-5d38-4db4-af06-107eba70b741"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "%cd fastcam\n",
        "\n",
        "import warnings\n",
        "import os\n",
        "import argparse\n",
        "\n",
        "import tensorflow as tf\n",
        "import math\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.utils.data\n",
        "from torch.utils.data import DataLoader,TensorDataset\n",
        "import logging\n",
        "from keras.layers import Input\n",
        "from keras.layers.merge import concatenate\n",
        "import torch.nn as nn\n",
        "from torch.nn import BatchNorm3d,Conv3d,ReLU,MaxPool3d,Linear,AdaptiveAvgPool3d,Flatten,Softmax\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from datetime import datetime\n",
        "from torch.utils import data\n",
        "import time\n",
        "import skimage.io as sio\n",
        "import os\n",
        "import shutil\n",
        "import pandas as pd\n",
        "from random import shuffle\n",
        "from skimage.transform import resize\n",
        "import skimage.io as sio\n",
        "from scipy.io import savemat,loadmat\n",
        "import cv2\n",
        "\n",
        "import mask\n",
        "import draw\n",
        "import norm\n",
        "import misc\n",
        "\n",
        "from torchvision import models\n",
        "from torchvision.utils import make_grid, save_image\n",
        "from gradcam.utils import visualize_cam\n",
        "from gradcam import GradCAMpp, GradCAM\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "def get_smoe_map(x,relu=False):\n",
        "\n",
        "  '''\n",
        "  Scaled map order equivalent map computation fumction:\n",
        "  reference from the saliency map paper : https://github.com/LLNL/fastcam.git and adapted/modified  to our usecase\n",
        "  '''\n",
        "\n",
        "  print(f' smoe input shape={x.shape}')\n",
        "  if relu:\n",
        "    x=tf.nn.relu(x).numpy()\n",
        "  print(f'x range={np.amax(x),np.amin(x)}')\n",
        "  \n",
        "  m   = np.mean(x,axis=-1)+0.0000001 \n",
        "  # m   = np.mean(x,axis=0)+0.0000001 #avoid log 0\n",
        "  \n",
        "  x   = x + 0.0000001\n",
        "  # k   = np.log2(m) - np.mean(np.log2(x), axis=0)\n",
        "  k   = np.log2(m) - np.mean(np.log2(x), axis=-1)\n",
        "  print(f'log of mean={np.log2(m)}, mean of log={np.mean(np.log2(x), axis=-1)}')\n",
        "  print(f'k={k}')\n",
        "  k   = k + 0.0000001\n",
        "  # k   = np.log10(m) - np.mean(np.log10(x), axis=-1)\n",
        "  print(np.array_equal(np.zeros(k.shape),k))\n",
        "  print(f'{x.shape,k.shape,np.amin(k)}')\n",
        "  print(f'kmax, kmin={np.min(k),np.max(k)}')\n",
        "  print(f'mean={m}')\n",
        "  th  = k * m\n",
        "  print(f'smoe map={th}')\n",
        "  print(f'smoe output shape={th.shape}')\n",
        "  return th\n",
        "\n",
        "def get_std_map(x):\n",
        "  '''\n",
        "  STD based map alternative to SMOE.\n",
        "  '''\n",
        "  print(f'before std map shape ={x.shape}')\n",
        "  m = np.std(x,axis=-1)\n",
        "\n",
        "  print(f'std map shape ={m.shape}')\n",
        "\n",
        "  return m\n",
        "\n",
        "def get_norm(x,const_mean=None,const_std=None):\n",
        "  '''\n",
        "  get norm refrence from the saliency map paper : https://github.com/LLNL/fastcam.git and adapted/modified  to our usecase\n",
        "  '''\n",
        "  s0      = x.shape[0]\n",
        "  s1      = x.shape[1]\n",
        "  s2      = x.shape[2]\n",
        "\n",
        "  # x       = np.reshape(x,(1,s0*s1))\n",
        "  x       = np.reshape(x,(1,s1*s2))\n",
        "  print(f'get norm func x after reshape={x.shape} ')\n",
        "\n",
        "  '''\n",
        "      Compute Mean\n",
        "  '''\n",
        "  if const_mean is None:\n",
        "      m       = np.mean(x,axis=1)\n",
        "      m       = np.reshape(m,(m.shape[0],1))\n",
        "  else:\n",
        "      m       = const_mean\n",
        "\n",
        "  print(f'get norm func x after mean reshape={m.shape} ') \n",
        "  '''\n",
        "      Compute Standard Deviation\n",
        "  '''\n",
        "  if const_std is None:\n",
        "      s       = np.std(x,axis=1)\n",
        "      s       = np.reshape(s,(s.shape[0],1))\n",
        "  else:\n",
        "      s       = const_std\n",
        "  \n",
        "  '''\n",
        "      The normal cumulative distribution function is used to squash the values from within the range of 0 to 1\n",
        "  '''\n",
        "\n",
        "  s=torch.tensor(s)\n",
        "  x       = 0.5*(1.0 + torch.erf((x-m)/(s*torch.sqrt(torch.tensor(2.0)))))\n",
        "  print(x.shape)    \n",
        "  # x       = x.reshape(1,s0,s1)\n",
        "  x       = x.reshape(1,s1,s2)\n",
        "\n",
        "  print(f'map after norm={x,x.shape}')\n",
        "  return x\n",
        "\n",
        "\n",
        "def combine_sal_maps(smaps,output_size,weights,map_num,resize_mode='bilinear',do_relu=False):\n",
        "\n",
        "  '''\n",
        "  Combined saliency maps are computed here .\n",
        "  '''\n",
        "\n",
        "  bn  = smaps[0].shape[0]\n",
        "  cm  = torch.zeros((bn, 1, output_size[0], output_size[1]), dtype=smaps[0].dtype, device=smaps[0].device)\n",
        "  ww  = []\n",
        "  \n",
        "  '''\n",
        "      Now get each saliency map and resize it. Then store it and also create a combined saliency map.\n",
        "  '''\n",
        "  for i in range(len(smaps)):\n",
        "      # assert torch.is_tensor(smaps[i]), \"Each saliency map must be a Torch Tensor.\"\n",
        "      wsz = smaps[i].shape\n",
        "      w   = np.reshape(smaps[i],(wsz[0], 1, wsz[1], wsz[2]))#smaps[i].reshape(wsz[0], 1, wsz[1], wsz[2])\n",
        "   \n",
        "      w   = nn.functional.interpolate(w, size=output_size, mode=resize_mode, align_corners=False) \n",
        "      ww.append(w)        # should we weight the raw maps ... hmmm\n",
        "      \n",
        "      cm  += (w * weights[i])\n",
        "\n",
        "  '''\n",
        "      Finish the combined saliency map to make it a weighted average.\n",
        "  '''\n",
        "  weight_sum =sum(weights)\n",
        "  cm  = cm / weight_sum\n",
        "  cm  = cm.reshape(bn, output_size[0],output_size[1])\n",
        "  \n",
        "  ww  = torch.stack(ww,dim=1)\n",
        "  ww  = ww.reshape(bn, map_num, output_size[0], output_size[1])\n",
        "  \n",
        "\n",
        "  \n",
        "  return cm, ww\n",
        "\n",
        "def compute_saliency_tf(base_path,inputs,tf_model):\n",
        "  '''\n",
        "   Saliency maps are computed for specicied layers and then combined\n",
        "  '''\n",
        "\n",
        "  # gender=inputs[1]\n",
        "  # gender=tf.reshape(gender,[1,1])\n",
        "  img=inputs\n",
        "  img_chunk= img #tf.convert_to_tensor(img)\n",
        "  print(img_chunk.shape)\n",
        "  img_chunk = tf.reshape(img_chunk,[1,121,145,1])\n",
        "  layers=[layer.name for layer in tf_model.layers]\n",
        "  outputs=[]\n",
        "\n",
        " \n",
        "  j=0\n",
        "  for i,l in enumerate(layers):\n",
        "    if 'activation' in l:\n",
        "      val=tf_model.get_layer(name=l).output\n",
        "      print(i,j,l,val.shape)\n",
        "      j+=1\n",
        "      outputs.append(val) \n",
        "  outputs.append(encoder.output) \n",
        "                                        \n",
        "  test_tf_model=tf.keras.models.Model(tf_model.inputs, outputs)\n",
        " \n",
        "  predictions = test_tf_model(img_chunk)\n",
        "\n",
        "  # Specify or experiment  with layers we want to compute saliency maps for.\n",
        "\n",
        "  # hooks=[predictions[0],predictions[1],predictions[2],predictions[8],predictions[14],predictions[20],predictions[23]\\\n",
        "  #        ,predictions[29],predictions[35],predictions[41],predictions[47],predictions[50],\\\n",
        "  #        predictions[56],predictions[62],predictions[65]]#predictions[:layer_end]\n",
        "  # hooks= [predictions[0],predictions[2],predictions[17],predictions[47],predictions[62]] #1x1 and 3x3 cnn\n",
        "\n",
        "  #these layers were picked as the outputs have diffrent scale dimensions,  we can experimentwith other layers as well.\n",
        "  hooks=[predictions[0],predictions[9],predictions[22],predictions[41],predictions[51]] \n",
        "\n",
        "\n",
        "  # choose specific channels / filters\n",
        "  for x in hooks:\n",
        "    print('ouput shapes layerwise')\n",
        "    print(x.shape)\n",
        "\n",
        "\n",
        "  #smoe saliency maps\n",
        "  # sal_maps       = [ get_norm(get_smoe_map(np.mean(x.numpy()[:,:,:,:],axis=-1))) for x in hooks ]\n",
        "  sal_maps       = [ get_norm(get_smoe_map(x.numpy())) for x in hooks ]\n",
        "\n",
        "  #std dev saliency maps\n",
        "  # sal_maps       = [ get_norm(get_std_map(np.mean(x.numpy()[:,:,:,:,:],axis=-2))) for x in hooks ]\n",
        "\n",
        "\n",
        "  for smaps in sal_maps:\n",
        "    print(smaps.shape)\n",
        "  \n",
        "  # all layer scale maps with equal weightage\n",
        "  weights=np.ones(len(hooks))\n",
        " \n",
        "  map_num=len(hooks)\n",
        "\n",
        "  f, axarr = plt.subplots(1,1,figsize=(10,10))\n",
        "  raw= np.mean(img_chunk[0,:,:,:],axis=-1)\n",
        "  raw= raw/np.max(raw)\n",
        "  r=axarr.imshow(raw,cmap='jet')\n",
        "  axarr.set_title('Input image')\n",
        "  cbar=plt.colorbar(r,fraction=0.01, pad=0.04)\n",
        "  cbar.set_clim(0,1)\n",
        "  plt.savefig(base_path+'input_chunk.png')\n",
        "\n",
        "  csal_maps,sal_maps = combine_sal_maps(sal_maps,output_size=[in_height,in_width],weights=weights,map_num=map_num)\n",
        "  output_path = base_path +'Map_Combined.png'\n",
        "  f, axarr = plt.subplots(1,1,figsize=(10,10))\n",
        "  csal_map=csal_maps[0,:,:].numpy()\n",
        "  imcs=csal_map/np.max(csal_map)\n",
        "  im = axarr.imshow(imcs,cmap='jet')\n",
        "  axarr.set_title('Combined saliency map')\n",
        "  cbar=plt.colorbar(im,fraction=0.01, pad=0.04)\n",
        "  cbar.set_clim(0,1)\n",
        "  plt.savefig(output_path)\n",
        "\n",
        "  il = [sal_maps[0,i,:,:] for i in range(map_num)] # Put each saliency map into the figure\n",
        "  il.append(csal_maps[0,:,:])                       # add in the combined map at the end of the figure\n",
        "  images        = [torch.stack(il, 0)]          \n",
        "  images        = make_grid(images, nrow=5)\n",
        "  sal_img=images.unsqueeze(1)\n",
        "  output_path=base_path +'Sal_Maps.png'\n",
        "  save_image(sal_img,output_path)\n",
        "\n",
        "  input_path = output_path\n",
        "  f, axarr = plt.subplots(1,1,figsize=(10,10))\n",
        "  im=sio.imread(input_path)\n",
        "  im=axarr.imshow(np.mean(im,axis=-1)/255, cmap='jet');\n",
        "  axarr.set_title('layerwise saliency maps')\n",
        "  cbar=plt.colorbar(im,fraction=0.01, pad=0.04)\n",
        "  cbar.set_clim(0,1)\n",
        "  output_path=base_path +'Sal_Maps_jet.png'\n",
        "  plt.savefig(output_path)\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "  return csal_maps\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_grads(layer_name,tf_model,inputs):\n",
        "  '''\n",
        "  computes gradients for GCAM/GCAM++\n",
        "  '''\n",
        "\n",
        "  cam_list=[]\n",
        "\n",
        "  img=inputs\n",
        "  grad_model = tf.keras.models.Model([tf_model.inputs], [tf_model.get_layer(name=layer_name).output, tf_model.output])\n",
        "  \n",
        "  img_chunk=img #tf.convert_to_tensor(img)\n",
        "  img_chunk = tf.reshape(img_chunk,[1,121,145,1])\n",
        " \n",
        "  with tf.GradientTape() as tape:\n",
        "      conv_outputs, predictions = grad_model(img_chunk)\n",
        "      print(f'predictions={predictions}')\n",
        "      print(f'conv_outputs shape={conv_outputs.shape},predictions shape={predictions.shape}')\n",
        "      loss=predictions[0]\n",
        "\n",
        "     \n",
        "  output = conv_outputs[0] \n",
        "  print(f'entering tape gradients')\n",
        "\n",
        "  grads = tape.gradient(loss, conv_outputs)[0]\n",
        "  print(type(grads))\n",
        "  print(f'Crossed tape gradients')\n",
        "  gate_f = tf.cast(output > 0, 'float32')\n",
        "  gate_r = tf.cast(grads > 0, 'float32')\n",
        "  # now there are 2 choice either use grads(raw grads) or use guided grads)\n",
        "  guided_grads = tf.cast(output > 0, 'float32') * tf.cast(grads > 0, 'float32') * grads\n",
        "\n",
        "  print(f'Entering reduce mean using guided_grads with shape={guided_grads.shape}')\n",
        "  #guided grads\n",
        "  weights = tf.reduce_mean(guided_grads, axis=(0,1,2))\n",
        "\n",
        "\n",
        "  print(f'Computing CAM using output with shape:{output.shape}')\n",
        "\n",
        "  print(f'weights={weights.shape}')\n",
        "  cam = np.zeros(output.shape[0:3], dtype=np.float32)\n",
        "  print(cam.shape)\n",
        "\n",
        "   \n",
        "  cam=tf.reduce_sum(tf.multiply(output,weights),axis=-1)\n",
        "  cam_list.append(cam)\n",
        "  return cam_list,grads,loss,weights,output,img_chunk\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def compute_gcam_and_gcam_pp(layer_name,model,inputs):\n",
        "  '''\n",
        "  Generates GCAM/GCAM++\n",
        "  '''\n",
        "\n",
        "  cam_list,grads,loss,weights,output,img_chunk = get_grads(layer_name,model,inputs)\n",
        "  \n",
        "  heatmap_list=[]\n",
        "  for i,cam in enumerate(cam_list):#as we are doing chunk wise so this camlist will have only one cam\n",
        "   \n",
        "    print(f'cam shape={cam.shape}')\n",
        "    \n",
        "    #gcam\n",
        "    cam_map=resize(cam,(img_chunk.shape[1],img_chunk.shape[2],img_chunk.shape[3]))\n",
        "\n",
        "    cam_map = np.maximum(cam_map,0)\n",
        "    original_image=img_chunk.numpy()\n",
        "   \n",
        "    heatmap = (cam_map - cam_map.min()) / (cam_map.max() - cam_map.min())\n",
        "\n",
        "  \n",
        "    print(original_image.shape)\n",
        "    image=np.mean(original_image[0,:,:,:],axis=-1)\n",
        "    print(image.shape)\n",
        "\n",
        "    mri_img=image#np.squeeze(image)\n",
        "    heatmap_list.append(heatmap)\n",
        "    # print(heatmap.min(),heatmap.max())\n",
        "\n",
        "    heatmap_gcam = (cam_map - cam_map.min()) / (cam_map.max() - cam_map.min())\n",
        "\n",
        "      \n",
        "    print(f'heatmap_gcam shape={heatmap_gcam.shape}')\n",
        "    gcam_img=(np.mean(heatmap_gcam,axis=-1)* 255).astype(\"uint8\")\n",
        "   \n",
        "    #gcam++\n",
        "    print(f'grads shape ={grads.shape},tf.exp(loss) shape={tf.exp(loss).shape}')\n",
        "    loss = np.mean(loss)\n",
        "    conv_first_grad = tf.exp(loss)*grads\n",
        "    #second_derivative\n",
        "    conv_second_grad = tf.exp(loss)*grads*grads\n",
        "    #triple_derivative\n",
        "    conv_third_grad = tf.exp(loss)*grads*grads*grads\n",
        "    global_sum = np.sum(tf.reshape(output,(-1,conv_first_grad.shape[2])), axis=0)\n",
        "    print(f'conv_first_grad shape={conv_first_grad.shape},output.shape={output.shape},conv_second_grad shape={conv_second_grad.shape} ,  conv_third_grad shape={conv_third_grad.shape}, global_sum.shape={global_sum.shape}  ')\n",
        "\n",
        "    alpha_num = conv_second_grad\n",
        "  \n",
        "    alpha_denom = conv_second_grad*2.0 + conv_third_grad*global_sum.reshape((1,1,conv_first_grad.shape[2]))\n",
        "    alpha_denom = np.where(alpha_denom != 0.0, alpha_denom, np.ones(alpha_denom.shape))\n",
        "    alphas = alpha_num/alpha_denom\n",
        "\n",
        "   \n",
        "\n",
        "    alphas_thresholding = np.where(weights, alphas, 0.0)\n",
        "    print(f'alphas_thresholding shape={alphas_thresholding.shape}')\n",
        "    alpha_normalization_constant = np.sum(np.sum(alphas_thresholding, axis=0),axis=0)\n",
        "    alpha_normalization_constant_processed = np.where(alpha_normalization_constant != 0.0, alpha_normalization_constant, np.ones(alpha_normalization_constant.shape))\n",
        "    \n",
        "    print(f'alpha_normalization_constant_processed shape={alpha_normalization_constant_processed.shape}')\n",
        "    \n",
        "    alphas /= alpha_normalization_constant_processed.reshape((1,1,conv_first_grad.shape[2]))\n",
        "    weights_alpha=tf.reduce_sum(tf.multiply(weights,alphas),axis=0)\n",
        "    \n",
        "    cam=tf.reduce_sum(tf.multiply(output,weights_alpha),axis=-1)\n",
        "    \n",
        "    cam_map=resize(cam,(img_chunk.shape[1],img_chunk.shape[2],img_chunk.shape[3]))\n",
        "  \n",
        "    \n",
        "    print(f'cam_map={cam_map.shape}')\n",
        "    cam_map = np.maximum(cam_map, 0)\n",
        "\n",
        "    heatmap_gcam_pp = (cam_map - cam_map.min()) / (cam_map.max() - cam_map.min())\n",
        "\n",
        "\n",
        "    gcam_pp_img=(np.mean(heatmap_gcam_pp,axis=-1) * 255).astype(\"uint8\")\n",
        "    ##\n",
        "    print(img_chunk.shape,mri_img.shape,gcam_img.shape,type(mri_img),type(gcam_img))\n",
        "    \n",
        "        \n",
        "    return image, gcam_img,gcam_pp_img\n",
        "\n",
        "def combine_sal_gcam(base_path,csmap,gcam_img,gcam_pp_img,image,layer_name ,angle=0,result_path='/content/drive/My Drive/BA_Estimation/final_results/'):\n",
        "  '''\n",
        "  3 kinds of map computed : saliency map , saliency map combined  with GCAM, saliency map combined with GCAM++ \n",
        "  '''\n",
        "  print(gcam_img.shape,csmap.shape,gcam_pp_img.shape,image.shape)\n",
        "  #saliency map\n",
        "\n",
        "  raw_tensor=torch.from_numpy(image).unsqueeze(0)\n",
        "  heatmap_csmap, result_csmap = visualize_cam(csmap, raw_tensor)\n",
        "  getMask                 = mask.SaliencyMaskDropout(keep_percent = 0.1, scale_map=False)\n",
        "  hard_masked_csmap,_       = getMask(raw_tensor.unsqueeze(0),csmap)#.squeeze(0))\n",
        "  hard_masked_csmap        = hard_masked_csmap.squeeze(0)\n",
        "  masked_csmap             = misc.AlphaMask(raw_tensor, csmap.squeeze(0)).squeeze(0)\n",
        "  \n",
        "\n",
        "  vmin=0\n",
        "  vmax=1.0\n",
        "  f, axarr = plt.subplots(2,3,figsize=(20,20))\n",
        "  img_plot = axarr[0][0].imshow(torch.mean(raw_tensor,axis=0),vmin=vmin,vmax=vmax, cmap='jet');\n",
        "  axarr[0][0].set_title('input')\n",
        "  cbar=plt.colorbar(img_plot,fraction=0.046, pad=0.04,ax=axarr[0][0])\n",
        "  cbar.set_clim(0,1)\n",
        "  img_plot = axarr[0][1].imshow(torch.mean(csmap,axis=0),vmin=vmin,vmax=vmax, cmap='jet');\n",
        "  axarr[0][1].set_title('combined saliency map')\n",
        "  cbar=plt.colorbar(img_plot,fraction=0.046, pad=0.04,ax=axarr[0][1])\n",
        "  cbar.set_clim(0,1)\n",
        "  img_plot = axarr[0][2].imshow(torch.mean(heatmap_csmap,axis=0),vmin=vmin,vmax=vmax, cmap='jet');\n",
        "  axarr[0][2].set_title('saliency map + gradcam')\n",
        "  cbar=plt.colorbar(img_plot,fraction=0.046, pad=0.04,ax=axarr[0][2])\n",
        "  cbar.set_clim(0,1)\n",
        "  img_plot = axarr[1][0].imshow(torch.mean(result_csmap,axis=0),vmin=vmin,vmax=vmax, cmap='jet');\n",
        "  axarr[1][0].set_title('saliency map+gradcam with alpha blend')\n",
        "  cbar=plt.colorbar(img_plot,fraction=0.046, pad=0.04,ax=axarr[1][0])\n",
        "  cbar.set_clim(0,1)\n",
        "  img_plot = axarr[1][1].imshow(masked_csmap,vmin=vmin,vmax=vmax, cmap='jet');\n",
        "  axarr[1][1].set_title('mask')\n",
        "  cbar=plt.colorbar(img_plot,fraction=0.046, pad=0.04,ax=axarr[1][1])\n",
        "  cbar.set_clim(0,1)\n",
        "  img_plot = axarr[1][2].imshow(hard_masked_csmap[0],vmin=vmin,vmax=vmax, cmap='jet');\n",
        "  axarr[1][2].set_title('hard mask')\n",
        "  cbar=plt.colorbar(img_plot,fraction=0.046, pad=0.04,ax=axarr[1][2])\n",
        "  cbar.set_clim(0,1)\n",
        "  plt.savefig(base_path+'saliency_only_fig.png')\n",
        "\n",
        "  print(hard_masked_csmap.permute([2,0,1]).shape)\n",
        "  csmap_img = torch.mean(csmap,axis=0).numpy()\n",
        "  output_path   = base_path+\"csmap.png\"\n",
        "  savemat(output_path.split('.png')[0] +'.mat',{'data':csmap_img ,'shape':csmap_img.shape})\n",
        "  output_path   = base_path+\"heatmap_csmap.png\"\n",
        "  savemat(output_path.split('.png')[0] +'.mat',{'data':heatmap_csmap.permute([1,2,0]).numpy() ,'shape':heatmap_csmap.permute([1,2,0]).numpy().shape})\n",
        "  output_path   = base_path+\"result_csmap.png\"\n",
        "  savemat(output_path.split('.png')[0] +'.mat',{'data':result_csmap.permute([1,2,0]).numpy() ,'shape':result_csmap.permute([1,2,0]).numpy().shape})\n",
        "  output_path   = base_path+\"hard_masked_csmap.png\" \n",
        "  savemat(output_path.split('.png')[0] +'.mat',{'data':hard_masked_csmap.permute([1,2,0]).numpy() ,'shape':hard_masked_csmap.permute([1,2,0]).shape})\n",
        "  output_path   = base_path+\"masked_csmap.mat\" \n",
        "  savemat(output_path,{'data':masked_csmap.numpy() ,'shape':masked_csmap.numpy().shape})\n",
        "  masked_csmap_mat = loadmat(output_path)['data']\n",
        "  plt.clf()\n",
        "  p=plt.imshow(masked_csmap_mat,cmap='jet')\n",
        "  plt.colorbar(p)      \n",
        "  plt.clim(0.8,1)\n",
        "  output_path   = base_path+\"masked_csmap_0.8.png\" \n",
        "  plt.savefig(output_path)\n",
        "\n",
        "  #gcam\n",
        "\n",
        "  if np.max(gcam_img) ==0:\n",
        "    gcam_img = gcam_img+0.0000001\n",
        "  if np.max(gcam_pp_img) ==0:\n",
        "    gcam_pp_img = gcam_pp_img+0.0000001\n",
        "  gcam_img_tensor=torch.from_numpy(gcam_img).unsqueeze(0)\n",
        "  mask_gcam = csmap*(gcam_img_tensor)\n",
        "  mask_gcam=mask_gcam/mask_gcam.max()\n",
        "  \n",
        "\n",
        "  \n",
        "\n",
        "  heatmap_gcam, result_gcam = visualize_cam(mask_gcam, raw_tensor)\n",
        "  getMask                 = mask.SaliencyMaskDropout(keep_percent = 0.1, scale_map=False)\n",
        "  hard_masked_gcam,_       = getMask(raw_tensor.unsqueeze(0),mask_gcam)#.squeeze(0))\n",
        "  hard_masked_gcam        = hard_masked_gcam.squeeze(0)\n",
        "  masked_gcam             = misc.AlphaMask(raw_tensor, mask_gcam.squeeze(0)).squeeze(0)\n",
        "  mx= str(np.max(masked_gcam.numpy()))\n",
        "  plt.imsave(base_path+'masked_gcam_unnormalized_{0}max.png'.format(mx),masked_gcam.numpy(),cmap='jet')\n",
        "  # masked_gcam              = misc.RangeNormalize(masked_gcam)\n",
        "\n",
        "\n",
        "  #gcam++\n",
        "  gcam_pp_img_tensor=torch.from_numpy(gcam_pp_img).unsqueeze(0)\n",
        "  mask_gcam_pp = csmap*(gcam_pp_img_tensor)\n",
        "  mask_gcam_pp=mask_gcam_pp/mask_gcam_pp.max()\n",
        "  raw_tensor=torch.from_numpy(image).unsqueeze(0)\n",
        "  heatmap_gcam_pp, result_gcam_pp = visualize_cam(mask_gcam_pp, raw_tensor)\n",
        "\n",
        "  hard_masked_gcam_pp,_       = getMask(raw_tensor.unsqueeze(0),mask_gcam_pp)#.squeeze(0))\n",
        "  hard_masked_gcam_pp         = hard_masked_gcam_pp.squeeze(0)\n",
        "  masked_gcam_pp           = misc.AlphaMask(raw_tensor, mask_gcam_pp.squeeze(0)).squeeze(0)\n",
        "  mx= str(np.max(masked_gcam_pp.numpy()))\n",
        "  plt.imsave(base_path+'masked_gcam_pp_unnormalized_{0}max.png'.format(mx),masked_gcam_pp.numpy(),cmap='jet')\n",
        "  # masked_gcam_pp           = misc.RangeNormalize(masked_gcam_pp) # avoid this step as it will normalize to 0 to 1 hence not good while comparing multiple scans\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "  #\n",
        "  output_path   = base_path+\"raw_img.mat\"\n",
        "  savemat(output_path,{'data':raw_tensor.numpy() ,'shape':raw_tensor.shape})\n",
        "  background_img=loadmat(output_path)['data']\n",
        "\n",
        "  base_path+='_'+layer_name\n",
        "\n",
        "  #save gcam and gcam++ fig\n",
        "  vmin=np.amin([np.min(gcam_img),np.min(gcam_pp_img)])\n",
        "  vmax=np.amax([np.max(gcam_img),np.max(gcam_pp_img)])\n",
        "\n",
        "  f, axarr = plt.subplots(1,2,figsize=(10,10))\n",
        "  img_plot = axarr[0].imshow(gcam_img,vmin=vmin,vmax=vmax, cmap='jet');\n",
        "  axarr[0].set_title('Gradcam')\n",
        "  img_plot = axarr[1].imshow(gcam_pp_img,vmin=vmin,vmax=vmax, cmap='jet');\n",
        "  axarr[1].set_title('Gradcam++')\n",
        "  plt.colorbar(img_plot,fraction=0.046, pad=0.04)\n",
        "  plt.savefig(base_path+'gcam_gcam++_fig.png')\n",
        "  \n",
        "  \n",
        "  #gcam\n",
        "\n",
        "  \n",
        "  vmin=0\n",
        "  vmax=1.0\n",
        "  f, axarr = plt.subplots(2,3,figsize=(20,20))\n",
        "  img_plot = axarr[0][0].imshow(torch.mean(raw_tensor,axis=0),vmin=vmin,vmax=vmax, cmap='jet');\n",
        "  axarr[0][0].set_title('input')\n",
        "  cbar=plt.colorbar(img_plot,fraction=0.046, pad=0.04,ax=axarr[0][0])\n",
        "  cbar.set_clim(0,1)\n",
        "  img_plot = axarr[0][1].imshow(torch.mean(csmap,axis=0),vmin=vmin,vmax=vmax, cmap='jet');\n",
        "  axarr[0][1].set_title('combined saliency map')\n",
        "  cbar=plt.colorbar(img_plot,fraction=0.046, pad=0.04,ax=axarr[0][1])\n",
        "  cbar.set_clim(0,1)\n",
        "  img_plot = axarr[0][2].imshow(torch.mean(heatmap_gcam,axis=0),vmin=vmin,vmax=vmax, cmap='jet');\n",
        "  axarr[0][2].set_title('saliency map + gradcam')\n",
        "  cbar=plt.colorbar(img_plot,fraction=0.046, pad=0.04,ax=axarr[0][2])\n",
        "  cbar.set_clim(0,1)\n",
        "  img_plot = axarr[1][0].imshow(torch.mean(result_gcam,axis=0),vmin=vmin,vmax=vmax, cmap='jet');\n",
        "  axarr[1][0].set_title('saliency map+gradcam with alpha blend')\n",
        "  cbar=plt.colorbar(img_plot,fraction=0.046, pad=0.04,ax=axarr[1][0])\n",
        "  cbar.set_clim(0,1)\n",
        "  img_plot = axarr[1][1].imshow(masked_gcam,vmin=vmin,vmax=vmax, cmap='jet');\n",
        "  axarr[1][1].set_title('mask')\n",
        "  cbar=plt.colorbar(img_plot,fraction=0.046, pad=0.04,ax=axarr[1][1])\n",
        "  cbar.set_clim(0,1)\n",
        "  img_plot = axarr[1][2].imshow(hard_masked_gcam[0],vmin=vmin,vmax=vmax, cmap='jet');\n",
        "  axarr[1][2].set_title('hard mask')\n",
        "  cbar=plt.colorbar(img_plot,fraction=0.046, pad=0.04,ax=axarr[1][2])\n",
        "  cbar.set_clim(0,1)\n",
        "  plt.savefig(base_path+'sal+gcam_fig.png')\n",
        "\n",
        "  print(hard_masked_gcam.permute([2,0,1]).shape)\n",
        "  output_path   = base_path+\"gcam_img.png\"\n",
        "  savemat(output_path.split('.png')[0] +'.mat',{'data':gcam_img ,'shape':gcam_img.shape})\n",
        "  output_path   = base_path+\"heatmap_gcam.png\"\n",
        "  savemat(output_path.split('.png')[0] +'.mat',{'data':heatmap_gcam.permute([1,2,0]).numpy() ,'shape':heatmap_gcam.permute([1,2,0]).numpy().shape})\n",
        "  output_path   = base_path+\"result_gcam.png\"\n",
        "  savemat(output_path.split('.png')[0] +'.mat',{'data':result_gcam.permute([1,2,0]).numpy() ,'shape':result_gcam.permute([1,2,0]).numpy().shape})\n",
        "  output_path   = base_path+\"hard_masked_gcam.png\" \n",
        "  savemat(output_path.split('.png')[0] +'.mat',{'data':hard_masked_gcam.permute([1,2,0]).numpy() ,'shape':hard_masked_gcam.permute([1,2,0]).shape})\n",
        "  output_path   = base_path+\"masked_gcam.mat\" \n",
        "  savemat(output_path,{'data':masked_gcam.numpy() ,'shape':masked_gcam.numpy().shape})\n",
        "  masked_gcam_mat = loadmat(output_path)['data']\n",
        "  plt.clf()\n",
        "  p=plt.imshow(masked_gcam_mat,cmap='jet')\n",
        "  plt.colorbar(p)      \n",
        "  plt.clim(0.8,1)\n",
        "  output_path   = base_path+\"masked_gcam_0.8.png\" \n",
        "  plt.savefig(output_path)\n",
        "  \n",
        "  #gcam_pp\n",
        "  vmin=np.amin([torch.min(raw_tensor),torch.min(csmap),torch.min(heatmap_gcam_pp),torch.min(result_gcam_pp),torch.min(masked_gcam_pp),torch.min(hard_masked_gcam_pp)])\n",
        "  vmax=np.amax([torch.max(raw_tensor),torch.max(csmap),torch.max(heatmap_gcam_pp),torch.max(result_gcam_pp),torch.max(masked_gcam_pp),torch.max(hard_masked_gcam_pp)])\n",
        "\n",
        "  vmin=0\n",
        "  vmax=1.0\n",
        "\n",
        "  f, axarr = plt.subplots(2,3,figsize=(20,20))\n",
        "  img_plot = axarr[0][0].imshow(torch.mean(raw_tensor,axis=0),vmin=vmin,vmax=vmax, cmap='jet');\n",
        "  axarr[0][0].set_title('input')\n",
        "  cbar=plt.colorbar(img_plot,fraction=0.046, pad=0.04,ax=axarr[0][0])\n",
        "  cbar.set_clim(0,1)\n",
        "  img_plot = axarr[0][1].imshow(torch.mean(csmap,axis=0),vmin=vmin,vmax=vmax, cmap='jet');\n",
        "  axarr[0][1].set_title('combined saliency map')\n",
        "  cbar=plt.colorbar(img_plot,fraction=0.046, pad=0.04,ax=axarr[0][1])\n",
        "  cbar.set_clim(0,1)\n",
        "  img_plot = axarr[0][2].imshow(torch.mean(heatmap_gcam_pp,axis=0),vmin=vmin,vmax=vmax, cmap='jet');\n",
        "  axarr[0][2].set_title('saliency map + gradcam++')\n",
        "  cbar=plt.colorbar(img_plot,fraction=0.046, pad=0.04,ax=axarr[0][2])\n",
        "  cbar.set_clim(0,1)\n",
        "  img_plot = axarr[1][0].imshow(torch.mean(result_gcam_pp,axis=0),vmin=vmin,vmax=vmax, cmap='jet');\n",
        "  axarr[1][0].set_title('saliency map+gradcam++ with alpha blend')\n",
        "  cbar=plt.colorbar(img_plot,fraction=0.046, pad=0.04,ax=axarr[1][0])\n",
        "  cbar.set_clim(0,1)\n",
        "  img_plot = axarr[1][1].imshow(masked_gcam_pp,vmin=vmin,vmax=vmax, cmap='jet');\n",
        "  axarr[1][1].set_title('mask')\n",
        "  cbar=plt.colorbar(img_plot,fraction=0.046, pad=0.04,ax=axarr[1][1])\n",
        "  cbar.set_clim(0,1)\n",
        "  img_plot = axarr[1][2].imshow(hard_masked_gcam_pp[0],vmin=vmin,vmax=vmax, cmap='jet');\n",
        "  axarr[1][2].set_title('hard mask')\n",
        "  cbar=plt.colorbar(img_plot,fraction=0.046, pad=0.04,ax=axarr[1][2])\n",
        "  cbar.set_clim(0,1)\n",
        "  plt.savefig(base_path+'sal+gcam++_fig.png')\n",
        "\n",
        "\n",
        "  raw_img = torch.mean(raw_tensor,axis=0).numpy()\n",
        "  output_path   = base_path+\"raw_input.png\"\n",
        "  savemat(output_path.split('.png')[0] +'.mat',{'data':raw_img ,'shape':raw_img.shape})\n",
        "\n",
        "  f, axarr = plt.subplots(1,1,figsize=(10,10))\n",
        "  \n",
        "  r=axarr.imshow(raw_img,cmap='gray')\n",
        "  axarr.set_title('raw gray image')\n",
        "  cbar=plt.colorbar(r,fraction=0.046, pad=0.04)\n",
        "  cbar.set_clim(0,1)\n",
        "  plt.savefig(base_path+'raw_gray_cbar.png')\n",
        "\n",
        "  \n",
        "  output_path   = base_path+\"gcam_pp_img.png\"\n",
        "  savemat(output_path.split('.png')[0] +'.mat',{'data':gcam_pp_img ,'shape':gcam_pp_img.shape})\n",
        "  output_path   = base_path+\"heatmap_gcam_pp.png\"\n",
        "  savemat(output_path.split('.png')[0] +'.mat',{'data':heatmap_gcam_pp.permute([1,2,0]).numpy() ,'shape':heatmap_gcam_pp.permute([1,2,0]).numpy().shape})\n",
        "  output_path   = base_path+\"result_gcam_pp.png\"\n",
        "  savemat(output_path.split('.png')[0] +'.mat',{'data':result_gcam_pp.permute([1,2,0]).numpy() ,'shape':result_gcam_pp.permute([1,2,0]).numpy().shape})\n",
        "  output_path   = base_path+\"hard_masked_gcam_pp.png\" \n",
        "  savemat(output_path.split('.png')[0] +'.mat',{'data':hard_masked_gcam_pp.permute([1,2,0]).numpy() ,'shape':hard_masked_gcam_pp.permute([1,2,0]).numpy().shape})\n",
        "  output_path   = base_path+\"masked_gcam_pp.mat\" \n",
        "  savemat(output_path,{'data':masked_gcam_pp.numpy() ,'shape':masked_gcam_pp.numpy().shape})\n",
        "  masked_gcam_pp_mat = loadmat(output_path)['data']\n",
        "  plt.clf()\n",
        "  p=plt.imshow(masked_gcam_pp_mat,cmap='jet')\n",
        "  plt.colorbar(p)      \n",
        "  plt.clim(0.8,1)\n",
        "  output_path   = base_path+\"masked_gcam_pp_0.8.png\" \n",
        "  plt.savefig(output_path)\n",
        "  \n",
        "\n",
        "  im=ndimage.rotate(masked_gcam_pp_mat,angle)\n",
        "  max=1\n",
        "  im = im/max #optional step as in our case max is 1 also use any contant val.\n",
        "\n",
        "  im[im<0.3]=np.nan\n",
        "  plt.imshow(im,cmap='jet')\n",
        "  plt.axis('off')\n",
        "  plt.clim(0,1)\n",
        "  plt.savefig(result_path+'_result.png')\n",
        "\n",
        "  ##############################################################################\n",
        "  '''\n",
        "  These are the images used in the final results the ones inside result_path\n",
        "  '''\n",
        "  plt.clf() # clear existing figure\n",
        "  #mask overlaid on gray matter\n",
        "  print(f'background shape before={background_img.shape}')\n",
        "  im2=background_img[0]\n",
        "  print(f'background shape after={im2.shape}')\n",
        "  im2=ndimage.rotate(im2,angle)\n",
        "  im2=1-im2\n",
        "  gray=plt.imshow(im2,cmap='gray')\n",
        "  plt.axis('off')\n",
        "  im=ndimage.rotate(masked_gcam_pp_mat,angle)\n",
        "  im[im<0.3]=np.nan\n",
        "  heat=plt.imshow(im,cmap='jet')\n",
        "  plt.axis('off')\n",
        "  plt.clim(0,1)\n",
        "  plt.colorbar()\n",
        "  plt.savefig(result_path+'_result_overlay.png')\n",
        "\n",
        "  ##############################################################################\n",
        "\n",
        "  ## Saliency only\n",
        "  masked_csmap=masked_csmap.numpy()\n",
        "\n",
        "  frac=0.5\n",
        "\n",
        "  t='masked_only_saliency'\n",
        "  max =  1 #np.amax(masked_gcam)\n",
        "  r1=(masked_csmap/max)\n",
        "\n",
        "  r1[np.where(r1<frac*np.max(r1))]=0\n",
        "  # r1[np.where(r1<np.median(r1))]=0\n",
        "  plt.imsave(base_path+'nodiff_{0}_{1}.png'.format(frac,t),r1,cmap='jet')\n",
        "\n",
        "  frac=0.3\n",
        "  r1=(masked_csmap/max)\n",
        "\n",
        "  r1[np.where(r1<frac*np.max(r1))]=0\n",
        "  # r1[np.where(r1<np.median(r1))]=0\n",
        "  plt.imsave(base_path+'nodiff_{0}_{1}.png'.format(frac,t),r1,cmap='jet')\n",
        "\n",
        "  frac=0.8\n",
        "  r1=(masked_csmap/max)\n",
        "\n",
        "  r1[np.where(r1<frac*np.max(r1))]=0\n",
        "  # r1[np.where(r1<np.median(r1))]=0\n",
        "  plt.imsave(base_path+'nodiff_{0}_{1}.png'.format(frac,t),r1,cmap='jet')\n",
        "\n",
        "\n",
        "  ## GCAM\n",
        "  masked_gcam=masked_gcam.numpy()\n",
        "\n",
        "  frac=0.5\n",
        "\n",
        "  t='masked_gcam'\n",
        "  max =  1 #np.amax(masked_gcam)\n",
        "  r1=(masked_gcam/max)\n",
        "\n",
        "  r1[np.where(r1<frac*np.max(r1))]=0\n",
        "  # r1[np.where(r1<np.median(r1))]=0\n",
        "  plt.imsave(base_path+'nodiff_{0}_{1}.png'.format(frac,t),r1,cmap='jet')\n",
        "\n",
        "  frac=0.3\n",
        "  r1=(masked_gcam/max)\n",
        "\n",
        "  r1[np.where(r1<frac*np.max(r1))]=0\n",
        "  # r1[np.where(r1<np.median(r1))]=0\n",
        "  plt.imsave(base_path+'nodiff_{0}_{1}.png'.format(frac,t),r1,cmap='jet')\n",
        "\n",
        "  frac=0.8\n",
        "  r1=(masked_gcam/max)\n",
        "\n",
        "  r1[np.where(r1<frac*np.max(r1))]=0\n",
        "  # r1[np.where(r1<np.median(r1))]=0\n",
        "  plt.imsave(base_path+'nodiff_{0}_{1}.png'.format(frac,t),r1,cmap='jet')\n",
        "\n",
        "  ## GCAM++\n",
        "  ## fraction mask  map for overlaying GCAM++\n",
        "  masked_gcam_pp=masked_gcam_pp.numpy()\n",
        "\n",
        "  frac=0.5\n",
        "\n",
        "  t='masked_gcam_pp'\n",
        "  max = 1 #np.amax(masked_gcam_pp)\n",
        "  r1=(masked_gcam_pp/max)\n",
        "\n",
        "  r1[np.where(r1<frac*np.max(r1))]=0\n",
        "  # r1[np.where(r1<np.median(r1))]=0\n",
        "  plt.imsave(base_path+'nodiff_{0}_{1}.png'.format(frac,t),r1,cmap='jet')\n",
        "\n",
        "  frac=0.3\n",
        "  r1=(masked_gcam_pp/max)\n",
        "\n",
        "  r1[np.where(r1<frac*np.max(r1))]=0\n",
        "  # r1[np.where(r1<np.median(r1))]=0\n",
        "  plt.imsave(base_path+'nodiff_{0}_{1}.png'.format(frac,t),r1,cmap='jet')\n",
        "\n",
        "  frac=0.8\n",
        "  r1=(masked_gcam_pp/max)\n",
        "\n",
        "  r1[np.where(r1<frac*np.max(r1))]=0\n",
        "  # r1[np.where(r1<np.median(r1))]=0\n",
        "  plt.imsave(base_path+'nodiff_{0}_{1}.png'.format(frac,t),r1,cmap='jet')\n",
        "\n",
        "  ##\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/fastcam\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Fc3oJlT9wlu",
        "colab_type": "text"
      },
      "source": [
        "# **Tf records loading and parsing utility**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsyZ1X6P9vvP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_selected_scan_from_subjects(data_path,subject_ids,label_df,selected_scans):\n",
        "    '''\n",
        "    Same as get_scan_from_subjects in case we need specific scan path and not all scans of a patient.\n",
        "    '''\n",
        "    scans=[]\n",
        "    labels=[]\n",
        "    gender=[]\n",
        "    cdr=[]\n",
        "    ids=[]\n",
        "    subject_ids = set(subject_ids)\n",
        "    for subject in subject_ids :\n",
        "        path=os.path.join(data_path,subject)\n",
        "        paths=os.listdir(path)\n",
        "\n",
        "        ids.extend([scan_id.split('.')[0] for scan_id in paths  if scan_id.split('/')[-1].split('.')[0] in selected_scans ])\n",
        "        scans.extend([ os.path.join(path,scan_id) for scan_id in paths   if scan_id.split('/')[-1].split('.')[0] in selected_scans ])\n",
        "        \n",
        "    \n",
        "        labels.extend([label_df[label_df['MRI ID']==scan_id.split('.')[0]]['Age'].to_list()[0] for scan_id in paths   if scan_id.split('/')[-1].split('.')[0] in selected_scans ])\n",
        "        gender.extend([label_df[label_df['MRI ID']==scan_id.split('.')[0]]['M/F'].to_list()[0] for scan_id in paths   if scan_id.split('/')[-1].split('.')[0] in selected_scans])\n",
        "        cdr.extend([label_df[label_df['MRI ID']==scan_id.split('.')[0]]['CDR'].to_list()[0] for scan_id in paths  if scan_id.split('/')[-1].split('.')[0] in selected_scans])\n",
        "\n",
        "    return scans,labels,gender,ids,cdr\n",
        "\n",
        "def get_scan_from_subjects(data_path,subject_ids,label_df):\n",
        "    '''\n",
        "    Scan paths,cdr,gender,labels  of subjects .\n",
        "    '''\n",
        "    scans=[]\n",
        "    labels=[]\n",
        "    gender=[]\n",
        "    cdr=[]\n",
        "    ids=[]\n",
        "    subject_ids = set(subject_ids)\n",
        "    for subject in subject_ids :\n",
        "        path=os.path.join(data_path,subject)\n",
        "        paths=os.listdir(path)\n",
        "        ids.extend([scan_id.split('.')[0] for scan_id in paths ])\n",
        "        scans.extend([ os.path.join(path,scan_path) for scan_path in paths  ])\n",
        " \n",
        "        labels.extend([label_df[label_df['MRI ID']==scan_id.split('.')[0]]['Age'].to_list()[0] for scan_id in paths   ])\n",
        "        gender.extend([label_df[label_df['MRI ID']==scan_id.split('.')[0]]['M/F'].to_list()[0] for scan_id in paths  ])\n",
        "        cdr.extend([label_df[label_df['MRI ID']==scan_id.split('.')[0]]['CDR'].to_list()[0] for scan_id in paths ])\n",
        "    #print(labels,gender)\n",
        "           \n",
        "    # shuffle(scans)\n",
        "    \n",
        "    return scans,labels,gender,ids,cdr\n",
        "\n",
        "\n",
        "def get_test_files(label_path,data_path,debug_mode_subject=None,selected_scans=[]):\n",
        "    '''\n",
        "    Primary function to get scans.\n",
        "    '''\n",
        "\n",
        "    data = pd.read_csv(label_path)\n",
        "    data = data.rename(columns={'MR ID':'MRI ID'})\n",
        "    data['M/F'] = encode_gender(data)\n",
        "    if debug_mode_subject is None:\n",
        "      test_ids = os.listdir(data_path)\n",
        "    else:\n",
        "      test_ids=debug_mode_subject\n",
        "    \n",
        "    shuffle(test_ids)\n",
        "    if len(selected_scans)>0:\n",
        "      test_patients,test_labels,test_gender,scan_ids,test_cdr = get_selected_scan_from_subjects(data_path,test_ids,data,selected_scans)\n",
        "    else:\n",
        "      test_patients,test_labels,test_gender,scan_ids,test_cdr = get_scan_from_subjects(data_path,test_ids,data)\n",
        "   \n",
        "    return test_patients,scan_ids, test_labels,test_gender,test_cdr\n",
        "   \n",
        "def encode_gender(data):\n",
        "    '''\n",
        "    Categorical encoding. for gender.\n",
        "    '''\n",
        "    data['M/F'] = pd.Categorical(data['M/F'])\n",
        "    \n",
        "    return data['M/F'].cat.codes\n",
        "\n",
        "def parse_function_image(example_proto):\n",
        "\n",
        "    features = {\n",
        "        'image': tf.io.FixedLenFeature([], tf.string),\n",
        "        'image_shape': tf.io.FixedLenFeature([], tf.string)\n",
        "    }\n",
        "\n",
        "    content = tf.io.parse_single_example(example_proto, features=features)\n",
        "\n",
        "    content['image_shape'] = tf.io.decode_raw(content['image_shape'], tf.int32)\n",
        "    content['image'] = tf.io.decode_raw(content['image'], tf.float32)\n",
        "    content['image'] = tf.reshape(content['image'], content['image_shape'])\n",
        "\n",
        "    return content['image']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k04fqJeqM15s",
        "colab_type": "text"
      },
      "source": [
        "# **Create Siamese model encoder (reference: Nivedita. V)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKWzDMBTJngH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "from tensorflow.keras.layers import Input, Dense, Lambda, Layer, Add, Multiply, add, Activation\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "\n",
        "latent_dim = 128\n",
        "  \n",
        "  \n",
        "def conv2d_bn(x,\n",
        "              filters,\n",
        "              strides,\n",
        "              padding='same'\n",
        "              ):\n",
        "\n",
        "    x = tf.keras.layers.Conv2D(filters, (3, 3),\n",
        "        strides=strides,\n",
        "        padding=padding, kernel_initializer='he_normal', kernel_regularizer=l2(5e-4),\n",
        "        use_bias=False)(x)\n",
        "\n",
        "    bn_axis = -1\n",
        "    x = tf.keras.layers.BatchNormalization(axis=bn_axis, scale=False)(x)\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "\n",
        "    return x\n",
        "    \n",
        "\n",
        "def conv2d_bn_1x1(x,\n",
        "              filters,\n",
        "              strides,\n",
        "              padding='same'\n",
        "              ):\n",
        "\n",
        "    x = tf.keras.layers.Conv2D(filters, (1, 1),\n",
        "        strides=strides,\n",
        "        padding=padding, kernel_initializer='he_normal', kernel_regularizer=l2(5e-4),\n",
        "        use_bias=False)(x)\n",
        "\n",
        "    bn_axis = -1\n",
        "    x = tf.keras.layers.BatchNormalization(axis=bn_axis, scale=False)(x)\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def conv2d_bn_7x7(x,\n",
        "              filters,\n",
        "              strides=(2, 2),\n",
        "              padding='same'\n",
        "              ):\n",
        "\t\t\t  \n",
        "    x = tf.keras.layers.Conv2D(filters, (7, 7),\n",
        "        strides=strides,\n",
        "        padding=padding, kernel_initializer='he_normal', kernel_regularizer=l2(5e-4),\n",
        "        use_bias=False)(x)\n",
        "\n",
        "    bn_axis = -1\n",
        "    x = tf.keras.layers.BatchNormalization(axis=bn_axis, scale=False)(x)\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "\n",
        "    return x\n",
        "\t\n",
        "\t\n",
        "def residual_module1(layer_in, n_filters):\n",
        "    # conv1\n",
        "    x = conv2d_bn(layer_in, n_filters, strides=(1, 1), padding='same')\n",
        "\n",
        "    # conv2\n",
        "    conv2 = conv2d_bn(x, n_filters, strides=(1, 1), padding='same')\n",
        "\n",
        "    # add filters, assumes filters/channels last\n",
        "    layer_out = add([conv2, layer_in])\n",
        "    # activation function\n",
        "    layer_out = Activation('relu')(layer_out)\n",
        "\n",
        "    return layer_out\n",
        "\n",
        "\n",
        "def residual_module2(layer_in, n_filters):\n",
        "    # conv1\n",
        "    x = conv2d_bn(layer_in, n_filters, strides=(2, 2), padding='same')\n",
        "    # conv2\n",
        "    conv2 = conv2d_bn(x, n_filters, strides=(1, 1), padding='same')\n",
        "    \n",
        "    #projection shortcut for mismatch in number of channels\n",
        "    y = conv2d_bn_1x1(layer_in, n_filters, strides=(2, 2), padding='same')\n",
        "\n",
        "    # add filters, assumes filters/channels last\n",
        "    layer_out = add([conv2, y])\n",
        "    # activation function\n",
        "    layer_out = Activation('relu')(layer_out)\n",
        "\n",
        "    return layer_out\n",
        "\t\n",
        "\t\n",
        "def res34(inp):\n",
        "    channel_axis = -1\n",
        "    #Instantiates the Inflated 3D Inception v1 architecture.\n",
        "\n",
        "    # Downsampling via convolution (spatial and temporal)\n",
        "    x = conv2d_bn_7x7(inp, 64, strides=(2, 2), padding='same')\n",
        "    x = tf.keras.layers.MaxPool2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "\t\n",
        "    x = residual_module1(x,64)\n",
        "    x = residual_module1(x,64)\n",
        "    x = residual_module1(x,64)\n",
        "\n",
        "    x = residual_module2(x,128)\n",
        "    x = residual_module1(x,128)\n",
        "    x = residual_module1(x,128)\n",
        "    x = residual_module1(x,128)\n",
        "\n",
        "    x = residual_module2(x,256)\n",
        "    x = residual_module1(x,256)\n",
        "    x = residual_module1(x,256)\n",
        "    x = residual_module1(x,256)\n",
        "    x = residual_module1(x,256)\n",
        "    x = residual_module1(x,256)\n",
        "\n",
        "    x = residual_module2(x,512)\n",
        "    x = residual_module1(x,512)\n",
        "    x = residual_module1(x,512)\n",
        "\t\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D(name = 'gap')(x)\n",
        "\t\n",
        "    # FCN with Relu activation, kernel_regularizer=l2(1e-3)\n",
        "    x = tf.keras.layers.Dense(units=512, kernel_regularizer=l2(1e-3), name='dense1')(x)\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "    x = tf.keras.layers.Dropout(0.4)(x)\n",
        "\n",
        "    # FCN with Relu activation, kernel_regularizer=l2(1e-3)\n",
        "    x = tf.keras.layers.Dense(units=256, kernel_regularizer=l2(1e-3), name='dense2')(x)\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "    x = tf.keras.layers.Dropout(0.4)(x)\n",
        "\n",
        "    z = tf.keras.layers.Dense(units = latent_dim)(x)\n",
        "    z = tf.keras.layers.Activation('relu')(z)\n",
        "    z = tf.keras.layers.Lambda(lambda x: K.l2_normalize(x, axis=1))(z)\n",
        "\n",
        "    return z\n",
        "\t\n",
        "def model_create():\n",
        "    # defining input shape\n",
        "    input = tf.keras.Input(shape=(121, 145, 1))\n",
        "\n",
        "    # base for encoder\n",
        "    z = res34(input)\n",
        "\n",
        "    # defining model for encoder\n",
        "    encoder = Model(inputs = input, outputs = z, name='encoder')\n",
        "    print(encoder.summary())\n",
        "\n",
        "    return encoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wclyYj3WNJFf",
        "colab_type": "text"
      },
      "source": [
        "# **Assigning Siamese model's encoder's weights to encoder created from above cell**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REX4yLooKfuU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# type(siam_model.get_layer(index=3).weights)\n",
        "def assign_encoder_weights(siam_model,encoder):\n",
        "  encoder_weights= siam_model.get_layer(index=3).weights\n",
        "  j=0\n",
        "  for i,l in enumerate(encoder.layers[1:-2]):\n",
        "    # print(l)\n",
        "    # if i > 0 and i< 150:\n",
        "    if 'activation' in l.name or 'pool' in l.name or 'add' in l.name or 'gap' in l.name or 'dropout' in l.name:\n",
        "      # j+=1\n",
        "      continue\n",
        "    \n",
        "    elif 'batch' in l.name:\n",
        "      print(f'I,J={i,j}')\n",
        "      print(encoder.layers[i+1].name,encoder_weights[j].name)\n",
        "\n",
        "      beta=encoder_weights[j].numpy()\n",
        "      mean=encoder_weights[j+1].numpy()\n",
        "      var=encoder_weights[j+2].numpy()\n",
        "\n",
        "      encoder.layers[i+1].set_weights([beta,mean,var])\n",
        "      j+=3\n",
        " \n",
        "    elif 'dense' in l.name:\n",
        "      print(f'I,J={i,j}')\n",
        "      print(encoder.layers[i+1].name,encoder_weights[j].name)\n",
        "      w=encoder_weights[j].numpy()\n",
        "      b=encoder_weights[j+1].numpy()\n",
        "      encoder.layers[i+1].set_weights([w,b])\n",
        "      j+=2\n",
        "    else:\n",
        "      print(f'I,J={i,j}')\n",
        "      print(encoder.layers[i+1].name,encoder_weights[j].name)\n",
        "     \n",
        "      encoder.layers[i+1].set_weights([encoder_weights[j].numpy()])\n",
        "      j+=1\n",
        "\n",
        "  return encoder\n",
        "  # print(l.weights)\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0blAk0hI6MXA",
        "colab_type": "text"
      },
      "source": [
        "#**Compute Visualizations for siamese model  on testset** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moBojgEYFnI6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cf={'Pretrained_Model':{'path':'/content/drive/My Drive/BA_Estimation/models/exp_siam/Model'},'Paths':\\\n",
        "      {'labels':'/content/drive/My Drive/BA_Estimation/csv_data/oasis1_oasis3_labels.csv',\\\n",
        "       'test_tfrecord':'/content/drive/My Drive/BA_Estimation/tf_records_data/training_testing_exp4'}}# #all_cdr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGosD0T1mXgL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d89bada4-0824-4b8c-c00a-da554d181ac8"
      },
      "source": [
        "\n",
        "siam_model =  tf.python.keras.models.load_model(cf['Pretrained_Model']['path'],compile=False)\n",
        "encoder=model_create()\n",
        "tf_model = assign_encoder_weights(siam_model,encoder)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:1045: UserWarning: Res34_model is not loaded, but a Lambda layer uses it. It may cause errors.\n",
            "  , UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"encoder\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 121, 145, 1) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 61, 73, 64)   3136        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 61, 73, 64)   192         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 61, 73, 64)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 31, 37, 64)   0           activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 31, 37, 64)   36864       max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 31, 37, 64)   192         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 31, 37, 64)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 31, 37, 64)   36864       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 31, 37, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 31, 37, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 31, 37, 64)   0           activation_2[0][0]               \n",
            "                                                                 max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 31, 37, 64)   0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 31, 37, 64)   36864       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 31, 37, 64)   192         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 31, 37, 64)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 31, 37, 64)   36864       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 31, 37, 64)   192         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 31, 37, 64)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 31, 37, 64)   0           activation_5[0][0]               \n",
            "                                                                 activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 31, 37, 64)   0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 31, 37, 64)   36864       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 31, 37, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 31, 37, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 31, 37, 64)   36864       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 31, 37, 64)   192         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 31, 37, 64)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 31, 37, 64)   0           activation_8[0][0]               \n",
            "                                                                 activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 31, 37, 64)   0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 19, 128)  73728       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 19, 128)  384         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 19, 128)  0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 19, 128)  147456      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 19, 128)  8192        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 19, 128)  384         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 19, 128)  384         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 19, 128)  0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 19, 128)  0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 16, 19, 128)  0           activation_11[0][0]              \n",
            "                                                                 activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 19, 128)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 19, 128)  147456      activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 19, 128)  384         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 19, 128)  0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 19, 128)  147456      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 19, 128)  384         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 19, 128)  0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 16, 19, 128)  0           activation_15[0][0]              \n",
            "                                                                 activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 19, 128)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 19, 128)  147456      activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 19, 128)  384         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 19, 128)  0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 19, 128)  147456      activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 19, 128)  384         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 19, 128)  0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 16, 19, 128)  0           activation_18[0][0]              \n",
            "                                                                 activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 19, 128)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 19, 128)  147456      activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 19, 128)  384         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 19, 128)  0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 19, 128)  147456      activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 19, 128)  384         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 19, 128)  0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 16, 19, 128)  0           activation_21[0][0]              \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 19, 128)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 8, 10, 256)   294912      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 8, 10, 256)   768         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 8, 10, 256)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 8, 10, 256)   589824      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 8, 10, 256)   32768       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 8, 10, 256)   768         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 8, 10, 256)   768         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 8, 10, 256)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 8, 10, 256)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 8, 10, 256)   0           activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 8, 10, 256)   0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 8, 10, 256)   589824      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 8, 10, 256)   768         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 8, 10, 256)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 8, 10, 256)   589824      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 8, 10, 256)   768         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 8, 10, 256)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 8, 10, 256)   0           activation_28[0][0]              \n",
            "                                                                 activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 8, 10, 256)   0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 8, 10, 256)   589824      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 8, 10, 256)   768         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 8, 10, 256)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 8, 10, 256)   589824      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 8, 10, 256)   768         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 8, 10, 256)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 8, 10, 256)   0           activation_31[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 8, 10, 256)   0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 8, 10, 256)   589824      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 8, 10, 256)   768         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 8, 10, 256)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 8, 10, 256)   589824      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 8, 10, 256)   768         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 8, 10, 256)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 8, 10, 256)   0           activation_34[0][0]              \n",
            "                                                                 activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 8, 10, 256)   0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 8, 10, 256)   589824      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 8, 10, 256)   768         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 8, 10, 256)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 8, 10, 256)   589824      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 8, 10, 256)   768         conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 8, 10, 256)   0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 8, 10, 256)   0           activation_37[0][0]              \n",
            "                                                                 activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 8, 10, 256)   0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 8, 10, 256)   589824      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 8, 10, 256)   768         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 8, 10, 256)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 8, 10, 256)   589824      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 8, 10, 256)   768         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 8, 10, 256)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 8, 10, 256)   0           activation_40[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 8, 10, 256)   0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 4, 5, 512)    1179648     activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 4, 5, 512)    1536        conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 4, 5, 512)    0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 4, 5, 512)    2359296     activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 4, 5, 512)    131072      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 4, 5, 512)    1536        conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 4, 5, 512)    1536        conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 4, 5, 512)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 4, 5, 512)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 4, 5, 512)    0           activation_43[0][0]              \n",
            "                                                                 activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 4, 5, 512)    0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 4, 5, 512)    2359296     activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 4, 5, 512)    1536        conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 4, 5, 512)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 4, 5, 512)    2359296     activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 4, 5, 512)    1536        conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 4, 5, 512)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 4, 5, 512)    0           activation_47[0][0]              \n",
            "                                                                 activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 4, 5, 512)    0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 4, 5, 512)    2359296     activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 4, 5, 512)    1536        conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 4, 5, 512)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 4, 5, 512)    2359296     activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 4, 5, 512)    1536        conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 4, 5, 512)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 4, 5, 512)    0           activation_50[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 4, 5, 512)    0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "gap (GlobalAveragePooling2D)    (None, 512)          0           activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense1 (Dense)                  (None, 512)          262656      gap[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 512)          0           dense1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 512)          0           activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense2 (Dense)                  (None, 256)          131328      dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 256)          0           dense2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 256)          0           activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 128)          32896       dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 128)          0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (None, 128)          0           activation_54[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 21,713,792\n",
            "Trainable params: 21,696,768\n",
            "Non-trainable params: 17,024\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "I,J=(0, 0)\n",
            "conv2d conv2d/kernel:0\n",
            "I,J=(1, 1)\n",
            "batch_normalization batch_normalization/beta:0\n",
            "I,J=(4, 4)\n",
            "conv2d_1 conv2d_1/kernel:0\n",
            "I,J=(5, 5)\n",
            "batch_normalization_1 batch_normalization_1/beta:0\n",
            "I,J=(7, 8)\n",
            "conv2d_2 conv2d_2/kernel:0\n",
            "I,J=(8, 9)\n",
            "batch_normalization_2 batch_normalization_2/beta:0\n",
            "I,J=(12, 12)\n",
            "conv2d_3 conv2d_3/kernel:0\n",
            "I,J=(13, 13)\n",
            "batch_normalization_3 batch_normalization_3/beta:0\n",
            "I,J=(15, 16)\n",
            "conv2d_4 conv2d_4/kernel:0\n",
            "I,J=(16, 17)\n",
            "batch_normalization_4 batch_normalization_4/beta:0\n",
            "I,J=(20, 20)\n",
            "conv2d_5 conv2d_5/kernel:0\n",
            "I,J=(21, 21)\n",
            "batch_normalization_5 batch_normalization_5/beta:0\n",
            "I,J=(23, 24)\n",
            "conv2d_6 conv2d_6/kernel:0\n",
            "I,J=(24, 25)\n",
            "batch_normalization_6 batch_normalization_6/beta:0\n",
            "I,J=(28, 28)\n",
            "conv2d_7 conv2d_7/kernel:0\n",
            "I,J=(29, 29)\n",
            "batch_normalization_7 batch_normalization_7/beta:0\n",
            "I,J=(31, 32)\n",
            "conv2d_8 conv2d_8/kernel:0\n",
            "I,J=(32, 33)\n",
            "conv2d_9 conv2d_9/kernel:0\n",
            "I,J=(33, 34)\n",
            "batch_normalization_8 batch_normalization_8/beta:0\n",
            "I,J=(34, 37)\n",
            "batch_normalization_9 batch_normalization_9/beta:0\n",
            "I,J=(39, 40)\n",
            "conv2d_10 conv2d_10/kernel:0\n",
            "I,J=(40, 41)\n",
            "batch_normalization_10 batch_normalization_10/beta:0\n",
            "I,J=(42, 44)\n",
            "conv2d_11 conv2d_11/kernel:0\n",
            "I,J=(43, 45)\n",
            "batch_normalization_11 batch_normalization_11/beta:0\n",
            "I,J=(47, 48)\n",
            "conv2d_12 conv2d_12/kernel:0\n",
            "I,J=(48, 49)\n",
            "batch_normalization_12 batch_normalization_12/beta:0\n",
            "I,J=(50, 52)\n",
            "conv2d_13 conv2d_13/kernel:0\n",
            "I,J=(51, 53)\n",
            "batch_normalization_13 batch_normalization_13/beta:0\n",
            "I,J=(55, 56)\n",
            "conv2d_14 conv2d_14/kernel:0\n",
            "I,J=(56, 57)\n",
            "batch_normalization_14 batch_normalization_14/beta:0\n",
            "I,J=(58, 60)\n",
            "conv2d_15 conv2d_15/kernel:0\n",
            "I,J=(59, 61)\n",
            "batch_normalization_15 batch_normalization_15/beta:0\n",
            "I,J=(63, 64)\n",
            "conv2d_16 conv2d_16/kernel:0\n",
            "I,J=(64, 65)\n",
            "batch_normalization_16 batch_normalization_16/beta:0\n",
            "I,J=(66, 68)\n",
            "conv2d_17 conv2d_17/kernel:0\n",
            "I,J=(67, 69)\n",
            "conv2d_18 conv2d_18/kernel:0\n",
            "I,J=(68, 70)\n",
            "batch_normalization_17 batch_normalization_17/beta:0\n",
            "I,J=(69, 73)\n",
            "batch_normalization_18 batch_normalization_18/beta:0\n",
            "I,J=(74, 76)\n",
            "conv2d_19 conv2d_19/kernel:0\n",
            "I,J=(75, 77)\n",
            "batch_normalization_19 batch_normalization_19/beta:0\n",
            "I,J=(77, 80)\n",
            "conv2d_20 conv2d_20/kernel:0\n",
            "I,J=(78, 81)\n",
            "batch_normalization_20 batch_normalization_20/beta:0\n",
            "I,J=(82, 84)\n",
            "conv2d_21 conv2d_21/kernel:0\n",
            "I,J=(83, 85)\n",
            "batch_normalization_21 batch_normalization_21/beta:0\n",
            "I,J=(85, 88)\n",
            "conv2d_22 conv2d_22/kernel:0\n",
            "I,J=(86, 89)\n",
            "batch_normalization_22 batch_normalization_22/beta:0\n",
            "I,J=(90, 92)\n",
            "conv2d_23 conv2d_23/kernel:0\n",
            "I,J=(91, 93)\n",
            "batch_normalization_23 batch_normalization_23/beta:0\n",
            "I,J=(93, 96)\n",
            "conv2d_24 conv2d_24/kernel:0\n",
            "I,J=(94, 97)\n",
            "batch_normalization_24 batch_normalization_24/beta:0\n",
            "I,J=(98, 100)\n",
            "conv2d_25 conv2d_25/kernel:0\n",
            "I,J=(99, 101)\n",
            "batch_normalization_25 batch_normalization_25/beta:0\n",
            "I,J=(101, 104)\n",
            "conv2d_26 conv2d_26/kernel:0\n",
            "I,J=(102, 105)\n",
            "batch_normalization_26 batch_normalization_26/beta:0\n",
            "I,J=(106, 108)\n",
            "conv2d_27 conv2d_27/kernel:0\n",
            "I,J=(107, 109)\n",
            "batch_normalization_27 batch_normalization_27/beta:0\n",
            "I,J=(109, 112)\n",
            "conv2d_28 conv2d_28/kernel:0\n",
            "I,J=(110, 113)\n",
            "batch_normalization_28 batch_normalization_28/beta:0\n",
            "I,J=(114, 116)\n",
            "conv2d_29 conv2d_29/kernel:0\n",
            "I,J=(115, 117)\n",
            "batch_normalization_29 batch_normalization_29/beta:0\n",
            "I,J=(117, 120)\n",
            "conv2d_30 conv2d_30/kernel:0\n",
            "I,J=(118, 121)\n",
            "conv2d_31 conv2d_31/kernel:0\n",
            "I,J=(119, 122)\n",
            "batch_normalization_30 batch_normalization_30/beta:0\n",
            "I,J=(120, 125)\n",
            "batch_normalization_31 batch_normalization_31/beta:0\n",
            "I,J=(125, 128)\n",
            "conv2d_32 conv2d_32/kernel:0\n",
            "I,J=(126, 129)\n",
            "batch_normalization_32 batch_normalization_32/beta:0\n",
            "I,J=(128, 132)\n",
            "conv2d_33 conv2d_33/kernel:0\n",
            "I,J=(129, 133)\n",
            "batch_normalization_33 batch_normalization_33/beta:0\n",
            "I,J=(133, 136)\n",
            "conv2d_34 conv2d_34/kernel:0\n",
            "I,J=(134, 137)\n",
            "batch_normalization_34 batch_normalization_34/beta:0\n",
            "I,J=(136, 140)\n",
            "conv2d_35 conv2d_35/kernel:0\n",
            "I,J=(137, 141)\n",
            "batch_normalization_35 batch_normalization_35/beta:0\n",
            "I,J=(142, 144)\n",
            "dense1 dense1/kernel:0\n",
            "I,J=(145, 146)\n",
            "dense2 dense2/kernel:0\n",
            "I,J=(148, 148)\n",
            "dense dense/kernel:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXJ-XQYXq2B-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "print(tf.__version__)\n",
        "\n",
        "\n",
        "dt_string = datetime.now().strftime('%d-%m-%Y-%H-%M')+'_smoe_maps_blockend_scale_endlayers_equal_weights'\n",
        "\n",
        "label_path= cf['Paths']['labels'] \n",
        "data_path= cf['Paths']['test_tfrecord'] \n",
        "# exp='exp_siam_ad'\n",
        "exp='exp_siam_healthy'\n",
        "# debug_mode_subject= ['OAS31054']#\n",
        "# debug_mode_subject = ['OAS30884','OAS30720','OAS30344','OAS30541'] #OAS30911\n",
        "# debug_mode_subject=['OAS30440','OAS30445','OAS31140','OAS30952','OAS30199','OAS30344']#exp4\n",
        "# debug_mode_subject=['OAS31165','OAS30819','OAS30392','OAS30310','OAS31035'] #exp2\n",
        "# debug_mode_subject = ['OAS30736','OAS30282','OAS30622','OAS30190','OAS30440','OAS30826','OAS30286','OAS30987','OAS30583','OAS30070','OAS30952']\n",
        "debug_mode_subject=['OAS10104','OAS10416','OAS10045','OAS31035','OAS30310','OAS30392','OAS30956','OAS30956','OAS30093','OAS30008']\n",
        "# debug_mode_subject=None\n",
        "test_patients,scan_ids, test_labels,test_gender,test_cdr = get_test_files(label_path,data_path,debug_mode_subject)\n",
        "tfr=tf.data.TFRecordDataset(test_patients)\n",
        "img_tf=tfr.map(map_func=lambda a:parse_function_image(a))\n",
        "\n",
        "gender_dict={0:'Female',1:'Male'}\n",
        "for i,im in enumerate(img_tf): \n",
        "  print(type(im),im.shape)\n",
        "  img=im.numpy()\n",
        "  print(img.shape)\n",
        "\n",
        "  max_intensity=0\n",
        "  csmap_list=[]\n",
        "  for chunk_id in [36,42,48,54,60]:#82,88,94]:#range(1,21):\n",
        "\n",
        "    start = (chunk_id)\n",
        "    end = start+1\n",
        "    \n",
        "    img_chunk=torch.tensor(img[:,:,start]).unsqueeze(0)\n",
        "    img_chunk = img_chunk.unsqueeze(-1)\n",
        "    \n",
        "    print(f'input shape={img_chunk.shape}')\n",
        "\n",
        "    input_tensor = img_chunk\n",
        "    #***********\n",
        "\n",
        "    in_height   = input_tensor.size()[1]\n",
        "    in_width    = input_tensor.size()[2]\n",
        "    print(test_gender[i],input_tensor.shape,scan_ids[i])\n",
        " \n",
        "    a=51\n",
        "    n=35\n",
        "    # layer_name='conv3d_'+str(n-1)\n",
        "    layer_name='activation_'+str(a)\n",
        "    # conv_path ='conv1_'+str(n)+'_tfw'\n",
        "    # conv_path ='conv1_'+str(n)+'_blockend_scale_endlayers_equal_weights'\n",
        "    conv_path ='conv1_'+str(n)\n",
        "    \n",
        "\n",
        "    #axial\n",
        "    base_dir= '/content/drive/My Drive/BA_Estimation/results/sal_map_axial/'+dt_string\\\n",
        "    +'_'+exp+'/'+scan_ids[i]+'_cdr'+str(test_cdr[i])\n",
        "    path = base_dir+'/'+str(chunk_id)+'_'+conv_path+'/'\n",
        "    print(path)\n",
        "    if not os.path.exists(path):\n",
        "      os.makedirs(path)\n",
        "    base_path  = path+scan_ids[i]+'_chunk_'+str(chunk_id)\n",
        "    result_path = '/content/drive/My Drive/BA_Estimation/final_results/{0}/'.format(case)+dt_string +'/cdr'+cdr_val+'/axial/'+str(chunk_id)+'/'\n",
        "    if not os.path.exists(result_path):\n",
        "      os.makedirs(result_path)\n",
        "    result_path += scan_ids[i]\n",
        "    csmap_a=compute_saliency_tf(base_path,inputs=input_tensor,tf_model=tf_model)\n",
        "    image,gcam_img,gcam_pp_img = compute_gcam_and_gcam_pp(layer_name,tf_model,input_tensor)\n",
        "    combine_sal_gcam(path+scan_ids[i]+'_cdr'+str(test_cdr[i])+'_'+gender_dict[test_gender[i]],csmap_a,gcam_img,gcam_pp_img,image,layer_name=layer_name,angle=-270,result_path=result_path ) \n",
        "    \n",
        "\n",
        "    #sagittal\n",
        "    base_dir= '/content/drive/My Drive/BA_Estimation/results/sal_map_sagittal/'+dt_string\\\n",
        "    +'_'+exp+'/'+scan_ids[i]+'_cdr'+str(test_cdr[i])\n",
        "    path = base_dir+'/'+str(chunk_id)+'_'+conv_path+'/'\n",
        "    print(path)\n",
        "    if not os.path.exists(path):\n",
        "      os.makedirs(path)\n",
        "    base_path  = path+scan_ids[i]+'_chunk_'+str(chunk_id)\n",
        "    result_path = '/content/drive/My Drive/BA_Estimation/final_results/{0}/'.format(case)+dt_string +'/cdr'+cdr_val+'/sagittal/'+str(chunk_id)+'/'\n",
        "    if not os.path.exists(result_path):\n",
        "      os.makedirs(result_path)\n",
        "    result_path += scan_ids[i]\n",
        "    img_s= torch.from_numpy(img[start:end,:,:]).permute(2,1,0)\n",
        "    csmap_s=compute_saliency_tf(base_path,inputs=img_s,tf_model=tf_model)\n",
        "    image,gcam_img,gcam_pp_img = compute_gcam_and_gcam_pp(layer_name,tf_model,img_s)\n",
        "    combine_sal_gcam(path+scan_ids[i]+'_cdr'+str(test_cdr[i])+'_'+gender_dict[test_gender[i]],csmap_s,gcam_img,gcam_pp_img,image,layer_name=layer_name,angle=180,result_path=result_path ) \n",
        "\n",
        "    #coronal\n",
        "    base_dir= '/content/drive/My Drive/BA_Estimation/results/sal_map_coronal/'+dt_string\\\n",
        "    +'_'+exp+'/'+scan_ids[i]+'_cdr'+str(test_cdr[i])\n",
        "    path = base_dir+'/'+str(chunk_id)+'_'+conv_path+'/'\n",
        "    print(path)\n",
        "    if not os.path.exists(path):\n",
        "      os.makedirs(path)\n",
        "    base_path  = path+scan_ids[i]+'_chunk_'+str(chunk_id)\n",
        "    result_path = '/content/drive/My Drive/BA_Estimation/final_results/{0}/'.format(case)+dt_string +'/cdr'+cdr_val+'/coronal/'+str(chunk_id)+'/'\n",
        "    if not os.path.exists(result_path):\n",
        "      os.makedirs(result_path)\n",
        "    result_path += scan_ids[i]\n",
        "    img_c= torch.from_numpy(img[:,start:end,:]).permute(2,0,1)\n",
        "    img_c=img_c.unsqueeze(0)\n",
        "    img_c = torch.nn.functional.upsample(img_c.unsqueeze(0), size=(121,145,1), mode='nearest') \n",
        "    csmap_c=compute_saliency_tf(base_path,inputs=img_c,tf_model=tf_model)\n",
        "    image,gcam_img,gcam_pp_img = compute_gcam_and_gcam_pp(layer_name,tf_model,img_c)\n",
        "    combine_sal_gcam(path+scan_ids[i]+'_cdr'+str(test_cdr[i])+'_'+gender_dict[test_gender[i]],csmap_c,gcam_img,gcam_pp_img,image,layer_name=layer_name,angle=180,result_path=result_path ) \n",
        "\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7NAJG8c5hIA",
        "colab_type": "text"
      },
      "source": [
        "# **Get healthy and ad subjects from eval set and compute mean images at cdr and gender level**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4vuHwqiECdd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# np.zeros(1)\n",
        "import copy\n",
        "exp='exp_siam'\n",
        "healthy_path = '/content/drive/My Drive/BA_Estimation/models/{0}/Shuffled_labels_evalhealthy.csv'.format(exp)\n",
        "ad_path = '/content/drive/My Drive/BA_Estimation/models/{0}/Shuffled_labels_evalAD.csv'.format(exp)\n",
        "healthy_path = '/content/drive/My Drive/BA_Estimation/models/{0}/testset.csv'.format(exp)\n",
        "ad_path = '/content/drive/My Drive/BA_Estimation/models/{0}/outlier.csv'.format(exp)\n",
        "hdf = pd.read_csv(healthy_path)\n",
        "adf = pd.read_csv(ad_path)\n",
        "print(hdf.columns)\n",
        "\n",
        "sub =  hdf['patient_id'].values.tolist()\n",
        "sub.extend(adf['patient_id'].values.tolist())\n",
        "sub= list(set(sub))\n",
        "scans= copy.deepcopy(sub)\n",
        "for i,s in enumerate(sub) :\n",
        "  if s.startswith('OAS1'):\n",
        "    s= s[:9] #OAS1_0123_MR1 take first 9 characters\n",
        "    sub[i] = s.replace('_','')\n",
        "  elif s.startswith('OAS3'): #OAS31098_MR_d7178 #take just subject id\n",
        "    sub[i] = s.split('_')[0]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3oEtQMSnzqu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#compute mean slices according to gender and cdr on entire dataset\n",
        "from collections import defaultdict\n",
        "if __name__=='__main__':\n",
        "  gender_dict={0:'Female',1:'Male'}\n",
        "  gender_cdr_chunk_dict = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))\n",
        "  gender_cdr_full_dict = defaultdict(lambda: defaultdict(list))\n",
        "  dt_string = datetime.now().strftime('%d-%m-%Y-%H-%M')+'mean_scans_smoe_maps_blockend_scale_endlayers_equal_weights'\n",
        "\n",
        "  label_path= cf['Paths']['labels']\n",
        "  data_path= cf['Paths']['test_tfrecord']\n",
        "  \n",
        "  test_patients,scan_ids, test_labels,test_gender,test_cdr = get_test_files(label_path,data_path,debug_mode_subject=sub,selected_scans=scans)\n",
        "  \n",
        "  tfr=tf.data.TFRecordDataset(test_patients)\n",
        "  img_tf=tfr.map(map_func=lambda a:parse_function_image(a))\n",
        "  for i,im in enumerate(img_tf):\n",
        "    print(i+1,im.shape)\n",
        "    img=im.numpy()\n",
        "    gender_cdr_full_dict[test_gender[i]][test_cdr[i]].append(img)\n",
        "    \n",
        "\n",
        "  \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ti1dWE1f6ftf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "137f589f-6172-46f5-a0a2-bcfaa872a921"
      },
      "source": [
        "\n",
        "slice_id =48\n",
        "for g in gender_cdr_full_dict.keys():\n",
        "          print(f'Gender = {gender_dict[g]}')\n",
        "          for cdr,_ in gender_cdr_full_dict[g].items():\n",
        "              print(f'CDR = {cdr}')\n",
        "              full_imgs = np.array(gender_cdr_full_dict[g][cdr])\n",
        "              full_mean = np.mean(full_imgs,axis=0)\n",
        "              print(full_imgs.shape,full_mean.shape)\n",
        "              matpath =  '/content/drive/My Drive/BA_Estimation/means/{0}/'.format(exp)\n",
        "              if not os.path.exists(matpath):\n",
        "                os.makedirs(matpath)\n",
        "              savemat(matpath+'full_img_mean_cdr'+str(cdr)+'_'+gender_dict[g]+'.mat',{'data': full_mean,'shape':full_mean.shape})\n",
        "              \n",
        "              print('********************************')\n",
        "              img_a = full_imgs[:,:,:,48]\n",
        "              img_a = np.expand_dims(img_a,-1)\n",
        "              slice_mean = np.mean(img_a,axis=0)\n",
        "              savemat(matpath+'slice'+str(slice_id)+'axial_img_mean_cdr'+str(cdr)+'_'+gender_dict[g]+'.mat',{'data': full_mean,'shape':full_mean.shape})\n",
        "              print(slice_mean.shape)\n",
        "              \n",
        "              img_s = np.mean(full_imgs[:,48,:,:],axis=0)\n",
        "              img_s=np.expand_dims(img_s,0)\n",
        "              slice_mean = torch.from_numpy(img_s).permute(2,1,0).numpy()\n",
        "              print(slice_mean.shape)\n",
        "              savemat(matpath+'slice'+str(slice_id)+'sagittal_img_mean_cdr'+str(cdr)+'_'+gender_dict[g]+'.mat',{'data': full_mean,'shape':full_mean.shape})\n",
        "              \n",
        "              img_c = np.mean(full_imgs[:,:,48,:],axis=0)\n",
        "              # img_c=np.expand_dims(img_c,0)\n",
        "              img_c= torch.from_numpy(img_c).permute(1,0)\n",
        "\n",
        "              img_c=img_c.unsqueeze(-1)\n",
        "              img_c=img_c.unsqueeze(0)\n",
        "              img_c = torch.nn.functional.upsample(img_c.unsqueeze(0), size=(121,145,1), mode='nearest') \n",
        "              slice_mean = img_c[0,0,:,:,:].numpy()\n",
        "              print(slice_mean.shape)\n",
        "              savemat(matpath+'slice'+str(slice_id)+'coronal_img_mean_cdr'+str(cdr)+'_'+gender_dict[g]+'.mat',{'data': full_mean,'shape':full_mean.shape})\n",
        "             "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gender = Female\n",
            "CDR = 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKBVIYqm6vZ2",
        "colab_type": "text"
      },
      "source": [
        "#**Compute Visualizations for Mean  subjects test set**\n",
        "\n",
        "The mean was computed on the test set ateach cdr value for male and female separately and then visualized ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdFZgWH0mGRH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "62c19ac1-eb0d-49c7-fa92-b66dc738b3ef"
      },
      "source": [
        "mat_path = '/content/drive/My Drive/BA_Estimation/means/exp_siam/full/'\n",
        "files = os.listdir(mat_path)\n",
        "files"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['full_img_mean_cdr1.0_Male.mat',\n",
              " 'full_img_mean_cdr0.0_Male.mat',\n",
              " 'full_img_mean_cdr0.5_Female.mat',\n",
              " 'full_img_mean_cdr0.5_Male.mat',\n",
              " 'full_img_mean_cdr1.0_Female.mat',\n",
              " 'full_img_mean_cdr2.0_Female.mat',\n",
              " 'full_img_mean_cdr0.0_Female.mat']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VTbDDcao8R9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c328407f-99c4-4650-9403-26a597606bdd"
      },
      "source": [
        "# files[0].split('_')[-1].split('.')[0], files[1].split('_')[-2][-3:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Male', '0.0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcbbierTiic3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mat_path = '/content/drive/My Drive/BA_Estimation/means/exp_siam/full/'\n",
        "files = os.listdir(mat_path)\n",
        "\n",
        "# dt_string = datetime.now().strftime('%d-%m-%Y-%H-%M')+'_smoe_maps_blockend_scale_endlayers_equal_weights'\n",
        "\n",
        "label_path= cf['Paths']['labels'] \n",
        "data_path= cf['Paths']['test_tfrecord'] \n",
        "# exp='exp_siam_ad'\n",
        "exp='exp_siam_means'\n",
        "\n",
        "\n",
        "gender_dict={0:'Female',1:'Male'}\n",
        "reverse_gender_dict = {'Female':0,'Male':0}\n",
        "for i,f in enumerate(files): #OAS30686_d0030\n",
        "  # print(type(f),im.shape)\n",
        "\n",
        "  test_gender = f.split('_')[-1].split('.')[0]\n",
        "  gender_tensor= np.array(reverse_gender_dict[test_gender])\n",
        "  test_cdr = f.split('_')[-2][-3:]\n",
        "  img=loadmat(mat_path+f)['data']\n",
        "  csmap_list=[]\n",
        "  for chunk_id in [48]:\n",
        "\n",
        "    start = (chunk_id)\n",
        "    end = start+1\n",
        "    \n",
        "\n",
        "    img_chunk=torch.tensor(img[:,:,start]).unsqueeze(0)\n",
        "    img_chunk = img_chunk.unsqueeze(-1)\n",
        "    \n",
        "    print(f'input shape={img_chunk.shape}')\n",
        "   \n",
        "    input_tensor = img_chunk\n",
        "\n",
        "    in_height   = input_tensor.size()[1]\n",
        "    in_width    = input_tensor.size()[2]\n",
        "    print(test_gender,input_tensor.shape,f)\n",
        "\n",
        "    a=51\n",
        "    n=35\n",
        "\n",
        "    layer_name='activation_'+str(a)\n",
        "\n",
        "    conv_path ='conv1_'+str(n)\n",
        "\n",
        "\n",
        "    #axial\n",
        "    base_dir= '/content/drive/My Drive/BA_Estimation/means/'+dt_string+ '/sal_map_axial/' \\\n",
        "    +exp+'/'+f+'_cdr'+str(test_cdr)\n",
        "    path = base_dir+'/'+str(chunk_id)+'_'+conv_path+'/'\n",
        "    print(path)\n",
        "    if not os.path.exists(path):\n",
        "      os.makedirs(path)\n",
        "    base_path  = path+f+'_chunk_'+str(chunk_id)\n",
        "    csmap_a=compute_saliency_tf(base_path,inputs=input_tensor,tf_model=tf_model)\n",
        "    image,gcam_img,gcam_pp_img = compute_gcam_and_gcam_pp(layer_name,tf_model,input_tensor)\n",
        "    combine_sal_gcam(path+f+'_cdr'+str(test_cdr)+'_'+test_gender,csmap_a,gcam_img,gcam_pp_img,image,layer_name=layer_name ) \n",
        "\n",
        "\n",
        "    #sagittal\n",
        "    base_dir= '/content/drive/My Drive/BA_Estimation/means/'+dt_string+'/sal_map_sagittal/' \\\n",
        "    +exp+'/'+f+'_cdr'+str(test_cdr)\n",
        "    path = base_dir+'/'+str(chunk_id)+'_'+conv_path+'/'\n",
        "    print(path)\n",
        "    if not os.path.exists(path):\n",
        "      os.makedirs(path)\n",
        "    base_path  = path+f+'_chunk_'+str(chunk_id)\n",
        "    img_s= torch.from_numpy(img[start:end,:,:]).permute(2,1,0)\n",
        "    csmap_s=compute_saliency_tf(base_path,inputs=img_s,tf_model=tf_model)\n",
        "    image,gcam_img,gcam_pp_img = compute_gcam_and_gcam_pp(layer_name,tf_model,img_s)\n",
        "    combine_sal_gcam(path+f+'_cdr'+str(test_cdr)+'_'+test_gender,csmap_s,gcam_img,gcam_pp_img,image,layer_name=layer_name ) \n",
        "\n",
        "    #coronal\n",
        "    base_dir= '/content/drive/My Drive/BA_Estimation/means/'+dt_string + '/sal_map_coronal/' \\\n",
        "    +exp+'/'+f+'_cdr'+str(test_cdr)\n",
        "    path = base_dir+'/'+str(chunk_id)+'_'+conv_path+'/'\n",
        "    print(path)\n",
        "    if not os.path.exists(path):\n",
        "      os.makedirs(path)\n",
        "    base_path  = path+f+'_chunk_'+str(chunk_id)\n",
        "    img_c= torch.from_numpy(img[:,start:end,:]).permute(2,0,1)\n",
        "    img_c=img_c.unsqueeze(0)\n",
        "    img_c = torch.nn.functional.upsample(img_c.unsqueeze(0), size=(121,145,1), mode='nearest') \n",
        "    csmap_c=compute_saliency_tf(base_path,inputs=img_c,tf_model=tf_model)\n",
        "    image,gcam_img,gcam_pp_img = compute_gcam_and_gcam_pp(layer_name,tf_model,img_c)\n",
        "    combine_sal_gcam(path+f+'_cdr'+str(test_cdr)+'_'+test_gender,csmap_c,gcam_img,gcam_pp_img,image,layer_name=layer_name ) \n",
        "\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}