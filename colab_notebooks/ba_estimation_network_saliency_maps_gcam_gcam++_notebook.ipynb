{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ba_estimation_network_saliency_maps_gcam_gcam++_notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "15P8hWSHbXF3iE6hYgBq4JlRArI_1UYzT",
      "authorship_tag": "ABX9TyPParJTtGJGoTxgL9okFnrV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shashank3110/Master_Thesis_BA_DeepVis/blob/master/colab_notebooks/ba_estimation_network_saliency_maps_gcam_gcam%2B%2B_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuM4VvCQ1UD3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "3c25634b-3d7a-41d1-f5a0-57f177fbfcca"
      },
      "source": [
        "!git clone https://github.com/LLNL/fastcam.git\n",
        "\n",
        "!pip install pytorch_gradcam   #hooks=[predictions[0],predictions[2],predictions[14],predictions[47],predictions[65]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'fastcam'...\n",
            "remote: Enumerating objects: 184, done.\u001b[K\n",
            "remote: Counting objects: 100% (184/184), done.\u001b[K\n",
            "remote: Compressing objects: 100% (113/113), done.\u001b[K\n",
            "remote: Total 598 (delta 113), reused 130 (delta 70), pack-reused 414\u001b[K\n",
            "Receiving objects: 100% (598/598), 18.54 MiB | 27.24 MiB/s, done.\n",
            "Resolving deltas: 100% (353/353), done.\n",
            "Collecting pytorch_gradcam\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e6/0a/55251f7cbea464581c6fb831813d38a41fdeb78f3dd8193522248cb98744/pytorch-gradcam-0.2.1.tar.gz (6.0MB)\n",
            "\u001b[K     |████████████████████████████████| 6.0MB 4.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from pytorch_gradcam) (4.1.2.30)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_gradcam) (1.18.5)\n",
            "Building wheels for collected packages: pytorch-gradcam\n",
            "  Building wheel for pytorch-gradcam (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytorch-gradcam: filename=pytorch_gradcam-0.2.1-cp36-none-any.whl size=5270 sha256=b678febc6b2dfe393050678cbb37d40b75c9d49a32ff8e46ac87140b3232acdf\n",
            "  Stored in directory: /root/.cache/pip/wheels/e8/1e/35/d24150a078a90ce0ad093586814d4665e945466baa89907300\n",
            "Successfully built pytorch-gradcam\n",
            "Installing collected packages: pytorch-gradcam\n",
            "Successfully installed pytorch-gradcam-0.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCpsLgu6VvJ9",
        "colab_type": "text"
      },
      "source": [
        "#**Compute Saliency,Gradcam,Gradcam++ modules**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19Xgk5ZOUbTF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bdc4be31-7f80-4afa-d500-b576d43b0fc6"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "%cd fastcam\n",
        "\n",
        "#importing libraries \n",
        "\n",
        "\n",
        "from scipy import ndimage\n",
        "from skimage.transform import resize\n",
        "import yaml\n",
        "import os\n",
        "import torch\n",
        "import warnings\n",
        "import argparse\n",
        "import tensorflow as tf\n",
        "import math\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.utils.data\n",
        "from torch.utils.data import DataLoader,TensorDataset\n",
        "import copy\n",
        "import logging\n",
        "from keras.layers import Input\n",
        "from keras.layers.merge import concatenate\n",
        "import torch.nn as nn\n",
        "from torch.nn import BatchNorm3d,Conv3d,ReLU,MaxPool3d,Linear,AdaptiveAvgPool3d,Flatten,Softmax\n",
        "import torch.nn.functional as F\n",
        "from datetime import datetime\n",
        "from torch.utils import data\n",
        "import time\n",
        "\n",
        "import skimage.io as sio\n",
        "import shutil\n",
        "from random import shuffle\n",
        "from skimage.transform import resize\n",
        "import skimage.io as sio\n",
        "from scipy.io import savemat,loadmat\n",
        "import cv2\n",
        "import mask\n",
        "import draw\n",
        "import norm\n",
        "import misc\n",
        "\n",
        "from torchvision import models\n",
        "from random import shuffle\n",
        "from torchvision.utils import make_grid, save_image\n",
        "import pandas as pd\n",
        "from gradcam.utils import visualize_cam\n",
        "from gradcam import GradCAMpp, GradCAM\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_smoe_map(x,relu=False):\n",
        "\n",
        "  '''\n",
        "  Scaled map order equivalent map computation fumction:\n",
        "  reference from the saliency map paper : https://github.com/LLNL/fastcam.git and adapted/modified  to our usecase\n",
        "  '''\n",
        "  print(f' smoe input shape={x.shape}')\n",
        "  if relu:\n",
        "    x=tf.nn.relu(x).numpy()\n",
        "  print(f'x range={np.amax(x),np.amin(x)}')\n",
        "  \n",
        "  m   = np.mean(x,axis=-1)+0.0000001 \n",
        "  # m   = np.mean(x,axis=0)+0.0000001 #avoid log 0\n",
        "  \n",
        "  x   = x + 0.0000001\n",
        "  # k   = np.log2(m) - np.mean(np.log2(x), axis=0)\n",
        "  k   = np.log2(m) - np.mean(np.log2(x), axis=-1)\n",
        "  print(f'log of mean={np.log2(m)}, mean of log={np.mean(np.log2(x), axis=-1)}')\n",
        "  print(f'k={k}')\n",
        "  k   = k + 0.0000001\n",
        "  # k   = np.log10(m) - np.mean(np.log10(x), axis=-1)\n",
        "  print(np.array_equal(np.zeros(k.shape),k))\n",
        "  print(f'{x.shape,k.shape,np.amin(k)}')\n",
        "  print(f'kmax, kmin={np.min(k),np.max(k)}')\n",
        "  print(f'mean={m}')\n",
        "  th  = k * m\n",
        "  print(f'smoe map={th}')\n",
        "  print(f'smoe output shape={th.shape}')\n",
        "  return th\n",
        "\n",
        "def get_std_map(x):\n",
        "  '''\n",
        "  STD based map alternative to SMOE.\n",
        "  '''\n",
        "  print(f'before std map shape ={x.shape}')\n",
        "  m = np.std(x,axis=-1)\n",
        "\n",
        "  print(f'std map shape ={m.shape}')\n",
        "\n",
        "  return m\n",
        "\n",
        "def get_norm(x,const_mean=None,const_std=None):\n",
        "  '''\n",
        "  get norm refrence from the saliency map paper : https://github.com/LLNL/fastcam.git and adapted/modified  to our usecase\n",
        "  '''\n",
        "  s0      = x.shape[0]\n",
        "  s1      = x.shape[1]\n",
        "  s2      = x.shape[2]\n",
        "\n",
        "  # x       = np.reshape(x,(1,s0*s1))\n",
        "  x       = np.reshape(x,(1,s1*s2))\n",
        "  print(f'get norm func x after reshape={x.shape} ')\n",
        "\n",
        "  '''\n",
        "      Compute Mean\n",
        "  '''\n",
        "  if const_mean is None:\n",
        "      m       = np.mean(x,axis=1)\n",
        "      m       = np.reshape(m,(m.shape[0],1))\n",
        "  else:\n",
        "      m       = const_mean\n",
        "\n",
        "  print(f'get norm func x after mean reshape={m.shape} ') \n",
        "  '''\n",
        "      Compute Standard Deviation\n",
        "  '''\n",
        "  if const_std is None:\n",
        "      s       = np.std(x,axis=1)\n",
        "      s       = np.reshape(s,(s.shape[0],1))\n",
        "  else:\n",
        "      s       = const_std\n",
        "  \n",
        "  '''\n",
        "      The normal cumulative distribution function is used to squash the values from within the range of 0 to 1\n",
        "  '''\n",
        "\n",
        "  s=torch.tensor(s)\n",
        "  x       = 0.5*(1.0 + torch.erf((x-m)/(s*torch.sqrt(torch.tensor(2.0)))))\n",
        "  print(x.shape)    \n",
        "  # x       = x.reshape(1,s0,s1)\n",
        "  x       = x.reshape(1,s1,s2)\n",
        "\n",
        "  print(f'map after norm={x,x.shape}')\n",
        "  return x\n",
        "\n",
        "\n",
        "def combine_sal_maps(smaps,output_size,weights,map_num,resize_mode='bilinear',do_relu=False):\n",
        "  '''\n",
        "  Combined saliency maps are computed here .\n",
        "  '''\n",
        "  bn  = smaps[0].shape[0]\n",
        "  cm  = torch.zeros((bn, 1, output_size[0], output_size[1]), dtype=smaps[0].dtype, device=smaps[0].device)\n",
        "  ww  = []\n",
        "  \n",
        "  '''\n",
        "      Now get each saliency map and resize it. Then store it and also create a combined saliency map.\n",
        "  '''\n",
        "  for i in range(len(smaps)):\n",
        "   \n",
        "      wsz = smaps[i].shape\n",
        "      w   = np.reshape(smaps[i],(wsz[0], 1, wsz[1], wsz[2]))#smaps[i].reshape(wsz[0], 1, wsz[1], wsz[2])\n",
        "   \n",
        "      w   = nn.functional.interpolate(w, size=output_size, mode=resize_mode, align_corners=False) \n",
        "      ww.append(w)  \n",
        "      \n",
        "      cm  += (w * weights[i])\n",
        "\n",
        "  '''\n",
        "      Finish the combined saliency map to make it a weighted average.\n",
        "  '''\n",
        "  weight_sum =sum(weights)\n",
        "  cm  = cm / weight_sum\n",
        "  cm  = cm.reshape(bn, output_size[0],output_size[1])\n",
        "  \n",
        "  ww  = torch.stack(ww,dim=1)\n",
        "  ww  = ww.reshape(bn, map_num, output_size[0], output_size[1])\n",
        "  \n",
        "\n",
        "  \n",
        "  return cm, ww\n",
        "\n",
        "def compute_saliency_tf(base_path,inputs,tf_model):\n",
        "  '''\n",
        "   Saliency maps are computed for specicied layers and then combined\n",
        "  '''\n",
        "\n",
        "  gender=inputs[1]\n",
        "  gender=tf.reshape(gender,[1,1])\n",
        "  img=inputs[0]\n",
        "  img_chunk=tf.convert_to_tensor(img)\n",
        "  print(img_chunk.shape)\n",
        "  img_chunk = tf.reshape(img_chunk,[1,121,145,6])\n",
        "  layers=[layer.name for layer in tf_model.layers]\n",
        "  outputs=[]\n",
        "\n",
        "  #select all layer activations after conv for eg: if there ae 66 conv layers then there are 66 activation layers.\n",
        "  for l in layers:\n",
        "   \n",
        "    if l.startswith('activation'):\n",
        "    \n",
        "        outputs.append(tf_model.get_layer(name=l).output) \n",
        "\n",
        "  outputs.append(tf_model.output)                                         \n",
        "  test_tf_model=tf.keras.models.Model([tf_model.inputs], outputs)\n",
        " \n",
        "  predictions = test_tf_model([img_chunk,gender])\n",
        "\n",
        "  # Specify or experiment  with layers we want to compute saliency maps for.\n",
        "\n",
        "  # hooks=[predictions[0],predictions[1],predictions[2],predictions[8],predictions[14],predictions[20],predictions[23]\\\n",
        "  #        ,predictions[29],predictions[35],predictions[41],predictions[47],predictions[50],\\\n",
        "  #        predictions[56],predictions[62],predictions[65]]#predictions[:layer_end]\n",
        "  # hooks= [predictions[0],predictions[2],predictions[17],predictions[47],predictions[62]] \n",
        "\n",
        "\n",
        "  #these layers were picked as the outputs have diffrent scale dimensions,  we can experimentwith other layers as well.\n",
        "  hooks=[predictions[0],predictions[2],predictions[14],predictions[47],predictions[65]] \n",
        "  \n",
        "  # choose specific channels / filters\n",
        "  for x in hooks:\n",
        "    print('ouput shapes layerwise')\n",
        "    print(x.shape)\n",
        "\n",
        "  \n",
        "  # sal_maps       = [ get_norm(get_smoe_map(np.expand_dims(np.mean(x.numpy()[:,:,:,:,:],axis=-2)[:,:,:,2],axis=-1))) for x in hooks ]\n",
        "\n",
        "  #smoe saliency map\n",
        "  sal_maps       = [ get_norm(get_smoe_map(np.mean(x.numpy()[:,:,:,:,:],axis=-2))) for x in hooks ]\n",
        "\n",
        "  #std dev saliency maps\n",
        "  # sal_maps       = [ get_norm(get_std_map(np.mean(x.numpy()[:,:,:,:,:],axis=-2))) for x in hooks ]\n",
        "\n",
        "  \n",
        "  for smaps in sal_maps:\n",
        "    print(smaps.shape)\n",
        "\n",
        "  # sal_maps = [np.reshape(smaps.numpy(),(121,121)) for smaps in sal_maps]\n",
        "\n",
        "  # all layer scale maps with equal weightage\n",
        "  weights=np.ones(len(hooks))\n",
        "  \n",
        "  # all layer scale maps with progressive increasing weightage\n",
        "  # weights=[i+1 for i in range(len(hooks))]\n",
        "  # weights = [i for i in range(len(hooks),0,-1)]\n",
        "  \n",
        "  map_num=len(hooks)\n",
        "\n",
        "  f, axarr = plt.subplots(1,1,figsize=(10,10))\n",
        "  raw=np.mean(img_chunk[0,:,:,:],axis=-1)\n",
        "  raw= raw/np.max(raw)\n",
        "  r=axarr.imshow(raw,cmap='jet')\n",
        "  axarr.set_title('Input image mean along 3rd dimension')\n",
        "  plt.colorbar(r,fraction=0.01, pad=0.04)\n",
        "  plt.savefig(base_path+'mean_input_chunk.png')\n",
        "\n",
        "  csal_maps,sal_maps = combine_sal_maps(sal_maps,output_size=[in_height,in_width],weights=weights,map_num=map_num)\n",
        "  output_path = base_path +'Map_Combined.png'\n",
        "  f, axarr = plt.subplots(1,1,figsize=(10,10))\n",
        "  csal_map=csal_maps[0,:,:].numpy()\n",
        "  imcs=csal_map/np.max(csal_map)\n",
        "  im = axarr.imshow(imcs,cmap='jet')\n",
        "  axarr.set_title('Combined saliency map')\n",
        "  plt.colorbar(im,fraction=0.01, pad=0.04)\n",
        "  plt.savefig(output_path)\n",
        "\n",
        "  il = [sal_maps[0,i,:,:] for i in range(map_num)] # Put each saliency map into the figure\n",
        "  il.append(csal_maps[0,:,:])                       # add in the combined map at the end of the figure\n",
        "  images        = [torch.stack(il, 0)]          \n",
        "  images        = make_grid(images, nrow=5)\n",
        "  sal_img=images.unsqueeze(1)\n",
        "  output_path=base_path +'Sal_Maps.png'\n",
        "  save_image(sal_img,output_path)\n",
        "\n",
        "  input_path = output_path\n",
        "  f, axarr = plt.subplots(1,1,figsize=(10,10))\n",
        "  im=sio.imread(input_path)\n",
        "  im=axarr.imshow(np.mean(im,axis=-1)/255, cmap='jet');\n",
        "  axarr.set_title('layerwise saliency maps')\n",
        "  plt.colorbar(im,fraction=0.01, pad=0.04)\n",
        "  output_path=base_path +'Sal_Maps_jet.png'\n",
        "  plt.savefig(output_path)\n",
        "  return csal_maps\n",
        "\n",
        "\n",
        "\n",
        "def get_grads(layer_name,tf_model,inputs):\n",
        "  '''\n",
        "  computes gradients for GCAM/GCAM++\n",
        "  '''\n",
        "\n",
        "  cam_list=[]\n",
        "  gender= inputs[1] #check the gender tensor dimensions tf.constant([[1]],dtype=tf.float32)\n",
        "  gender=tf.reshape(gender,[1,1])\n",
        "  img=inputs[0]\n",
        "  grad_model = tf.keras.models.Model([tf_model.inputs], [tf_model.get_layer(name=layer_name).output, tf_model.output])\n",
        "\n",
        "  img_chunk=tf.convert_to_tensor(img)\n",
        "  img_chunk = tf.reshape(img_chunk,[1,121,145,6])\n",
        "\n",
        "  cdr_ohe_dict={0:[1.0,0.0,0.0,0.0],0.5:[0.0,1.0,0.0,0.0],1:[0.0,0.0,1.0,0.0],2:[0.0,0.0,0.0,1.0]}\n",
        "  cdr_keys= list(cdr_ohe_dict.keys())\n",
        "  with tf.GradientTape() as tape:\n",
        "      conv_outputs, predictions = grad_model([img_chunk,gender])\n",
        "      print(f'predictions={predictions}')\n",
        "      # loss=predictions\n",
        "      loss = predictions[0] # in case of an extra dimension [[]]\n",
        "     \n",
        "\n",
        "  output = conv_outputs[0]#[0,:,:,:,100]\n",
        "  print(f'entering tape gradients')\n",
        "\n",
        "  grads = tape.gradient(loss, conv_outputs)[0]#[0,:,:,:,100]\n",
        "  print(type(grads))\n",
        "  print(f'Crossed tape gradients')\n",
        "  gate_f = tf.cast(output > 0, 'float32')\n",
        "  gate_r = tf.cast(grads > 0, 'float32')\n",
        "  # now there are 2 choice either use grads(raw grads) or use guided grads)\n",
        "  guided_grads = tf.cast(output > 0, 'float32') * tf.cast(grads > 0, 'float32') * grads\n",
        "\n",
        "  print(f'Entering reduce mean using guided_grads with shape={guided_grads.shape}')\n",
        "  #guided grads\n",
        "  weights = tf.reduce_mean(guided_grads, axis=(0,1,2))\n",
        "\n",
        "\n",
        "  print(f'Computing CAM using output with shape:{output.shape}')\n",
        "\n",
        "  print(f'weights={weights.shape}')\n",
        "  cam = np.zeros(output.shape[0:3], dtype=np.float32)\n",
        "  print(cam.shape)\n",
        "\n",
        "\n",
        "  cam=tf.reduce_sum(tf.multiply(output,weights),axis=-1)\n",
        "  cam_list.append(cam)\n",
        "  return cam_list,grads,loss,weights,output,img_chunk\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def compute_gcam_and_gcam_pp(layer_name,model,inputs):\n",
        "  '''\n",
        "  Generates GCAM/GCAM++\n",
        "  '''\n",
        "  cam_list,grads,loss,weights,output,img_chunk = get_grads(layer_name,model,inputs)\n",
        "  \n",
        "  heatmap_list=[]\n",
        "  for i,cam in enumerate(cam_list):#as we are doing chunk wise so this camlist will have only one cam\n",
        "\n",
        "    print(f'cam shape={cam.shape}')\n",
        "    \n",
        "    #gcam\n",
        "    cam_map=resize(cam,(img_chunk.shape[1],img_chunk.shape[2],img_chunk.shape[3]))\n",
        "\n",
        "    cam_map = np.maximum(cam_map,0)\n",
        "    original_image=img_chunk.numpy()\n",
        "   \n",
        "    heatmap = (cam_map - cam_map.min()) / (cam_map.max() - cam_map.min())\n",
        "\n",
        "  \n",
        "    print(original_image.shape)\n",
        "    image=np.mean(original_image[0,:,:,:],axis=-1)\n",
        "    print(image.shape)\n",
        "\n",
        "    mri_img=image#np.squeeze(image)\n",
        "    heatmap_list.append(heatmap)\n",
        "\n",
        "\n",
        "    heatmap_gcam = (cam_map - cam_map.min()) / (cam_map.max() - cam_map.min())\n",
        "\n",
        "      \n",
        "      \n",
        "    gcam_img=(np.mean(heatmap_gcam,axis=-1)* 255).astype(\"uint8\")\n",
        "   \n",
        "    #gcam++\n",
        "    print(f'grads shape ={grads.shape},tf.exp(loss) shape={tf.exp(loss).shape}')\n",
        "    conv_first_grad = tf.exp(loss)[0]*grads\n",
        "    #second_derivative\n",
        "    conv_second_grad = tf.exp(loss)[0]*grads*grads\n",
        "    #triple_derivative\n",
        "    conv_third_grad = tf.exp(loss)[0]*grads*grads*grads\n",
        "    \n",
        "    global_sum = np.sum(tf.reshape(output,(-1,conv_first_grad[0].shape[2])), axis=0)\n",
        "    print(f'conv_first_grad shape={conv_first_grad.shape},conv_second_grad shape={conv_second_grad.shape} ,  conv_third_grad shape={conv_third_grad.shape}, global_sum.shape={global_sum.shape}  ')\n",
        "    alpha_num = conv_second_grad[0]\n",
        "    # alpha_denom = conv_second_grad[0]*2.0 + conv_third_grad[0]*global_sum.reshape((1,1,conv_first_grad[0].shape[2]))\n",
        "    alpha_denom = conv_second_grad*2.0 + conv_third_grad*global_sum.reshape((1,1,1,conv_first_grad[0].shape[2]))\n",
        "    alpha_denom = np.where(alpha_denom != 0.0, alpha_denom, np.ones(alpha_denom.shape))\n",
        "    alphas = alpha_num/alpha_denom\n",
        "\n",
        "    \n",
        "\n",
        "    alphas_thresholding = np.where(weights, alphas, 0.0)\n",
        "    print(f'alphas_thresholding shape={alphas_thresholding.shape}')\n",
        "    alpha_normalization_constant = np.sum(np.sum(alphas_thresholding, axis=0),axis=0)\n",
        "    alpha_normalization_constant_processed = np.where(alpha_normalization_constant != 0.0, alpha_normalization_constant, np.ones(alpha_normalization_constant.shape))\n",
        "    print(f'alpha_normalization_constant_processed shape={alpha_normalization_constant_processed.shape}')\n",
        "    \n",
        "    # alphas /= alpha_normalization_constant_processed.reshape((1,1,conv_first_grad[0].shape[2]))\n",
        "    alphas /= alpha_normalization_constant_processed.reshape((1,1,3,conv_first_grad[0].shape[2]))\n",
        "    print(f'weights.shape={weights.shape},alphas.shape={alphas.shape}')\n",
        "    weights_alpha=tf.reduce_sum(tf.multiply(weights,alphas),axis=0)\n",
        "    \n",
        "    cam=tf.reduce_sum(tf.multiply(output,weights_alpha),axis=-1)\n",
        "    \n",
        "    cam_map=resize(cam,(img_chunk.shape[1],img_chunk.shape[2],img_chunk.shape[3]))\n",
        "  \n",
        "    \n",
        "    print(f'cam_map={cam_map.shape}')\n",
        "    cam_map = np.maximum(cam_map, 0)\n",
        "\n",
        "    heatmap_gcam_pp = (cam_map - cam_map.min()) / (cam_map.max() - cam_map.min())\n",
        "\n",
        "\n",
        "    gcam_pp_img=(np.mean(heatmap_gcam_pp,axis=-1) * 255).astype(\"uint8\")\n",
        "    \n",
        "    print(img_chunk.shape,mri_img.shape,gcam_img.shape,type(mri_img),type(gcam_img))\n",
        "  \n",
        "        \n",
        "    return image, gcam_img,gcam_pp_img\n",
        "\n",
        "def combine_sal_gcam(base_path,csmap,gcam_img,gcam_pp_img,image,layer_name,angle,result_path ):\n",
        "\n",
        "  '''\n",
        "\n",
        "  3 kinds of map computed : saliency map , saliency map combined  with GCAM, saliency map combined with GCAM++ \n",
        "  '''\n",
        "  print(gcam_img.shape,csmap.shape,gcam_pp_img.shape,image.shape)\n",
        "  #saliency map\n",
        "\n",
        "  raw_tensor=torch.from_numpy(image).unsqueeze(0)\n",
        "  heatmap_csmap, result_csmap = visualize_cam(csmap, raw_tensor)\n",
        "  getMask                 = mask.SaliencyMaskDropout(keep_percent = 0.1, scale_map=False)\n",
        "  hard_masked_csmap,_       = getMask(raw_tensor.unsqueeze(0),csmap)#.squeeze(0))\n",
        "  hard_masked_csmap        = hard_masked_csmap.squeeze(0)\n",
        "  masked_csmap             = misc.AlphaMask(raw_tensor, csmap.squeeze(0)).squeeze(0)\n",
        "  \n",
        "\n",
        "  vmin=0\n",
        "  vmax=1.0\n",
        "  f, axarr = plt.subplots(2,3,figsize=(20,20))\n",
        "  img_plot = axarr[0][0].imshow(torch.mean(raw_tensor,axis=0),vmin=vmin,vmax=vmax, cmap='jet');\n",
        "  axarr[0][0].set_title('input')\n",
        "  cbar=plt.colorbar(img_plot,fraction=0.046, pad=0.04,ax=axarr[0][0])\n",
        "  cbar.set_clim(0,1)\n",
        "  img_plot = axarr[0][1].imshow(torch.mean(csmap,axis=0),vmin=vmin,vmax=vmax, cmap='jet');\n",
        "  axarr[0][1].set_title('combined saliency map')\n",
        "  cbar=plt.colorbar(img_plot,fraction=0.046, pad=0.04,ax=axarr[0][1])\n",
        "  cbar.set_clim(0,1)\n",
        "  img_plot = axarr[0][2].imshow(torch.mean(heatmap_csmap,axis=0),vmin=vmin,vmax=vmax, cmap='jet');\n",
        "  axarr[0][2].set_title('saliency map')\n",
        "  cbar=plt.colorbar(img_plot,fraction=0.046, pad=0.04,ax=axarr[0][2])\n",
        "  cbar.set_clim(0,1)\n",
        "  img_plot = axarr[1][0].imshow(torch.mean(result_csmap,axis=0),vmin=vmin,vmax=vmax, cmap='jet');\n",
        "  axarr[1][0].set_title('saliency map with alpha blend')\n",
        "  cbar=plt.colorbar(img_plot,fraction=0.046, pad=0.04,ax=axarr[1][0])\n",
        "  cbar.set_clim(0,1)\n",
        "  img_plot = axarr[1][1].imshow(masked_csmap,vmin=vmin,vmax=vmax, cmap='jet');\n",
        "  axarr[1][1].set_title('mask')\n",
        "  cbar=plt.colorbar(img_plot,fraction=0.046, pad=0.04,ax=axarr[1][1])\n",
        "  cbar.set_clim(0,1)\n",
        "  img_plot = axarr[1][2].imshow(hard_masked_csmap[0],vmin=vmin,vmax=vmax, cmap='jet');\n",
        "  axarr[1][2].set_title('hard mask')\n",
        "  cbar=plt.colorbar(img_plot,fraction=0.046, pad=0.04,ax=axarr[1][2])\n",
        "  cbar.set_clim(0,1)\n",
        "  plt.savefig(base_path+'saliency_only_fig.png')\n",
        "\n",
        "  print(hard_masked_csmap.permute([2,0,1]).shape)\n",
        "  csmap_img = torch.mean(csmap,axis=0).numpy()\n",
        "  output_path   = base_path+\"csmap.png\"\n",
        "  savemat(output_path.split('.png')[0] +'.mat',{'data':csmap_img ,'shape':csmap_img.shape})\n",
        "  output_path   = base_path+\"heatmap_csmap.png\"\n",
        "  savemat(output_path.split('.png')[0] +'.mat',{'data':heatmap_csmap.permute([1,2,0]).numpy() ,'shape':heatmap_csmap.permute([1,2,0]).numpy().shape})\n",
        "  output_path   = base_path+\"result_csmap.png\"\n",
        "  savemat(output_path.split('.png')[0] +'.mat',{'data':result_csmap.permute([1,2,0]).numpy() ,'shape':result_csmap.permute([1,2,0]).numpy().shape})\n",
        "  output_path   = base_path+\"hard_masked_csmap.png\" \n",
        "  savemat(output_path.split('.png')[0] +'.mat',{'data':hard_masked_csmap.permute([1,2,0]).numpy() ,'shape':hard_masked_csmap.permute([1,2,0]).shape})\n",
        "  output_path   = base_path+\"masked_csmap.mat\" \n",
        "  savemat(output_path,{'data':masked_csmap.numpy() ,'shape':masked_csmap.numpy().shape})\n",
        "  masked_csmap_mat = loadmat(output_path)['data']\n",
        "  plt.clf()\n",
        "  p=plt.imshow(masked_csmap_mat,cmap='jet')\n",
        "  plt.colorbar(p)      \n",
        "  plt.clim(0.8,1)\n",
        "  output_path   = base_path+\"masked_csmap_0.8.png\" \n",
        "  plt.savefig(output_path)\n",
        "\n",
        "  #gcam\n",
        "\n",
        "  if np.max(gcam_img) ==0:\n",
        "    gcam_img = gcam_img+0.0000001\n",
        "  if np.max(gcam_pp_img) ==0:\n",
        "    gcam_pp_img = gcam_pp_img+0.0000001\n",
        "  gcam_img_tensor=torch.from_numpy(gcam_img).unsqueeze(0)\n",
        "  mask_gcam = csmap*(gcam_img_tensor)\n",
        "  mask_gcam=mask_gcam/mask_gcam.max()\n",
        "  \n",
        "\n",
        "  \n",
        "\n",
        "  heatmap_gcam, result_gcam = visualize_cam(mask_gcam, raw_tensor)\n",
        "  getMask                 = mask.SaliencyMaskDropout(keep_percent = 0.1, scale_map=False)\n",
        "  hard_masked_gcam,_       = getMask(raw_tensor.unsqueeze(0),mask_gcam)#.squeeze(0))\n",
        "  hard_masked_gcam        = hard_masked_gcam.squeeze(0)\n",
        "  masked_gcam             = misc.AlphaMask(raw_tensor, mask_gcam.squeeze(0)).squeeze(0)\n",
        "  mx= str(np.max(masked_gcam.numpy()))\n",
        "  plt.imsave(base_path+'masked_gcam_unnormalized_{0}max.png'.format(mx),masked_gcam.numpy(),cmap='jet')\n",
        "  # masked_gcam              = misc.RangeNormalize(masked_gcam)\n",
        "\n",
        "\n",
        "  #gcam++\n",
        "  gcam_pp_img_tensor=torch.from_numpy(gcam_pp_img).unsqueeze(0)\n",
        "  mask_gcam_pp = csmap*(gcam_pp_img_tensor)\n",
        "  mask_gcam_pp=mask_gcam_pp/mask_gcam_pp.max()\n",
        "  raw_tensor=torch.from_numpy(image).unsqueeze(0)\n",
        "  heatmap_gcam_pp, result_gcam_pp = visualize_cam(mask_gcam_pp, raw_tensor)\n",
        "\n",
        "  hard_masked_gcam_pp,_       = getMask(raw_tensor.unsqueeze(0),mask_gcam_pp)#.squeeze(0))\n",
        "  hard_masked_gcam_pp         = hard_masked_gcam_pp.squeeze(0)\n",
        "  masked_gcam_pp           = misc.AlphaMask(raw_tensor, mask_gcam_pp.squeeze(0)).squeeze(0)\n",
        "  mx= str(np.max(masked_gcam_pp.numpy()))\n",
        "  plt.imsave(base_path+'masked_gcam_pp_unnormalized_{0}max.png'.format(mx),masked_gcam_pp.numpy(),cmap='jet')\n",
        "  # masked_gcam_pp           = misc.RangeNormalize(masked_gcam_pp) # avoid this step as it will normalize to 0 to 1 hence not good while comparing multiple scans\n",
        "\n",
        "\n",
        "  #\n",
        "  output_path   = base_path+\"raw_img.mat\"\n",
        "  savemat(output_path,{'data':raw_tensor.numpy() ,'shape':raw_tensor.shape})\n",
        "  background_img=loadmat(output_path)['data']\n",
        "\n",
        "  base_path+='_'+layer_name\n",
        "\n",
        "  #save gcam and gcam++ fig\n",
        "  vmin=np.amin([np.min(gcam_img),np.min(gcam_pp_img)])\n",
        "  vmax=np.amax([np.max(gcam_img),np.max(gcam_pp_img)])\n",
        "\n",
        "  f, axarr = plt.subplots(1,2,figsize=(10,10))\n",
        "  img_plot = axarr[0].imshow(gcam_img,vmin=vmin,vmax=vmax, cmap='jet');\n",
        "  axarr[0].set_title('Gradcam')\n",
        "  img_plot = axarr[1].imshow(gcam_pp_img,vmin=vmin,vmax=vmax, cmap='jet');\n",
        "  axarr[1].set_title('Gradcam++')\n",
        "  plt.colorbar(img_plot,fraction=0.046, pad=0.04)\n",
        "  plt.savefig(base_path+'gcam_gcam++_fig.png')\n",
        "  \n",
        "  \n",
        "  #gcam\n",
        "\n",
        "  # vmin=np.amin([torch.min(raw_tensor),torch.min(csmap),torch.min(heatmap_gcam),torch.min(result_gcam),torch.min(masked_gcam),torch.min(hard_masked_gcam)])\n",
        "  # vmax=np.amax([torch.max(raw_tensor),torch.max(csmap),torch.max(heatmap_gcam),torch.max(result_gcam),torch.max(masked_gcam),torch.max(hard_masked_gcam)])\n",
        "  vmin=0\n",
        "  vmax=1.0\n",
        "  f, axarr = plt.subplots(2,3,figsize=(20,20))\n",
        "  img_plot = axarr[0][0].imshow(torch.mean(raw_tensor,axis=0),vmin=vmin,vmax=vmax, cmap='jet');\n",
        "  axarr[0][0].set_title('input')\n",
        "  cbar=plt.colorbar(img_plot,fraction=0.046, pad=0.04,ax=axarr[0][0])\n",
        "  cbar.set_clim(0,1)\n",
        "  img_plot = axarr[0][1].imshow(torch.mean(csmap,axis=0),vmin=vmin,vmax=vmax, cmap='jet');\n",
        "  axarr[0][1].set_title('combined saliency map')\n",
        "  cbar=plt.colorbar(img_plot,fraction=0.046, pad=0.04,ax=axarr[0][1])\n",
        "  cbar.set_clim(0,1)\n",
        "  img_plot = axarr[0][2].imshow(torch.mean(heatmap_gcam,axis=0),vmin=vmin,vmax=vmax, cmap='jet');\n",
        "  axarr[0][2].set_title('saliency map + gradcam')\n",
        "  cbar=plt.colorbar(img_plot,fraction=0.046, pad=0.04,ax=axarr[0][2])\n",
        "  cbar.set_clim(0,1)\n",
        "  img_plot = axarr[1][0].imshow(torch.mean(result_gcam,axis=0),vmin=vmin,vmax=vmax, cmap='jet');\n",
        "  axarr[1][0].set_title('saliency map+gradcam with alpha blend')\n",
        "  cbar=plt.colorbar(img_plot,fraction=0.046, pad=0.04,ax=axarr[1][0])\n",
        "  cbar.set_clim(0,1)\n",
        "  img_plot = axarr[1][1].imshow(masked_gcam,vmin=vmin,vmax=vmax, cmap='jet');\n",
        "  axarr[1][1].set_title('mask')\n",
        "  cbar=plt.colorbar(img_plot,fraction=0.046, pad=0.04,ax=axarr[1][1])\n",
        "  cbar.set_clim(0,1)\n",
        "  img_plot = axarr[1][2].imshow(hard_masked_gcam[0],vmin=vmin,vmax=vmax, cmap='jet');\n",
        "  axarr[1][2].set_title('hard mask')\n",
        "  cbar=plt.colorbar(img_plot,fraction=0.046, pad=0.04,ax=axarr[1][2])\n",
        "  cbar.set_clim(0,1)\n",
        "  plt.savefig(base_path+'sal+gcam_fig.png')\n",
        "\n",
        "  print(hard_masked_gcam.permute([2,0,1]).shape)\n",
        "  output_path   = base_path+\"gcam_img.png\"\n",
        "  savemat(output_path.split('.png')[0] +'.mat',{'data':gcam_img ,'shape':gcam_img.shape})\n",
        "  output_path   = base_path+\"heatmap_gcam.png\"\n",
        "  savemat(output_path.split('.png')[0] +'.mat',{'data':heatmap_gcam.permute([1,2,0]).numpy() ,'shape':heatmap_gcam.permute([1,2,0]).numpy().shape})\n",
        "  output_path   = base_path+\"result_gcam.png\"\n",
        "  savemat(output_path.split('.png')[0] +'.mat',{'data':result_gcam.permute([1,2,0]).numpy() ,'shape':result_gcam.permute([1,2,0]).numpy().shape})\n",
        "  output_path   = base_path+\"hard_masked_gcam.png\" \n",
        "  savemat(output_path.split('.png')[0] +'.mat',{'data':hard_masked_gcam.permute([1,2,0]).numpy() ,'shape':hard_masked_gcam.permute([1,2,0]).shape})\n",
        "  output_path   = base_path+\"masked_gcam.mat\" \n",
        "  savemat(output_path,{'data':masked_gcam.numpy() ,'shape':masked_gcam.numpy().shape})\n",
        "  masked_gcam_mat = loadmat(output_path)['data']\n",
        "  plt.clf()\n",
        "  p=plt.imshow(masked_gcam_mat,cmap='jet')\n",
        "  plt.colorbar(p)      \n",
        "  plt.clim(0.8,1)\n",
        "  output_path   = base_path+\"masked_gcam_0.8.png\" \n",
        "  plt.savefig(output_path)\n",
        "  \n",
        "  #gcam_pp\n",
        "  vmin=np.amin([torch.min(raw_tensor),torch.min(csmap),torch.min(heatmap_gcam_pp),torch.min(result_gcam_pp),torch.min(masked_gcam_pp),torch.min(hard_masked_gcam_pp)])\n",
        "  vmax=np.amax([torch.max(raw_tensor),torch.max(csmap),torch.max(heatmap_gcam_pp),torch.max(result_gcam_pp),torch.max(masked_gcam_pp),torch.max(hard_masked_gcam_pp)])\n",
        "\n",
        "  vmin=0\n",
        "  vmax=1.0\n",
        "\n",
        "  f, axarr = plt.subplots(2,3,figsize=(20,20))\n",
        "  img_plot = axarr[0][0].imshow(torch.mean(raw_tensor,axis=0),vmin=vmin,vmax=vmax, cmap='jet');\n",
        "  axarr[0][0].set_title('input')\n",
        "  cbar=plt.colorbar(img_plot,fraction=0.046, pad=0.04,ax=axarr[0][0])\n",
        "  cbar.set_clim(0,1)\n",
        "  img_plot = axarr[0][1].imshow(torch.mean(csmap,axis=0),vmin=vmin,vmax=vmax, cmap='jet');\n",
        "  axarr[0][1].set_title('combined saliency map')\n",
        "  cbar=plt.colorbar(img_plot,fraction=0.046, pad=0.04,ax=axarr[0][1])\n",
        "  cbar.set_clim(0,1)\n",
        "  img_plot = axarr[0][2].imshow(torch.mean(heatmap_gcam_pp,axis=0),vmin=vmin,vmax=vmax, cmap='jet');\n",
        "  axarr[0][2].set_title('saliency map + gradcam++')\n",
        "  cbar=plt.colorbar(img_plot,fraction=0.046, pad=0.04,ax=axarr[0][2])\n",
        "  cbar.set_clim(0,1)\n",
        "  img_plot = axarr[1][0].imshow(torch.mean(result_gcam_pp,axis=0),vmin=vmin,vmax=vmax, cmap='jet');\n",
        "  axarr[1][0].set_title('saliency map+gradcam++ with alpha blend')\n",
        "  cbar=plt.colorbar(img_plot,fraction=0.046, pad=0.04,ax=axarr[1][0])\n",
        "  cbar.set_clim(0,1)\n",
        "  img_plot = axarr[1][1].imshow(masked_gcam_pp,vmin=vmin,vmax=vmax, cmap='jet');\n",
        "  axarr[1][1].set_title('mask')\n",
        "  cbar=plt.colorbar(img_plot,fraction=0.046, pad=0.04,ax=axarr[1][1])\n",
        "  cbar.set_clim(0,1)\n",
        "  img_plot = axarr[1][2].imshow(hard_masked_gcam_pp[0],vmin=vmin,vmax=vmax, cmap='jet');\n",
        "  axarr[1][2].set_title('hard mask')\n",
        "  cbar=plt.colorbar(img_plot,fraction=0.046, pad=0.04,ax=axarr[1][2])\n",
        "  cbar.set_clim(0,1)\n",
        "  plt.savefig(base_path+'sal+gcam++_fig.png')\n",
        "\n",
        "\n",
        "  raw_img = torch.mean(raw_tensor,axis=0).numpy()\n",
        "  output_path   = base_path+\"raw_input.png\"\n",
        "  savemat(output_path.split('.png')[0] +'.mat',{'data':raw_img ,'shape':raw_img.shape})\n",
        "\n",
        "  f, axarr = plt.subplots(1,1,figsize=(10,10))\n",
        "  \n",
        "  r=axarr.imshow(raw_img,cmap='gray')\n",
        "  axarr.set_title('raw gray image')\n",
        "  cbar=plt.colorbar(r,fraction=0.046, pad=0.04)\n",
        "  cbar.set_clim(0,1)\n",
        "  plt.savefig(base_path+'raw_gray_cbar.png')\n",
        "\n",
        "  \n",
        "  output_path   = base_path+\"gcam_pp_img.png\"\n",
        "  savemat(output_path.split('.png')[0] +'.mat',{'data':gcam_pp_img ,'shape':gcam_pp_img.shape})\n",
        "  output_path   = base_path+\"heatmap_gcam_pp.png\"\n",
        "  savemat(output_path.split('.png')[0] +'.mat',{'data':heatmap_gcam_pp.permute([1,2,0]).numpy() ,'shape':heatmap_gcam_pp.permute([1,2,0]).numpy().shape})\n",
        "  output_path   = base_path+\"result_gcam_pp.png\"\n",
        "  savemat(output_path.split('.png')[0] +'.mat',{'data':result_gcam_pp.permute([1,2,0]).numpy() ,'shape':result_gcam_pp.permute([1,2,0]).numpy().shape})\n",
        "  output_path   = base_path+\"hard_masked_gcam_pp.png\" \n",
        "  savemat(output_path.split('.png')[0] +'.mat',{'data':hard_masked_gcam_pp.permute([1,2,0]).numpy() ,'shape':hard_masked_gcam_pp.permute([1,2,0]).numpy().shape})\n",
        "  output_path   = base_path+\"masked_gcam_pp.mat\" \n",
        "  savemat(output_path,{'data':masked_gcam_pp.numpy() ,'shape':masked_gcam_pp.numpy().shape})\n",
        "  masked_gcam_pp_mat = loadmat(output_path)['data']\n",
        "  plt.clf()\n",
        "  # p=plt.imshow(masked_gcam_pp_mat,cmap='jet')\n",
        "  # plt.colorbar(p)      \n",
        "  # plt.clim(0.8,1)\n",
        "  # output_path   = base_path+\"masked_gcam_pp_0.8.png\" \n",
        "  # plt.savefig(output_path)\n",
        "  \n",
        "\n",
        "  im=ndimage.rotate(masked_gcam_pp_mat,angle)\n",
        "  max=1\n",
        "  im = im/max #optional step as in our case max is 1 also use any contant val.\n",
        "\n",
        "  im[im<0.3]=np.nan\n",
        "  plt.imshow(im,cmap='jet')\n",
        "  plt.axis('off')\n",
        "  plt.clim(0,1)\n",
        "  plt.savefig(result_path+'_result.png')\n",
        "\n",
        "  \n",
        "  ##############################################################################\n",
        "  '''\n",
        "  These are the images used in the final results the ones inside result_path\n",
        "  '''\n",
        "  plt.clf() # clear existing figure\n",
        "  #mask overlaid on gray matter\n",
        "  print(f'background shape before={background_img.shape}')\n",
        "  im2=background_img[0]\n",
        "  print(f'background shape after={im2.shape}')\n",
        "  im2=ndimage.rotate(im2,angle)\n",
        "  im2=1-im2\n",
        "  gray=plt.imshow(im2,cmap='gray')\n",
        "  plt.axis('off')\n",
        "  im=ndimage.rotate(masked_gcam_pp_mat,angle)\n",
        "  im[im<0.3]=np.nan\n",
        "  heat=plt.imshow(im,cmap='jet')\n",
        "  plt.axis('off')\n",
        "  plt.clim(0,1)\n",
        "  plt.colorbar()\n",
        "  plt.savefig(result_path+'_result_overlay.png')\n",
        "\n",
        "  ##############################################################################\n",
        " \n",
        "\n",
        " ## Below section to experiment different masking thresholds\n",
        "\n",
        "\n",
        "  ## Saliency only\n",
        "  masked_csmap=masked_csmap.numpy()\n",
        "\n",
        "  t='masked_only_saliency'\n",
        "\n",
        "\n",
        "\n",
        "  max =  1 #or use any other constant\n",
        "  \n",
        "  frac=0.3\n",
        "  r1=(masked_csmap/max)\n",
        "\n",
        "  r1[np.where(r1<frac*np.max(r1))]=0\n",
        "  # r1[np.where(r1<np.median(r1))]=0\n",
        "  plt.imsave(base_path+'nodiff_{0}_{1}.png'.format(frac,t),r1,cmap='jet')\n",
        "  \n",
        "\n",
        "  # frac=0.5\n",
        "  # r1=(masked_csmap/max)\n",
        "\n",
        "  # r1[np.where(r1<frac*np.max(r1))]=0\n",
        "  # # r1[np.where(r1<np.median(r1))]=0\n",
        "  # plt.imsave(base_path+'nodiff_{0}_{1}.png'.format(frac,t),r1,cmap='jet')\n",
        "\n",
        "  \n",
        "\n",
        "  # frac=0.8\n",
        "  # r1=(masked_csmap/max)\n",
        "\n",
        "  # r1[np.where(r1<frac*np.max(r1))]=0\n",
        "  # # r1[np.where(r1<np.median(r1))]=0\n",
        "  # plt.imsave(base_path+'nodiff_{0}_{1}.png'.format(frac,t),r1,cmap='jet')\n",
        "\n",
        "\n",
        "  ## GCAM\n",
        "  masked_gcam=masked_gcam.numpy()\n",
        "\n",
        "  \n",
        "\n",
        "  t='masked_gcam'\n",
        "\n",
        "  max =  1 #np.amax(masked_gcam)\n",
        "\n",
        "  frac=0.3\n",
        "  r1=(masked_gcam/max)\n",
        "\n",
        "  r1[np.where(r1<frac*np.max(r1))]=0\n",
        "  # r1[np.where(r1<np.median(r1))]=0\n",
        "  plt.imsave(base_path+'nodiff_{0}_{1}.png'.format(frac,t),r1,cmap='jet')\n",
        "\n",
        "\n",
        "  # frac=0.5\n",
        "  # r1=(masked_gcam/max)\n",
        "\n",
        "  # r1[np.where(r1<frac*np.max(r1))]=0\n",
        "  # # r1[np.where(r1<np.median(r1))]=0\n",
        "  # plt.imsave(base_path+'nodiff_{0}_{1}.png'.format(frac,t),r1,cmap='jet')\n",
        "\n",
        "  \n",
        "\n",
        "  # frac=0.8\n",
        "  # r1=(masked_gcam/max)\n",
        "\n",
        "  # r1[np.where(r1<frac*np.max(r1))]=0\n",
        "  # # r1[np.where(r1<np.median(r1))]=0\n",
        "  # plt.imsave(base_path+'nodiff_{0}_{1}.png'.format(frac,t),r1,cmap='jet')\n",
        "\n",
        "  ## GCAM++\n",
        "  ## fraction mask  map for overlaying GCAM++\n",
        "  masked_gcam_pp=masked_gcam_pp.numpy()\n",
        "\n",
        "  \n",
        "\n",
        "  t='masked_gcam_pp'\n",
        "  max = 1 #np.amax(masked_gcam_pp)\n",
        "\n",
        "  frac=0.3\n",
        "  r1=(masked_gcam_pp/max)\n",
        "\n",
        "  r1[np.where(r1<frac*np.max(r1))]=0\n",
        "  # r1[np.where(r1<np.median(r1))]=0\n",
        "  plt.imsave(base_path+'nodiff_{0}_{1}.png'.format(frac,t),r1,cmap='jet')\n",
        "  \n",
        "  # frac=0.5\n",
        "  # r1=(masked_gcam_pp/max)\n",
        "\n",
        "\n",
        "\n",
        "  # r1[np.where(r1<frac*np.max(r1))]=0\n",
        "  # # r1[np.where(r1<np.median(r1))]=0\n",
        "  # plt.imsave(base_path+'nodiff_{0}_{1}.png'.format(frac,t),r1,cmap='jet')\n",
        "\n",
        "  \n",
        "\n",
        "  # frac=0.8\n",
        "  # r1=(masked_gcam_pp/max)\n",
        "\n",
        "  # r1[np.where(r1<frac*np.max(r1))]=0\n",
        "  # # r1[np.where(r1<np.median(r1))]=0\n",
        "  # plt.imsave(base_path+'nodiff_{0}_{1}.png'.format(frac,t),r1,cmap='jet')\n",
        "\n",
        "  ##\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/fastcam\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-gWgUmHBPYo",
        "colab_type": "text"
      },
      "source": [
        "# **Tf records loading and parsing utility**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87R0vSUNBOVI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_selected_scan_from_subjects(data_path,subject_ids,label_df,selected_scans):\n",
        "    '''\n",
        "    Same as get_scan_from_subjects in case we need specific scan path and not all scans of a patient.\n",
        "    '''\n",
        "    scans=[]\n",
        "    labels=[]\n",
        "    gender=[]\n",
        "    cdr=[]\n",
        "    ids=[]\n",
        "    subject_ids = set(subject_ids)\n",
        "    for subject in subject_ids :\n",
        "        path=os.path.join(data_path,subject)\n",
        "        paths=os.listdir(path)\n",
        "\n",
        "        ids.extend([scan_id.split('.')[0] for scan_id in paths  if scan_id.split('/')[-1].split('.')[0] in selected_scans ])\n",
        "        scans.extend([ os.path.join(path,scan_id) for scan_id in paths   if scan_id.split('/')[-1].split('.')[0] in selected_scans ])\n",
        "        \n",
        "    \n",
        "        labels.extend([label_df[label_df['MRI ID']==scan_id.split('.')[0]]['Age'].to_list()[0] for scan_id in paths   if scan_id.split('/')[-1].split('.')[0] in selected_scans ])\n",
        "        gender.extend([label_df[label_df['MRI ID']==scan_id.split('.')[0]]['M/F'].to_list()[0] for scan_id in paths   if scan_id.split('/')[-1].split('.')[0] in selected_scans])\n",
        "        cdr.extend([label_df[label_df['MRI ID']==scan_id.split('.')[0]]['CDR'].to_list()[0] for scan_id in paths  if scan_id.split('/')[-1].split('.')[0] in selected_scans])\n",
        "\n",
        "    return scans,labels,gender,ids,cdr\n",
        "\n",
        "def get_scan_from_subjects(data_path,subject_ids,label_df):\n",
        "    '''\n",
        "    Scan paths,cdr,gender,labels  of subjects .\n",
        "    '''\n",
        "    scans=[]\n",
        "    labels=[]\n",
        "    gender=[]\n",
        "    cdr=[]\n",
        "    ids=[]\n",
        "    subject_ids = set(subject_ids)\n",
        "    for subject in subject_ids :\n",
        "        path=os.path.join(data_path,subject)\n",
        "        paths=os.listdir(path)\n",
        "        ids.extend([scan_id.split('.')[0] for scan_id in paths ])\n",
        "        scans.extend([ os.path.join(path,scan_path) for scan_path in paths  ])\n",
        " \n",
        "        labels.extend([label_df[label_df['MRI ID']==scan_id.split('.')[0]]['Age'].to_list()[0] for scan_id in paths   ])\n",
        "        gender.extend([label_df[label_df['MRI ID']==scan_id.split('.')[0]]['M/F'].to_list()[0] for scan_id in paths  ])\n",
        "        cdr.extend([label_df[label_df['MRI ID']==scan_id.split('.')[0]]['CDR'].to_list()[0] for scan_id in paths ])\n",
        "    #print(labels,gender)\n",
        "           \n",
        "    # shuffle(scans)\n",
        "    \n",
        "    return scans,labels,gender,ids,cdr\n",
        "\n",
        "\n",
        "def get_test_files(label_path,data_path,debug_mode_subject=None,selected_scans=[]):\n",
        "    '''\n",
        "    Primary function to get scans.\n",
        "    '''\n",
        "\n",
        "    data = pd.read_csv(label_path)\n",
        "    data = data.rename(columns={'MR ID':'MRI ID'})\n",
        "    data['M/F'] = encode_gender(data)\n",
        "    if debug_mode_subject is None:\n",
        "      test_ids = os.listdir(data_path)\n",
        "    else:\n",
        "      test_ids=debug_mode_subject\n",
        "    \n",
        "    shuffle(test_ids)\n",
        "    if len(selected_scans)>0:\n",
        "      test_patients,test_labels,test_gender,scan_ids,test_cdr = get_selected_scan_from_subjects(data_path,test_ids,data,selected_scans)\n",
        "    else:\n",
        "      test_patients,test_labels,test_gender,scan_ids,test_cdr = get_scan_from_subjects(data_path,test_ids,data)\n",
        "   \n",
        "    return test_patients,scan_ids, test_labels,test_gender,test_cdr\n",
        "   \n",
        "def encode_gender(data):\n",
        "    '''\n",
        "    Categorical encoding. for gender.\n",
        "    '''\n",
        "    data['M/F'] = pd.Categorical(data['M/F'])\n",
        "    \n",
        "    return data['M/F'].cat.codes\n",
        "\n",
        "def parse_function_image(example_proto):\n",
        "\n",
        "    features = {\n",
        "        'image': tf.io.FixedLenFeature([], tf.string),\n",
        "        'image_shape': tf.io.FixedLenFeature([], tf.string)\n",
        "    }\n",
        "\n",
        "    content = tf.io.parse_single_example(example_proto, features=features)\n",
        "\n",
        "    content['image_shape'] = tf.io.decode_raw(content['image_shape'], tf.int32)\n",
        "    content['image'] = tf.io.decode_raw(content['image'], tf.float32)\n",
        "    content['image'] = tf.reshape(content['image'], content['image_shape'])\n",
        "\n",
        "    return content['image']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h779w7TwiICn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(scans),len(sub)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgIqdczJWDry",
        "colab_type": "text"
      },
      "source": [
        "# **Visualize maps on BA estimation agenet model on testset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGosD0T1mXgL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load model\n",
        "\n",
        "cf={'Pretrained_Model':{'path':'/content/drive/My Drive/BA_Estimation/models/exp_ba/age_net.hdf5'},'Paths':\\\n",
        "      {'labels':'/content/drive/My Drive/BA_Estimation/csv_data/oasis1_oasis3_labels.csv',\\\n",
        "       'test_tfrecord':'/content/drive/My Drive/BA_Estimation/tf_records_data/testing_all_cdr'}}#testing_all_cdr\n",
        "model =  tf.python.keras.models.load_model(cf['Pretrained_Model']['path'],compile=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbTQb78-OzWo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "print(tf.__version__)\n",
        "\n",
        "\n",
        "# model =  tf.python.keras.models.load_model(cf['Pretrained_Model']['path'],compile=False)\n",
        "tf_model = model\n",
        "tfw=tf_model.weights\n",
        "\n",
        "dt_string = datetime.now().strftime('%d-%m-%Y-%H-%M')+'_smoe_maps_blockend_scale_endlayers_equal_weights'\n",
        "# dt_string = '01-09-2020-12-33_smoe_maps_blockend_scale_endlayers_equal_weights'\n",
        "# dt_string = '07-09-2020-15-56_smoe_maps_blockend_scale_endlayers_equal_weights'\n",
        "\n",
        "label_path= cf['Paths']['labels'] #'/content/drive/My Drive/BA_Estimation/csv_data/oasis1_oasis3_labels.csv'#/media/shashanks/My Passport/documents/Master_Thesis_Backup/data/\n",
        "data_path= cf['Paths']['test_tfrecord'] #'/home/raarmak1/.shashanks/BA_estimation/tfrecords_data/OASIS1_3_combined/tfrecords_data_exp3/testing/'\n",
        "# exp='exp_ba_outliers'\n",
        "\n",
        "# debug_mode_subject= ['OAS31054']#\n",
        "# debug_mode_subject = ['OAS30884','OAS30720','OAS30344','OAS30541'] #,'OAS31054'] #OAS30911\n",
        "#outliers\n",
        "# debug_mode_subject=['OAS30736','OAS30282','OAS30190']#\n",
        "# debug_mode_subject=['OAS31156','OAS30377','OAS30622','OAS30091','OAS30440','OAS30947','OAS30126','OAS30071','OAS31002','OAS30194','OAS30379','OAS31090',]\n",
        "# debug_mode_subject=['OAS30628','OAS30102','OAS30194','OAS30383','OAS30126','OAS31002']#'OAS30955','OAS30955','OAS30457','OAS30849','OAS30110','OAS30941',]\n",
        "#healthy\n",
        "# debug_mode_subject=['OAS31035','OAS30310','OAS30392','OAS30512','OAS30273','OAS31153','OAS30956']\n",
        "\n",
        "exp='exp_ba'\n",
        "healthy_path = '/content/drive/My Drive/BA_Estimation/models/{0}/non_outliers.csv'.format(exp)\n",
        "# ad_path = '/content/drive/My Drive/BA_Estimation/models/{0}/outlier.csv'.format(exp)\n",
        "hdf = pd.read_csv(healthy_path)\n",
        "# adf = pd.read_csv(ad_path)\n",
        "\n",
        "\n",
        "sub =  hdf['patient_id'].values.tolist()\n",
        "# sub =  adf['patient_id'].values.tolist()\n",
        "# sub.extend(adf['patient_id'].values.tolist())\n",
        "sub= list(set(sub))\n",
        "scans= copy.deepcopy(sub)\n",
        "for i,s in enumerate(sub) :\n",
        "  if s.startswith('OAS1'):\n",
        "    s= s[:9] #OAS1_0123_MR1 take first 9 characters\n",
        "    sub[i] = s.replace('_','')\n",
        "  elif s.startswith('OAS3'): #OAS31098_MR_d7178 #take just subject id\n",
        "    sub[i] = s.split('_')[0]\n",
        "# debug_mode_subject=None\n",
        "print(f'subjects={sub}')\n",
        "print(f'scans={scans}')\n",
        "test_patients,scan_ids, test_labels,test_gender,test_cdr = get_test_files(label_path,data_path,debug_mode_subject=sub[100:200],selected_scans=scans[100:200])\n",
        "# test_patients,scan_ids, test_labels,test_gender,test_cdr = get_test_files(label_path,data_path,debug_mode_subject)\n",
        "tfr=tf.data.TFRecordDataset(test_patients)\n",
        "img_tf=tfr.map(map_func=lambda a:parse_function_image(a))\n",
        "\n",
        "case='healthy'\n",
        "# case = 'outliers'\n",
        "exp='exp_ba_healthy'\n",
        "# exp='exp_ba_outliers'\n",
        "gender_dict={0:'Female',1:'Male'}\n",
        "counter =0\n",
        "for i,im in enumerate(img_tf): \n",
        "    print(type(im),im.shape)\n",
        "    # if test_cdr[i] > 0: #if block to only include healthy subjects from testset for visualizations\n",
        "    #   continue \n",
        "    counter+=1\n",
        "\n",
        "    img=im.numpy()\n",
        "    print(img.shape)\n",
        "  \n",
        "    max_intensity=0\n",
        "    csmap_list=[]\n",
        "    for chunk_id in [6,7,9]:# [7,9,11]: #[7,8,9,10,11,12,13,14]:#[3,7,9,11,14,18]:#range(1,21):\n",
        "\n",
        "      start = (chunk_id-1)*6\n",
        "      end = chunk_id*6\n",
        "      \n",
        "      img_chunk=torch.tensor(img[:,:,start:end])\n",
        "      # img_chunk=torch.tensor(img[:,:,0:6])\n",
        "      img_chunk = img_chunk.unsqueeze(0)\n",
        "      input_tensor = img_chunk.unsqueeze(0)\n",
        "      # imshow(input_tensor[0,0,:,:,-1],cmap='jet')\n",
        "      in_height   = input_tensor.size()[2]\n",
        "      in_width    = input_tensor.size()[3]\n",
        "      print(test_gender[i],input_tensor.shape,scan_ids[i])\n",
        "     \n",
        "      n=66\n",
        "      # layer_name='conv3d_'+str(n-1)\n",
        "      # layer_name='activation_'+str(n-1)\n",
        "      layer_name='activation_'+str(n)\n",
        "   \n",
        "      conv_path ='conv1_'+str(n)\n",
        "      \n",
        "      cdr_val = str(test_cdr[i])\n",
        "      #axial\n",
        "      base_dir= '/content/drive/My Drive/BA_Estimation/results/sal_map_axial/'+dt_string\\\n",
        "      +'_'+exp+'/'+scan_ids[i]+'_cdr'+str(test_cdr[i])\n",
        "      path = base_dir+'/'+str(chunk_id)+'_'+conv_path+'/'\n",
        "      print(path)\n",
        "      if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "      \n",
        "      base_path  = path+scan_ids[i]+'_chunk_'+str(chunk_id)\n",
        "      result_path = '/content/drive/My Drive/BA_Estimation/final_results/{0}/'.format(case)+dt_string+'/cdr'+cdr_val+ '/axial/'+str(chunk_id)+'/'\n",
        "\n",
        "      if not os.path.exists(result_path):\n",
        "        os.makedirs(result_path)\n",
        "      result_path += scan_ids[i]\n",
        "      csmap_a=compute_saliency_tf(base_path,inputs=[img[:,:,start:end],test_gender[i]],tf_model=tf_model)\n",
        "      image,gcam_img,gcam_pp_img = compute_gcam_and_gcam_pp(layer_name,tf_model,[img[:,:,start:end],test_gender[i]])\n",
        "      combine_sal_gcam(path+scan_ids[i]+'_cdr'+str(test_cdr[i])+'_'+gender_dict[test_gender[i]],csmap_a,gcam_img,gcam_pp_img,image,layer_name=layer_name,angle=-270,result_path=result_path ) \n",
        "      \n",
        "      \n",
        "\n",
        "      #sagittal\n",
        "      base_dir= '/content/drive/My Drive/BA_Estimation/results/sal_map_sagittal/'+dt_string\\\n",
        "      +'_'+exp+'/'+scan_ids[i]+'_cdr'+str(test_cdr[i])\n",
        "      path = base_dir+'/'+str(chunk_id)+'_'+conv_path+'/'\n",
        "      print(path)\n",
        "      \n",
        "      if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "      base_path  = path+scan_ids[i]+'_chunk_'+str(chunk_id)\n",
        "      img_s= torch.from_numpy(img[start:end,:,:]).permute(2,1,0)\n",
        "      result_path = '/content/drive/My Drive/BA_Estimation/final_results/{0}/'.format(case)+dt_string +'/cdr'+cdr_val+'/sagittal/'+str(chunk_id)+'/'\n",
        "      if not os.path.exists(result_path):\n",
        "        os.makedirs(result_path)\n",
        "      result_path += scan_ids[i]\n",
        "      csmap_s=compute_saliency_tf(base_path,inputs=[img_s.numpy(),test_gender[i]],tf_model=tf_model)\n",
        "      image,gcam_img,gcam_pp_img = compute_gcam_and_gcam_pp(layer_name,tf_model,[img_s.numpy(),test_gender[i]])\n",
        "      combine_sal_gcam(path+scan_ids[i]+'_cdr'+str(test_cdr[i])+'_'+gender_dict[test_gender[i]],csmap_s,gcam_img,gcam_pp_img,image,layer_name=layer_name,angle=180,result_path=result_path ) \n",
        "\n",
        "      #coronal\n",
        "      base_dir= '/content/drive/My Drive/BA_Estimation/results/sal_map_coronal/'+dt_string\\\n",
        "      +'_'+exp+'/'+scan_ids[i]+'_cdr'+str(test_cdr[i])\n",
        "      # path = base_dir+'/'+str(chunk_id)+'_old_'+conv_path+'/'\n",
        "      result_path = '/content/drive/My Drive/BA_Estimation/final_results/{0}/'.format(case)+dt_string+'/cdr'+cdr_val+'/coronal/'+str(chunk_id)+'/'\n",
        "      path = base_dir+'/'+str(chunk_id)+'_'+conv_path+'/'\n",
        "      print(path)\n",
        "      if not os.path.exists(result_path):\n",
        "        os.makedirs(result_path)\n",
        "      result_path += scan_ids[i]\n",
        "      if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "      base_path  = path+scan_ids[i]+'_chunk_'+str(chunk_id)\n",
        "      img_c= torch.from_numpy(img[:,start:end,:]).permute(2,0,1)\n",
        "      img_c=img_c.unsqueeze(0)\n",
        "      img_c = torch.nn.functional.upsample(img_c.unsqueeze(0), size=(121,145,6), mode='nearest') \n",
        "      csmap_c=compute_saliency_tf(base_path,inputs=[img_c.numpy(),test_gender[i]],tf_model=tf_model)\n",
        "      image,gcam_img,gcam_pp_img = compute_gcam_and_gcam_pp(layer_name,tf_model,[img_c.numpy(),test_gender[i]])\n",
        "      combine_sal_gcam(path+scan_ids[i]+'_cdr'+str(test_cdr[i])+'_'+gender_dict[test_gender[i]],csmap_c,gcam_img,gcam_pp_img,image,layer_name=layer_name,angle=180,result_path=result_path ) \n",
        "\n",
        "\n",
        "    print(f'scan count={counter}')\n",
        "\n",
        "      # #coronal\n",
        "      # base_dir= '/content/drive/My Drive/BA_Estimation/results/sal_map_coronal/'+dt_string\\\n",
        "      # +'_'+exp+'/'+scan_ids[i]+'_cdr'+str(test_cdr[i])\n",
        "      # path = base_dir+'/'+str(chunk_id)+'_new_'+conv_path+'/'\n",
        "      # print(path)\n",
        "      # if not os.path.exists(path):\n",
        "      #   os.makedirs(path)\n",
        "      # base_path  = path+scan_ids[i]+'_chunk_'+str(chunk_id) #36:42\n",
        "      # img_c= torch.from_numpy(img[:,42:48,:]).permute(2,0,1)\n",
        "      # img_c=img_c.unsqueeze(0)\n",
        "      # img_c = torch.nn.functional.upsample(img_c.unsqueeze(0), size=(121,145,6), mode='nearest') \n",
        "      # csmap_c=compute_saliency_tf(base_path,inputs=[img_c.numpy(),test_gender[i]],tf_model=tf_model)\n",
        "      # image,gcam_img,gcam_pp_img = compute_gcam_and_gcam_pp(layer_name,tf_model,[img_c.numpy(),test_gender[i]])\n",
        "      # combine_sal_gcam(path+scan_ids[i]+'_cdr'+str(test_cdr[i])+'_'+gender_dict[test_gender[i]],csmap_c,gcam_img,gcam_pp_img,image,layer_name=layer_name ) \n",
        "      \n",
        "\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNWUvS6W1Idc",
        "colab_type": "text"
      },
      "source": [
        "# **Visualizing mean testset on BA models.**\n",
        "## The mean was computed on the test set ateach cdr value for male and female separately and then visualized ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhbPSHIM0O6n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "mat_path = '/content/drive/My Drive/BA_Estimation/means/exp_ba/full/'\n",
        "files = os.listdir(mat_path)\n",
        "\n",
        "# dt_string = datetime.now().strftime('%d-%m-%Y-%H-%M')+'_smoe_maps_blockend_scale_endlayers_equal_weights'\n",
        "\n",
        "label_path= cf['Paths']['labels'] \n",
        "data_path= cf['Paths']['test_tfrecord'] \n",
        "# exp='exp_siam_ad'\n",
        "exp='exp_ba_means'\n",
        "tf_model = model\n",
        "\n",
        "gender_dict={0:'Female',1:'Male'}\n",
        "reverse_gender_dict = {'Female':0,'Male':0}\n",
        "for i,f in enumerate(files): #OAS30686_d0030\n",
        "  # print(type(f),im.shape)\n",
        "  \n",
        "  test_gender = f.split('_')[-1].split('.')[0]\n",
        "  gender_tensor= np.array(reverse_gender_dict[test_gender])\n",
        "  test_cdr = f.split('_')[-2][-3:]\n",
        "  img=loadmat(mat_path+f)['data']\n",
        "  print(img.shape)\n",
        "  csmap_list=[]\n",
        "\n",
        "  for chunk_id in [6,7]:#range(1,21): #select chunks from 1,21 (significant ones are from chunk 6-11)\n",
        "\n",
        "    start = 6*(chunk_id-1)\n",
        "    end = start+6\n",
        "    # img = loadmat(f)['data']\n",
        "\n",
        "    img_chunk=torch.tensor(img[:,:,start:end]).unsqueeze(0)\n",
        "    img_chunk = img_chunk.unsqueeze(-1)\n",
        "    \n",
        "    print(f'input shape={img_chunk.shape}')\n",
        "   \n",
        "    input_tensor = img_chunk\n",
        "\n",
        "    in_height   = input_tensor.size()[1]\n",
        "    in_width    = input_tensor.size()[2]\n",
        "    print(test_gender,input_tensor.shape,f)\n",
        "\n",
        "    a=51\n",
        "    n=35\n",
        "\n",
        "    layer_name='activation_'+str(a)\n",
        "\n",
        "    conv_path ='conv1_'+str(n)\n",
        "\n",
        "\n",
        "    #axial\n",
        "    base_dir= '/content/drive/My Drive/BA_Estimation/means/'+dt_string+ '/sal_map_axial/' \\\n",
        "    +exp+'/'+f+'_cdr'+str(test_cdr)\n",
        "    path = base_dir+'/'+str(chunk_id)+'_'+conv_path+'/'\n",
        "    print(path)\n",
        "    if not os.path.exists(path):\n",
        "      os.makedirs(path)\n",
        "    base_path  = path+f+'_chunk_'+str(chunk_id)\n",
        "    csmap_a=compute_saliency_tf(base_path,inputs=[input_tensor,gender_tensor],tf_model=tf_model)\n",
        "    image,gcam_img,gcam_pp_img = compute_gcam_and_gcam_pp(layer_name,tf_model,[input_tensor,gender_tensor])\n",
        "    combine_sal_gcam(path+f+'_cdr'+str(test_cdr)+'_'+test_gender,csmap_a,gcam_img,gcam_pp_img,image,layer_name=layer_name ) \n",
        "\n",
        "\n",
        "    #sagittal\n",
        "    base_dir= '/content/drive/My Drive/BA_Estimation/means/'+dt_string+'/sal_map_sagittal/' \\\n",
        "    +exp+'/'+f+'_cdr'+str(test_cdr)\n",
        "    path = base_dir+'/'+str(chunk_id)+'_'+conv_path+'/'\n",
        "    print(path)\n",
        "    if not os.path.exists(path):\n",
        "      os.makedirs(path)\n",
        "    base_path  = path+f+'_chunk_'+str(chunk_id)\n",
        "    img_s= torch.from_numpy(img[start:end,:,:]).permute(2,1,0)\n",
        "    csmap_s=compute_saliency_tf(base_path,inputs=[img_s,gender_tensor],tf_model=tf_model)\n",
        "    image,gcam_img,gcam_pp_img = compute_gcam_and_gcam_pp(layer_name,tf_model,[img_s,gender_tensor])\n",
        "    combine_sal_gcam(path+f+'_cdr'+str(test_cdr)+'_'+test_gender,csmap_s,gcam_img,gcam_pp_img,image,layer_name=layer_name ) \n",
        "\n",
        "\n",
        "    #coronal\n",
        "    base_dir= '/content/drive/My Drive/BA_Estimation/means/'+dt_string + '/sal_map_coronal/' \\\n",
        "    +exp+'/'+f+'_cdr'+str(test_cdr)\n",
        "    path = base_dir+'/'+str(chunk_id)+'_old_'+conv_path+'/'\n",
        "    print(path)\n",
        "    if not os.path.exists(path):\n",
        "      os.makedirs(path)\n",
        "    base_path  = path+f+'_chunk_'+str(chunk_id)\n",
        "    # img_c= torch.from_numpy(img[:,58:64,:]).permute(2,0,1)\n",
        "    img_c= torch.from_numpy(img[:,start:end,:]).permute(2,0,1)\n",
        "    img_c=img_c.unsqueeze(0)\n",
        "    img_c = torch.nn.functional.upsample(img_c.unsqueeze(0), size=(121,145,6), mode='nearest') \n",
        "    csmap_c=compute_saliency_tf(base_path,inputs=[img_c,gender_tensor],tf_model=tf_model)\n",
        "    image,gcam_img,gcam_pp_img = compute_gcam_and_gcam_pp(layer_name,tf_model,[img_c,gender_tensor])\n",
        "    combine_sal_gcam(path+f+'_cdr'+str(test_cdr)+'_'+test_gender,csmap_c,gcam_img,gcam_pp_img,image,layer_name=layer_name ) \n",
        "\n",
        "    #coronal\n",
        "    base_dir= '/content/drive/My Drive/BA_Estimation/means/'+dt_string + '/sal_map_coronal/' \\\n",
        "    +exp+'/'+f+'_cdr'+str(test_cdr)\n",
        "    path = base_dir+'/'+str(chunk_id)+'_new_'+conv_path+'/'\n",
        "    print(path)\n",
        "    if not os.path.exists(path):\n",
        "      os.makedirs(path)\n",
        "    base_path  = path+f+'_chunk_'+str(chunk_id)\n",
        "    # img_c= torch.from_numpy(img[:,58:64,:]).permute(2,0,1)\n",
        "    img_c= torch.from_numpy(img[:,end:end+6,:]).permute(2,0,1)\n",
        "    img_c=img_c.unsqueeze(0)\n",
        "    img_c = torch.nn.functional.upsample(img_c.unsqueeze(0), size=(121,145,6), mode='nearest') \n",
        "    csmap_c=compute_saliency_tf(base_path,inputs=[img_c,gender_tensor],tf_model=tf_model)\n",
        "    image,gcam_img,gcam_pp_img = compute_gcam_and_gcam_pp(layer_name,tf_model,[img_c,gender_tensor])\n",
        "    combine_sal_gcam(path+f+'_cdr'+str(test_cdr)+'_'+test_gender,csmap_c,gcam_img,gcam_pp_img,image,layer_name=layer_name ) \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZpZTNiPCKKx",
        "colab_type": "text"
      },
      "source": [
        "# **End of code notebook (the following cells below are only for experimental trying outs.)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZxWbcYNTsch",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5a7f78db-5018-432c-b8c8-e1bba527bd05"
      },
      "source": [
        "img=loadmat('/content/drive/My Drive/BA_Estimation/results/sal_map_axial/25-08-2020-11-36_smoe_maps_blockend_scale_endlayers_equal_weights_exp_ba/OAS30190_MR_d0082_cdr1.0/9_conv1_66/OAS30190_MR_d0082_cdr1.0_Female_activation_66masked_gcam_pp.mat')\n",
        "\n",
        "img['data'].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(121, 145)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aT_etON1AJoQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image=img['data']\n",
        "image[np.where(image<0.3*np.max(image))]=0\n",
        "im=plt.imshow(image,cmap='jet')\n",
        "plt.colorbar(im)\n",
        "plt.clim(0.6,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLyoVEbgJ2EX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image=img['data']\n",
        "image[np.where(image<0.3*np.max(image))]=0\n",
        "im=plt.imshow(image,cmap='jet')\n",
        "plt.colorbar(im)\n",
        "plt.clim(0.6,0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mobp01JvLzyO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "71d7fa43-f575-43b1-f87c-11a359d035eb"
      },
      "source": [
        "import nibabel\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# nii_img=nibabel.load('/content/sub-OAS30440_ses-d0163_T1w.nii').get_fdata() /content/OAS30070_MR_d0070.tfrecord\n",
        "# nii_img=nibabel.load('/content/sub-OAS30070_ses-d0070_T1w.nii').get_fdata() /content/smwc1sub-OAS30282_ses-d0040_T1w.nii\n",
        "# nii_img=nibabel.load('/content/smwc1sub-OAS30282_ses-d0040_T1w.nii').get_fdata() /content/sub-OAS31035_ses-d5659_run-02_T1w.nii\n",
        "# nii_img=nibabel.load('/content/sub-OAS31035_ses-d5659_run-02_T1w.nii').get_fdata() /content/sub-OAS30310_ses-d0191_T1w.nii\n",
        "# nii_img=nibabel.load('/content/sub-OAS31002_ses-d4948_run-02_T1w.nii').get_fdata()\n",
        "# nii_img=nibabel.load('/content/sub-OAS30102_ses-d0024_T1w.nii').get_fdata()\n",
        "# nii_img=nibabel.load('/content/sub-OAS30383_ses-d0134_run-02_T1w.nii').get_fdata()\n",
        "# \n",
        "# nii_img.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(176, 256, 256)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ehw1ci9DMGZm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "# plt.imshow(nii_img[79,:,:],cmap='gray')\n",
        "# plt.imshow(nii_img[70,:,:],cmap='gray') #79\n",
        "# plt.imshow(nii_img[88,:,:],cmap='gray')\n",
        "# plt.imshow(nii_img[79,:,:],cmap='gray')\n",
        "# plt.imshow(nii_img[67,:,:],cmap='gray')\n",
        "# plt.imshow(nii_img[67,:,:],cmap='gray')\n",
        "# plt.imshow(np.mean(nii_img[70:79,:,:],axis=0),cmap='gray')\n",
        "\n",
        "\n",
        "# plt.imshow(np.mean(nii_img[80:86,:,:],axis=0),cmap='gray')\n",
        "# plt.axis('off')\n",
        "# plt.savefig('sagittal.png')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpacuWx3O7Xs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plt.imshow(nii_img[:,101,:],cmap='gray')\n",
        "plt.imshow(np.mean(nii_img[:,85:91,:],axis=1),cmap='gray')\n",
        "# plt.imshow(nii_img[:,90,:],cmap='gray') #96\n",
        "# plt.imshow(nii_img[:,103,:],cmap='gray')\n",
        "# plt.imshow(np.mean(nii_img[:,103:110,:],axis=1),cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.savefig('coronal.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFMH0X9PPB_F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plt.imshow(nii_img[:,:,101],cmap='gray')\n",
        "# plt.imshow(np.mean(nii_img[:,:,103:110],axis=-1),cmap='gray')\n",
        "plt.imshow(np.mean(nii_img[:,:,116:122],axis=-1),cmap='gray')\n",
        "# plt.imshow(nii_img[:,:,102],cmap='gray') #115\n",
        "# plt.imshow(nii_img[:,:,90],cmap='gray') \n",
        "# plt.imshow(nii_img[:,:,96],cmap='gray')\n",
        "# plt.imshow(nii_img[:,:,103:110],cmap='gray') #102, 108,112,110\n",
        "plt.axis('off')\n",
        "plt.savefig('axial.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-dzL0Br4VMi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nii_img2= nibabel.load('/content/smwc1sub-OAS31002_ses-d4948_run-02_T1w.nii').get_fdata()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0orKlcE84rT9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plt.imshow(nii_img2[54,:,:],cmap='gray') \n",
        "# plt.imshow(nii_img2[36,:,:],cmap='gray') \n",
        "plt.imshow(np.mean(nii_img2[30:36,:,:],axis=0),cmap='gray') \n",
        "# plt.imshow(np.mean(nii_img[70:79,:,:],axis=0),cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.savefig('sagittal_preprocessed.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUAnC5I95BQo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plt.imshow(nii_img2[:,54,:],cmap='gray')\n",
        "plt.imshow(np.mean(nii_img2[:,42:48,:],axis=1),cmap='gray') \n",
        "plt.axis('off')\n",
        "plt.savefig('coronal_preprocessed.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTmYf9FS5XLn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plt.imshow(nii_img2[:,:,36],cmap='gray') #54\n",
        "plt.imshow(np.mean(nii_img2[:,:,36:42],axis=-1),cmap='gray') \n",
        "# plt.imshow(nii_img2[:,:,36],cmap='gray')\n",
        "# plt.imshow(np.mean(nii_img2[:,:,36:42],axis=-1),cmap='gray')  \n",
        "plt.axis('off')\n",
        "plt.savefig('axial_preprocessed.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmRdaTe7AjYb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b6a339f0-5ee2-4d07-e73e-b3ee051bee52"
      },
      "source": [
        "np.max(img['data']),np.max(img['data']),np.min(img['data']),np.min(img['data'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.0, 1.0, 0.0, 0.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4O2sCIFpzeH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "39385e5f-221e-4e35-a547-0e72c6e591de"
      },
      "source": [
        "# # -*- coding: utf-8 -*-\n",
        "# %cd fastcam\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# import warnings\n",
        "# import os\n",
        "# import argparse\n",
        "\n",
        "# import tensorflow as tf\n",
        "# import math\n",
        "# import numpy as np\n",
        "# import torch\n",
        "# import torchvision\n",
        "# import torch.utils.data\n",
        "# from torch.utils.data import DataLoader,TensorDataset\n",
        "# import logging\n",
        "# from keras.layers import Input\n",
        "# from keras.layers.merge import concatenate\n",
        "# import torch.nn as nn\n",
        "# from torch.nn import BatchNorm3d,Conv3d,ReLU,MaxPool3d,Linear,AdaptiveAvgPool3d,Flatten,Softmax\n",
        "# import torch.nn.functional as F\n",
        "\n",
        "# from datetime import datetime\n",
        "# from torch.utils import data\n",
        "# import time\n",
        "\n",
        "\n",
        "# import skimage.io as sio\n",
        "# import os\n",
        "# import shutil\n",
        "# import pandas as pd\n",
        "# from random import shuffle\n",
        "\n",
        "# from skimage.transform import resize\n",
        "# import skimage.io as sio\n",
        "# from scipy.io import savemat,loadmat\n",
        "# import cv2\n",
        "\n",
        "# import mask\n",
        "# import draw\n",
        "# import norm\n",
        "# import misc\n",
        "\n",
        "# from torchvision import models\n",
        "\n",
        "# from random import shuffle\n",
        "# from torchvision.utils import make_grid, save_image\n",
        "\n",
        "# import pandas as pd\n",
        "# from gradcam.utils import visualize_cam\n",
        "# from gradcam import GradCAMpp, GradCAM\n",
        "# from matplotlib import pyplot as plt\n",
        "# \"\"\"#**Read Nii images code**\"\"\"\n",
        "\n",
        "# import os\n",
        "\n",
        "\n",
        "# def get_smoe_map(x,relu=True):\n",
        "#   print(f' smoe input shape={x.shape}')\n",
        "#   if relu:\n",
        "#     x=tf.nn.relu(x).numpy()\n",
        "#   print(f'x range={np.amax(x),np.amin(x)}')\n",
        "  \n",
        "#   m   = np.mean(x,axis=-1)+0.0000001 #avoid log 0\n",
        "  \n",
        "#   x   = x + 0.0000001\n",
        "#   k   = np.log2(m) - np.mean(np.log2(x), axis=-1)\n",
        "  \n",
        "#   # k   = np.log10(m) - np.mean(np.log10(x), axis=-1)\n",
        "#   print(np.array_equal(np.zeros(k.shape),k))\n",
        "#   print(f'smoe map={k}')\n",
        "#   print(f'mean={m}')\n",
        "#   th  = k * m\n",
        "#   print(f'smoe output shape={th.shape}')\n",
        "#   return th\n",
        "\n",
        "# def get_std_map(x):\n",
        "#   print(f'before std map shape ={x.shape}')\n",
        "#   m = np.std(x,axis=-1)\n",
        "\n",
        "#   print(f'std map shape ={m.shape}')\n",
        "\n",
        "#   return m\n",
        "\n",
        "# def get_norm(x,const_mean=None,const_std=None):\n",
        "#   # print(f'x shape={x.shape}')\n",
        "#   s0      = x.shape[0]\n",
        "#   s1      = x.shape[1]\n",
        "#   s2      = x.shape[2]\n",
        "#   # s3      = x.shape[3]\n",
        "#   # print(s0,s1,s2)\n",
        "#   x       = np.reshape(x,(s0,s1*s2))\n",
        "#   # x       = np.reshape(x,(s0,s1*s2*s3))\n",
        "#   # print(x)\n",
        "#   '''\n",
        "#       Compute Mean\n",
        "#   '''\n",
        "#   if const_mean is None:\n",
        "#       m       = np.mean(x,axis=-1)\n",
        "#       m       = np.reshape(m,(m.shape[0],1))\n",
        "#   else:\n",
        "#       m       = const_mean\n",
        "      \n",
        "#   '''\n",
        "#       Compute Standard Deviation\n",
        "#   '''\n",
        "#   if const_std is None:\n",
        "#       s       = np.std(x,axis=-1)\n",
        "#       s       = np.reshape(s,(s.shape[0],1))\n",
        "#   else:\n",
        "#       s       = const_std\n",
        "  \n",
        "#   '''\n",
        "#       The normal cumulative distribution function is used to squash the values from within the range of 0 to 1\n",
        "#   '''\n",
        "#   # print(s)\n",
        "#   s=torch.tensor(s)\n",
        "#   x       = 0.5*(1.0 + torch.erf((x-m)/(s*torch.sqrt(torch.tensor(2.0)))))\n",
        "          \n",
        "#   x       = x.reshape(s0,s1,s2)\n",
        "#   # x       = x.reshape(s0,s1,s2,s3)\n",
        "  \n",
        "#   return x\n",
        "#   # return torch.mean(x,dim=-1)\n",
        "\n",
        "# def combine_sal_maps(smaps,output_size,weights,map_num,resize_mode='bilinear',do_relu=False):\n",
        "#   bn  = smaps[0].shape[0]\n",
        "#   cm  = torch.zeros((bn, 1, output_size[0], output_size[1]), dtype=smaps[0].dtype, device=smaps[0].device)\n",
        "#   ww  = []\n",
        "  \n",
        "#   '''\n",
        "#       Now get each saliency map and resize it. Then store it and also create a combined saliency map.\n",
        "#   '''\n",
        "#   for i in range(len(smaps)):\n",
        "#       # assert torch.is_tensor(smaps[i]), \"Each saliency map must be a Torch Tensor.\"\n",
        "#       wsz = smaps[i].shape\n",
        "#       w   = np.reshape(smaps[i],(wsz[0], 1, wsz[1], wsz[2]))#smaps[i].reshape(wsz[0], 1, wsz[1], wsz[2])\n",
        "#       # w=torch.from_numpy(w)\n",
        "#       # print(type(w))\n",
        "#       w   = nn.functional.interpolate(w, size=output_size, mode=resize_mode, align_corners=False) \n",
        "#       ww.append(w)        # should we weight the raw maps ... hmmm\n",
        "      \n",
        "#       cm  += (w * weights[i])\n",
        "\n",
        "#   '''\n",
        "#       Finish the combined saliency map to make it a weighted average.\n",
        "#   '''\n",
        "#   weight_sum =sum(weights)\n",
        "#   cm  = cm / weight_sum\n",
        "#   cm  = cm.reshape(bn, output_size[0],output_size[1])\n",
        "  \n",
        "#   ww  = torch.stack(ww,dim=1)\n",
        "#   ww  = ww.reshape(bn, map_num, output_size[0], output_size[1])\n",
        "  \n",
        "#   # if do_relu:\n",
        "#   #     cm = F.relu(cm)\n",
        "#   #     ww = F.relu(ww)\n",
        "  \n",
        "#   return cm, ww\n",
        "\n",
        "# def compute_saliency_tf(base_path,inputs,tf_model,layer_end):\n",
        "\n",
        "#   gender=inputs[1]\n",
        "#   gender=tf.reshape(gender,[1,1])\n",
        "#   img=inputs[0]\n",
        "#   img_chunk=tf.convert_to_tensor(img)\n",
        "#   print(img_chunk.shape)\n",
        "#   img_chunk = tf.reshape(img_chunk,[1,121,145,6])\n",
        "#   layers=[layer.name for layer in tf_model.layers]\n",
        "#   outputs=[]\n",
        "#   for l in layers:\n",
        "#     # if l in ['activation','activation_2','activation_1']:\n",
        "#     if l.startswith('activation'):\n",
        "#     # if l.startswith('batch_normalization') or l in ['conv3d_48','conv3d_49','conv3d_50','conv3d_63',\\\n",
        "#     # \n",
        "#         outputs.append(tf_model.get_layer(name=l).output) \n",
        "#   outputs.append(tf_model.output)                                         \n",
        "#   test_tf_model=tf.keras.models.Model([tf_model.inputs], outputs)\n",
        "#   # test_tf_model=tf.keras.models.Model([tf_model.inputs], [tf_model.get_layer(name=layers[2]).output,tf_model.get_layer(name=layers[6]).output,tf_model.get_layer(name=layers[9]).output, tf_model.output])\n",
        "\n",
        "#   predictions = test_tf_model([img_chunk,gender])\n",
        "\n",
        "#   # hooks=[predictions[0],predictions[1],predictions[2],predictions[8],predictions[14],predictions[20],predictions[23]\\\n",
        "#   #        ,predictions[29],predictions[35],predictions[41],predictions[47],predictions[50],\\\n",
        "#   #        predictions[56],predictions[62],predictions[65]]#predictions[:layer_end]\n",
        "#   # hooks= [predictions[0],predictions[2],predictions[17],predictions[47],predictions[62]] #1x1 and 3x3 cnn\n",
        "#   hooks=[predictions[0],predictions[2],predictions[14],predictions[47],predictions[65]] #1x1 cnn\n",
        "#   # hooks=predictions[:9]+predictions[-9:layer_end]\n",
        "\n",
        "#   # choose specific channels / filters\n",
        "#   for x in hooks:\n",
        "#     print('ouput shapes layerwise')\n",
        "#     print(x.shape)\n",
        "#   #   print(x.numpy().shape)\n",
        "#   #   print(np.mean(x.numpy(),axis=-2)[:,:,:,-1].shape)\n",
        "#   # sal_maps       = [ get_norm(get_smoe_map(np.expand_dims(np.mean(x.numpy()[:,:,:,:,:],axis=-2)[:,:,:,2],axis=-1))) for x in hooks ]\n",
        "\n",
        "#   #smoe\n",
        "#   sal_maps       = [ get_norm(get_smoe_map(np.mean(x.numpy()[:,:,:,:,:],axis=-2))) for x in hooks ]\n",
        "\n",
        "#   #std dev\n",
        "#   # sal_maps       = [ get_norm(get_std_map(np.mean(x.numpy()[:,:,:,:,:],axis=-2))) for x in hooks ]\n",
        "\n",
        "#   # sal_maps       = [ get_norm(get_smoe_map(x.numpy()[:,:,:,:,:])) for x in hooks ]\n",
        "#   for smaps in sal_maps:\n",
        "#     print(smaps.shape)\n",
        "#   # return\n",
        "#   # sal_maps = [np.reshape(smaps.numpy(),(121,121)) for smaps in sal_maps]\n",
        "\n",
        "#   # all layer scale maps with equal weightage\n",
        "#   weights=np.ones(len(hooks))\n",
        "#    # all layer scale maps with progressive increasing weightage\n",
        "#   # weights=[i+1 for i in range(len(hooks))]\n",
        "#   # weights = [i for i in range(len(hooks),0,-1)]\n",
        "#   map_num=len(hooks)\n",
        "\n",
        "#   f, axarr = plt.subplots(1,1,figsize=(10,10))\n",
        "#   raw=np.mean(img_chunk[0,:,:,:],axis=-1)\n",
        "#   raw= raw/np.max(raw)\n",
        "#   r=axarr.imshow(raw,cmap='jet')\n",
        "#   axarr.set_title('Input image mean along 3rd dimension')\n",
        "#   plt.colorbar(r,fraction=0.01, pad=0.04)\n",
        "#   plt.savefig(base_path+'mean_input_chunk.png')\n",
        "\n",
        "#   csal_maps,sal_maps = combine_sal_maps(sal_maps,output_size=[in_height,in_width],weights=weights,map_num=map_num)\n",
        "#   output_path = base_path +'Map_Combined.png'\n",
        "#   f, axarr = plt.subplots(1,1,figsize=(10,10))\n",
        "#   csal_map=csal_maps[0,:,:].numpy()\n",
        "#   imcs=csal_map/np.max(csal_map)\n",
        "#   im = axarr.imshow(imcs,cmap='jet')\n",
        "#   axarr.set_title('Combined saliency map')\n",
        "#   plt.colorbar(im,fraction=0.01, pad=0.04)\n",
        "#   plt.savefig(output_path)\n",
        "\n",
        "#   il = [sal_maps[0,i,:,:] for i in range(map_num)] # Put each saliency map into the figure\n",
        "#   il.append(csal_maps[0,:,:])                       # add in the combined map at the end of the figure\n",
        "#   images        = [torch.stack(il, 0)]          \n",
        "#   images        = make_grid(images, nrow=5)\n",
        "#   sal_img=images.unsqueeze(1)\n",
        "#   output_path=base_path +'Sal_Maps.png'\n",
        "#   save_image(sal_img,output_path)\n",
        "\n",
        "#   input_path = output_path\n",
        "#   f, axarr = plt.subplots(1,1,figsize=(10,10))\n",
        "#   im=sio.imread(input_path)\n",
        "#   im=axarr.imshow(np.mean(im,axis=-1)/255, cmap='jet');\n",
        "#   axarr.set_title('layerwise saliency maps')\n",
        "#   plt.colorbar(im,fraction=0.01, pad=0.04)\n",
        "#   output_path=base_path +'Sal_Maps_jet.png'\n",
        "#   plt.savefig(output_path)\n",
        "#   return csal_maps\n",
        "\n",
        "\n",
        "\n",
        "# # \"\"\"#**Saliency Map section begins**\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "# # Commented out IPython magic to ensure Python compatibility.\n",
        "# # %cd fastcam/\n",
        "# from random import shuffle\n",
        "# def get_scan_from_subjects(data_path,subject_ids,label_df):\n",
        "#     scans=[]\n",
        "#     labels=[]\n",
        "#     gender=[]\n",
        "#     cdr=[]\n",
        "#     ids=[]\n",
        "#     subject_ids = set(subject_ids)\n",
        "#     for subject in subject_ids :\n",
        "#         path=os.path.join(data_path,subject)\n",
        "#         paths=os.listdir(path)\n",
        "#         ids.extend([scan_id.split('.')[0] for scan_id in paths])\n",
        "#         scans.extend([ os.path.join(path,scan_path) for scan_path in paths])\n",
        "    \n",
        "#         labels.extend([label_df[label_df['MRI ID']==scan_id.split('.')[0]]['Age'].to_list()[0] for scan_id in paths ])\n",
        "#         gender.extend([label_df[label_df['MRI ID']==scan_id.split('.')[0]]['M/F'].to_list()[0] for scan_id in paths ])\n",
        "#         cdr.extend([label_df[label_df['MRI ID']==scan_id.split('.')[0]]['CDR'].to_list()[0] for scan_id in paths ])\n",
        "  \n",
        "#     return scans,labels,gender,ids,cdr\n",
        "\n",
        "# def get_test_files(label_path,data_path,debug_mode_subject=None):\n",
        "\n",
        "#     data = pd.read_csv(label_path)\n",
        "#     data = data.rename(columns={'MR ID':'MRI ID'})\n",
        "#     data['M/F'] = encode_gender(data)\n",
        "#     if debug_mode_subject is None:\n",
        "#       test_ids = os.listdir(data_path)\n",
        "#     else:\n",
        "#       test_ids=debug_mode_subject\n",
        "\n",
        "#     shuffle(test_ids)\n",
        "#     test_patients,test_labels,test_gender,scan_ids,test_cdr = get_scan_from_subjects(data_path,test_ids,data)\n",
        "\n",
        "#     return test_patients,scan_ids, test_labels,test_gender,test_cdr\n",
        "\n",
        "# def encode_gender(data):\n",
        "#     data['M/F'] = pd.Categorical(data['M/F'])\n",
        "    \n",
        "#     return data['M/F'].cat.codes\n",
        "\n",
        "# def parse_function_image(example_proto):\n",
        "\n",
        "#     features = {\n",
        "#         'image': tf.io.FixedLenFeature([], tf.string),\n",
        "#         'image_shape': tf.io.FixedLenFeature([], tf.string)\n",
        "#     }\n",
        "\n",
        "#     content = tf.io.parse_single_example(example_proto, features=features)\n",
        "\n",
        "#     content['image_shape'] = tf.io.decode_raw(content['image_shape'], tf.int32)\n",
        "#     content['image'] = tf.io.decode_raw(content['image'], tf.float32)\n",
        "#     content['image'] = tf.reshape(content['image'], content['image_shape'])\n",
        "\n",
        "#     return content['image']\n",
        "\n",
        "\n",
        "\n",
        "# import cv2\n",
        "# import numpy as np\n",
        "# # LAYER_NAME='conv3d'\n",
        "# def get_grads(layer_name,tf_model,inputs):\n",
        "\n",
        "#   cam_list=[]\n",
        "#   gender= inputs[1] #tf.constant([[1]],dtype=tf.float32)\n",
        "#   gender=tf.reshape(gender,[1,1])\n",
        "#   img=inputs[0]\n",
        "#   grad_model = tf.keras.models.Model([tf_model.inputs], [tf_model.get_layer(name=layer_name).output, tf_model.output])\n",
        "#   # for i in range(48,54,6):\n",
        "#   # end=start+6\n",
        "#   # print(f'{start,end}')\n",
        "#   # img_chunk2=\n",
        "#   img_chunk=tf.convert_to_tensor(img)\n",
        "#   img_chunk = tf.reshape(img_chunk,[1,121,145,6])\n",
        "\n",
        "#   cdr_ohe_dict={0:[1.0,0.0,0.0,0.0],0.5:[0.0,1.0,0.0,0.0],1:[0.0,0.0,1.0,0.0],2:[0.0,0.0,0.0,1.0]}\n",
        "#   cdr_keys= list(cdr_ohe_dict.keys())\n",
        "#   with tf.GradientTape() as tape:\n",
        "#       conv_outputs, predictions = grad_model([img_chunk,gender])\n",
        "#       print(f'predictions={predictions}')\n",
        "#       # loss=predictions\n",
        "#       loss = predictions[0] \n",
        "     \n",
        "\n",
        "#   output = conv_outputs[0]#[0,:,:,:,100]\n",
        "#   print(f'entering tape gradients')\n",
        "\n",
        "#   grads = tape.gradient(loss, conv_outputs)[0]#[0,:,:,:,100]\n",
        "#   print(type(grads))\n",
        "#   print(f'Crossed tape gradients')\n",
        "#   gate_f = tf.cast(output > 0, 'float32')\n",
        "#   gate_r = tf.cast(grads > 0, 'float32')\n",
        "#   # now there are 2 choice either use grads(raw grads) or use guided grads)\n",
        "#   guided_grads = tf.cast(output > 0, 'float32') * tf.cast(grads > 0, 'float32') * grads\n",
        "\n",
        "#   print(f'Entering reduce mean using guided_grads with shape={guided_grads.shape}')\n",
        "#   #guided grads\n",
        "#   weights = tf.reduce_mean(guided_grads, axis=(0,1,2))\n",
        "\n",
        "\n",
        "#   print(f'Computing CAM using output with shape:{output.shape}')\n",
        "\n",
        "#   print(f'weights={weights.shape}')\n",
        "#   cam = np.zeros(output.shape[0:3], dtype=np.float32)\n",
        "#   print(cam.shape)\n",
        "\n",
        "\n",
        "#   cam=tf.reduce_sum(tf.multiply(output,weights),axis=-1)\n",
        "#   cam_list.append(cam)\n",
        "#   return cam_list,grads,loss,weights,output,img_chunk\n",
        "\n",
        "# from skimage.transform import resize\n",
        "# from matplotlib import pyplot as plt\n",
        "# import os\n",
        "# import torch\n",
        "# # p='/content/drive/My Drive/Uni-Sem4/'+mname+'/layer_'+LAYER_NAME+'/'\n",
        "\n",
        "# def compute_gcam_and_gcam_pp(layer_name,model,inputs):\n",
        "#   # print(f'{inputs[0].shape,inputs[1].shape}')\n",
        "#   cam_list,grads,loss,weights,output,img_chunk = get_grads(layer_name,model,inputs)\n",
        "  \n",
        "#   heatmap_list=[]\n",
        "#   for i,cam in enumerate(cam_list):#as we are doing chunk wise so this camlist will have only one cam\n",
        "\n",
        "#     print(f'cam shape={cam.shape}')\n",
        "    \n",
        "#     #gcam\n",
        "#     cam_map=resize(cam,(img_chunk.shape[1],img_chunk.shape[2],img_chunk.shape[3]))\n",
        "\n",
        "#     cam_map = np.maximum(cam_map,0)\n",
        "#     original_image=img_chunk.numpy()\n",
        "   \n",
        "#     heatmap = (cam_map - cam_map.min()) / (cam_map.max() - cam_map.min())\n",
        "\n",
        "  \n",
        "#     print(original_image.shape)\n",
        "#     image=np.mean(original_image[0,:,:,:],axis=-1)\n",
        "#     print(image.shape)\n",
        "\n",
        "#     mri_img=image#np.squeeze(image)\n",
        "#     heatmap_list.append(heatmap)\n",
        "#     # print(heatmap.min(),heatmap.max())\n",
        "\n",
        "#     heatmap_gcam = (cam_map - cam_map.min()) / (cam_map.max() - cam_map.min())\n",
        "\n",
        "      \n",
        "      \n",
        "#     gcam_img=(np.mean(heatmap_gcam,axis=-1)* 255).astype(\"uint8\")\n",
        "   \n",
        "#     #gcam++\n",
        "#     print(f'grads shape ={grads.shape},tf.exp(loss) shape={tf.exp(loss).shape}')\n",
        "#     conv_first_grad = tf.exp(loss)[0]*grads\n",
        "#     #second_derivative\n",
        "#     conv_second_grad = tf.exp(loss)[0]*grads*grads\n",
        "#     #triple_derivative\n",
        "#     conv_third_grad = tf.exp(loss)[0]*grads*grads*grads\n",
        "    \n",
        "#     global_sum = np.sum(tf.reshape(output,(-1,conv_first_grad[0].shape[2])), axis=0)\n",
        "#     print(f'conv_first_grad shape={conv_first_grad.shape},conv_second_grad shape={conv_second_grad.shape} ,  conv_third_grad shape={conv_third_grad.shape}, global_sum.shape={global_sum.shape}  ')\n",
        "#     alpha_num = conv_second_grad[0]\n",
        "#     # alpha_denom = conv_second_grad[0]*2.0 + conv_third_grad[0]*global_sum.reshape((1,1,conv_first_grad[0].shape[2]))\n",
        "#     alpha_denom = conv_second_grad*2.0 + conv_third_grad*global_sum.reshape((1,1,1,conv_first_grad[0].shape[2]))\n",
        "#     alpha_denom = np.where(alpha_denom != 0.0, alpha_denom, np.ones(alpha_denom.shape))\n",
        "#     alphas = alpha_num/alpha_denom\n",
        "\n",
        "    \n",
        "\n",
        "#     alphas_thresholding = np.where(weights, alphas, 0.0)\n",
        "#     print(f'alphas_thresholding shape={alphas_thresholding.shape}')\n",
        "#     alpha_normalization_constant = np.sum(np.sum(alphas_thresholding, axis=0),axis=0)\n",
        "#     alpha_normalization_constant_processed = np.where(alpha_normalization_constant != 0.0, alpha_normalization_constant, np.ones(alpha_normalization_constant.shape))\n",
        "#     print(f'alpha_normalization_constant_processed shape={alpha_normalization_constant_processed.shape}')\n",
        "    \n",
        "#     # alphas /= alpha_normalization_constant_processed.reshape((1,1,conv_first_grad[0].shape[2]))\n",
        "#     alphas /= alpha_normalization_constant_processed.reshape((1,1,3,conv_first_grad[0].shape[2]))\n",
        "#     print(f'weights.shape={weights.shape},alphas.shape={alphas.shape}')\n",
        "#     weights_alpha=tf.reduce_sum(tf.multiply(weights,alphas),axis=0)\n",
        "    \n",
        "#     cam=tf.reduce_sum(tf.multiply(output,weights_alpha),axis=-1)\n",
        "    \n",
        "#     cam_map=resize(cam,(img_chunk.shape[1],img_chunk.shape[2],img_chunk.shape[3]))\n",
        "  \n",
        "    \n",
        "#     print(f'cam_map={cam_map.shape}')\n",
        "#     cam_map = np.maximum(cam_map, 0)\n",
        "\n",
        "#     heatmap_gcam_pp = (cam_map - cam_map.min()) / (cam_map.max() - cam_map.min())\n",
        "\n",
        "\n",
        "#     gcam_pp_img=(np.mean(heatmap_gcam_pp,axis=-1) * 255).astype(\"uint8\")\n",
        "#     ##\n",
        "#     print(img_chunk.shape,mri_img.shape,gcam_img.shape,type(mri_img),type(gcam_img))\n",
        "  \n",
        "        \n",
        "#     return image, gcam_img,gcam_pp_img\n",
        "\n",
        "# def combine_sal_gcam(base_path,csmap,gcam_img,gcam_pp_img,image,layer_name ):\n",
        "#   print(gcam_img.shape,csmap.shape,gcam_pp_img.shape,image.shape)\n",
        "#   #gcam\n",
        "#   if np.max(gcam_img) ==0:\n",
        "#     gcam_img = gcam_img+0.001\n",
        "#   if np.max(gcam_pp_img) ==0:\n",
        "#     gcam_pp_img = gcam_pp_img+0.001\n",
        "#   gcam_img_tensor=torch.from_numpy(gcam_img).unsqueeze(0)\n",
        "#   mask_gcam = csmap*(gcam_img_tensor)\n",
        "#   mask_gcam=mask_gcam/mask_gcam.max()\n",
        "#   raw_tensor=torch.from_numpy(image).unsqueeze(0)\n",
        "#   heatmap_gcam, result_gcam = visualize_cam(mask_gcam, raw_tensor)\n",
        "#   getMask                 = mask.SaliencyMaskDropout(keep_percent = 0.1, scale_map=False)\n",
        "#   hard_masked_gcam,_       = getMask(raw_tensor.unsqueeze(0),mask_gcam)#.squeeze(0))\n",
        "#   hard_masked_gcam        = hard_masked_gcam.squeeze(0)\n",
        "#   masked_gcam             = misc.AlphaMask(raw_tensor, mask_gcam.squeeze(0)).squeeze(0)\n",
        "#   # print(masked_gcam.shape,type(masked_gcam))\n",
        "#   mx= str(np.max(masked_gcam.numpy()))\n",
        "#   plt.imsave(base_path+'masked_gcam_unnormalized_{0}max.png'.format(mx),masked_gcam.numpy(),cmap='jet')\n",
        "#   # masked_gcam              = misc.RangeNormalize(masked_gcam)\n",
        "\n",
        " \n",
        "#   ##\n",
        "\n",
        "#   #gcam++\n",
        "#   gcam_pp_img_tensor=torch.from_numpy(gcam_pp_img).unsqueeze(0)\n",
        "#   mask_gcam_pp = csmap*(gcam_pp_img_tensor)\n",
        "#   mask_gcam_pp=mask_gcam_pp/mask_gcam_pp.max()\n",
        "#   raw_tensor=torch.from_numpy(image).unsqueeze(0)\n",
        "#   heatmap_gcam_pp, result_gcam_pp = visualize_cam(mask_gcam_pp, raw_tensor)\n",
        "\n",
        "#   hard_masked_gcam_pp,_       = getMask(raw_tensor.unsqueeze(0),mask_gcam_pp)#.squeeze(0))\n",
        "#   hard_masked_gcam_pp         = hard_masked_gcam_pp.squeeze(0)\n",
        "#   masked_gcam_pp           = misc.AlphaMask(raw_tensor, mask_gcam_pp.squeeze(0)).squeeze(0)\n",
        "#   mx= str(np.max(masked_gcam_pp.numpy()))\n",
        "#   plt.imsave(base_path+'masked_gcam_pp_unnormalized_{0}max.png'.format(mx),masked_gcam_pp.numpy(),cmap='jet')\n",
        "#   # masked_gcam_pp           = misc.RangeNormalize(masked_gcam_pp)\n",
        "\n",
        "#   #input image\n",
        "#   #log gcam++\n",
        " \n",
        "\n",
        "#   #\n",
        "#   output_path   = base_path+\"raw_img.png\"\n",
        "#   savemat(output_path.split('.png')[0] +'.mat',{'data':raw_tensor.numpy() ,'shape':raw_tensor.shape})\n",
        "#   # plt.imsave(output_path,gcam_img)#provision for png if required.\n",
        "#   base_path+='_'+layer_name\n",
        "\n",
        "#   #save gcam and gcam++ fig\n",
        "#   vmin=np.amin([np.min(gcam_img),np.min(gcam_pp_img)])\n",
        "#   vmax=np.amax([np.max(gcam_img),np.max(gcam_pp_img)])\n",
        "\n",
        "#   f, axarr = plt.subplots(1,2,figsize=(10,10))\n",
        "#   img_plot = axarr[0].imshow(gcam_img,vmin=vmin,vmax=vmax, cmap='jet');\n",
        "#   axarr[0].set_title('Gradcam')\n",
        "#   img_plot = axarr[1].imshow(gcam_pp_img,vmin=vmin,vmax=vmax, cmap='jet');\n",
        "#   axarr[1].set_title('Gradcam++')\n",
        "#   plt.colorbar(img_plot,fraction=0.046, pad=0.04)\n",
        "#   plt.savefig(base_path+'gcam_gcam++_fig.png')\n",
        "#   #gcam\n",
        "# # \n",
        "#   vmin=np.amin([torch.min(raw_tensor),torch.min(csmap),torch.min(heatmap_gcam),torch.min(result_gcam),torch.min(masked_gcam),torch.min(hard_masked_gcam)])\n",
        "#   vmax=np.amax([torch.max(raw_tensor),torch.max(csmap),torch.max(heatmap_gcam),torch.max(result_gcam),torch.max(masked_gcam),torch.max(hard_masked_gcam)])\n",
        "#   vmin=0\n",
        "#   vmax=1.0\n",
        "#   f, axarr = plt.subplots(1,6,figsize=(20,20))\n",
        "#   img_plot = axarr[0].imshow(torch.mean(raw_tensor,axis=0),vmin=vmin,vmax=vmax, cmap='jet');\n",
        "#   axarr[0].set_title('input')\n",
        "#   img_plot = axarr[1].imshow(torch.mean(csmap,axis=0),vmin=vmin,vmax=vmax, cmap='jet');\n",
        "#   axarr[1].set_title('combined saliency map')\n",
        "#   img_plot = axarr[2].imshow(torch.mean(heatmap_gcam,axis=0),vmin=vmin,vmax=vmax, cmap='jet');\n",
        "#   axarr[2].set_title('saliency map + gradcam')\n",
        "#   img_plot = axarr[3].imshow(torch.mean(result_gcam,axis=0),vmin=vmin,vmax=vmax, cmap='jet');\n",
        "#   axarr[3].set_title('saliency map+gradcam with alpha blend')\n",
        "#   img_plot = axarr[4].imshow(masked_gcam,vmin=vmin,vmax=vmax, cmap='jet');\n",
        "#   axarr[4].set_title('mask')\n",
        "#   img_plot = axarr[5].imshow(hard_masked_gcam[0],vmin=vmin,vmax=vmax, cmap='jet');\n",
        "#   axarr[5].set_title('hard mask')\n",
        "#   plt.colorbar(img_plot,fraction=0.046, pad=0.04)\n",
        "#   plt.savefig(base_path+'sal+gcam_fig.png')\n",
        "\n",
        "#   print(hard_masked_gcam.permute([2,0,1]).shape)\n",
        "#   output_path   = base_path+\"gcam_img.png\"\n",
        "#   savemat(output_path.split('.png')[0] +'.mat',{'data':gcam_img ,'shape':gcam_img.shape})\n",
        "#   output_path   = base_path+\"heatmap_gcam.png\"\n",
        "#   savemat(output_path.split('.png')[0] +'.mat',{'data':heatmap_gcam.permute([1,2,0]).numpy() ,'shape':heatmap_gcam.permute([1,2,0]).numpy().shape})\n",
        "#   output_path   = base_path+\"result_gcam.png\"\n",
        "#   savemat(output_path.split('.png')[0] +'.mat',{'data':result_gcam.permute([1,2,0]).numpy() ,'shape':result_gcam.permute([1,2,0]).numpy().shape})\n",
        "#   output_path   = base_path+\"hard_masked_gcam.png\" \n",
        "#   savemat(output_path.split('.png')[0] +'.mat',{'data':hard_masked_gcam.permute([1,2,0]).numpy() ,'shape':hard_masked_gcam.permute([1,2,0]).shape})\n",
        "#   output_path   = base_path+\"masked_gcam.mat\" \n",
        "#   savemat(output_path,{'data':masked_gcam.numpy() ,'shape':masked_gcam.numpy().shape})\n",
        "#   masked_gcam_mat = loadmat(output_path)['data']\n",
        "#   plt.clf()\n",
        "#   p=plt.imshow(masked_gcam_mat,cmap='jet')\n",
        "#   plt.colorbar(p)      \n",
        "#   plt.clim(0.8,1)\n",
        "#   output_path   = base_path+\"masked_gcam_0.8.png\" \n",
        "#   plt.savefig(output_path)\n",
        "\n",
        "\n",
        "#   #gcam_pp\n",
        "#   vmin=np.amin([torch.min(raw_tensor),torch.min(csmap),torch.min(heatmap_gcam_pp),torch.min(result_gcam_pp),torch.min(masked_gcam_pp),torch.min(hard_masked_gcam_pp)])\n",
        "#   vmax=np.amax([torch.max(raw_tensor),torch.max(csmap),torch.max(heatmap_gcam_pp),torch.max(result_gcam_pp),torch.max(masked_gcam_pp),torch.max(hard_masked_gcam_pp)])\n",
        "\n",
        "#   vmin=0\n",
        "#   vmax=1.0\n",
        "\n",
        "#   f, axarr = plt.subplots(1,6,figsize=(20,20))\n",
        "#   img_plot = axarr[0].imshow(torch.mean(raw_tensor,axis=0),vmin=vmin,vmax=vmax, cmap='jet');\n",
        "#   axarr[0].set_title('input')\n",
        "#   img_plot = axarr[1].imshow(torch.mean(csmap,axis=0),vmin=vmin,vmax=vmax, cmap='jet');\n",
        "#   axarr[1].set_title('combined saliency map')\n",
        "#   img_plot = axarr[2].imshow(torch.mean(heatmap_gcam_pp,axis=0),vmin=vmin,vmax=vmax, cmap='jet');\n",
        "#   axarr[2].set_title('saliency map + gradcam++')\n",
        "#   img_plot = axarr[3].imshow(torch.mean(result_gcam_pp,axis=0),vmin=vmin,vmax=vmax, cmap='jet');\n",
        "#   axarr[3].set_title('saliency map+gradcam++ with alpha blend')\n",
        "#   img_plot = axarr[4].imshow(masked_gcam_pp,vmin=vmin,vmax=vmax, cmap='jet');\n",
        "#   axarr[4].set_title('mask')\n",
        "#   img_plot = axarr[5].imshow(hard_masked_gcam_pp[0],vmin=vmin,vmax=vmax, cmap='jet');\n",
        "#   axarr[5].set_title('hard mask')\n",
        "#   plt.colorbar(img_plot,fraction=0.046, pad=0.04)\n",
        "#   plt.savefig(base_path+'sal+gcam++_fig.png')\n",
        "\n",
        "\n",
        "#   raw_img = torch.mean(raw_tensor,axis=0).numpy()\n",
        "#   output_path   = base_path+\"raw_input.png\"\n",
        "#   savemat(output_path.split('.png')[0] +'.mat',{'data':raw_img ,'shape':raw_img.shape})\n",
        "\n",
        "#   f, axarr = plt.subplots(1,1,figsize=(10,10))\n",
        "\n",
        "#   r=axarr.imshow(raw_img,cmap='gray')\n",
        "#   axarr.set_title('raw gray image')\n",
        "#   cbar=plt.colorbar(r,fraction=0.046, pad=0.04)\n",
        "#   cbar.set_clim(0,1)\n",
        "#   plt.savefig(base_path+'raw_gray_cbar.png')\n",
        "\n",
        "#   csmap_img = torch.mean(csmap,axis=0).numpy()\n",
        "#   output_path   = base_path+\"csmap.png\"\n",
        "#   savemat(output_path.split('.png')[0] +'.mat',{'data':csmap_img ,'shape':csmap_img.shape})\n",
        "#   output_path   = base_path+\"gcam_pp_img.png\"\n",
        "#   savemat(output_path.split('.png')[0] +'.mat',{'data':gcam_pp_img ,'shape':gcam_pp_img.shape})\n",
        "#   output_path   = base_path+\"heatmap_gcam_pp.png\"\n",
        "#   savemat(output_path.split('.png')[0] +'.mat',{'data':heatmap_gcam_pp.permute([1,2,0]).numpy() ,'shape':heatmap_gcam_pp.permute([1,2,0]).numpy().shape})\n",
        "#   output_path   = base_path+\"result_gcam_pp.png\"\n",
        "#   savemat(output_path.split('.png')[0] +'.mat',{'data':result_gcam_pp.permute([1,2,0]).numpy() ,'shape':result_gcam_pp.permute([1,2,0]).numpy().shape})\n",
        "#   output_path   = base_path+\"hard_masked_gcam_pp.png\" \n",
        "#   savemat(output_path.split('.png')[0] +'.mat',{'data':hard_masked_gcam_pp.permute([1,2,0]).numpy() ,'shape':hard_masked_gcam_pp.permute([1,2,0]).numpy().shape})\n",
        "#   output_path   = base_path+\"masked_gcam_pp.mat\" \n",
        "#   savemat(output_path,{'data':masked_gcam_pp.numpy() ,'shape':masked_gcam_pp.numpy().shape})\n",
        "#   masked_gcam_pp_mat = loadmat(output_path)['data']\n",
        "#   plt.clf()\n",
        "#   p=plt.imshow(masked_gcam_pp_mat,cmap='jet',vmin=np.min(masked_gcam_pp_mat),vmax=np.max(masked_gcam_pp_mat))\n",
        "#   plt.colorbar(p)      \n",
        "#   plt.clim(0.8,1)\n",
        "#   output_path   = base_path+\"masked_gcam_pp_0.8fig.png\" \n",
        "#   plt.savefig(output_path)\n",
        "# l\n",
        "#   ## GCAM\n",
        "#   masked_gcam=masked_gcam.numpy()\n",
        "\n",
        "#   frac=0.5\n",
        "\n",
        "#   t='masked_gcam'\n",
        "#   max =  1 #np.amax(masked_gcam)\n",
        "#   r1=(masked_gcam/max)\n",
        "\n",
        "#   r1[np.where(r1<frac*np.max(r1))]=0\n",
        "#   # r1[np.where(r1<np.median(r1))]=0\n",
        "#   plt.imsave(base_path+'nodiff_{0}_{1}.png'.format(frac,t),r1,cmap='jet',vmin=np.min(r1),vmax=np.max(r1))\n",
        "\n",
        "#   frac=0.3\n",
        "#   r1=(masked_gcam/max)\n",
        "#   print(f'Min Max values of Sal+GCAM map ={np.min(r1),np.max(r1)}')\n",
        "#   r1[np.where(r1<frac*np.max(r1))]=0\n",
        "#   # r1[np.where(r1<np.median(r1))]=0\n",
        "  \n",
        "#   plt.imsave(base_path+'nodiff_{0}_{1}.png'.format(frac,t),r1,cmap='jet',vmin=np.min(r1),vmax=np.max(r1))\n",
        "\n",
        "\n",
        "#   plt.clf()\n",
        "#   p=plt.imshow(masked_gcam_mat,cmap='jet',vmin=np.min(r1),vmax=np.max(r1))\n",
        "#   plt.colorbar(p)      \n",
        "#   plt.clim(0,1)\n",
        "#   output_path   = base_path+\"masked_gcam_0.3_fig.png\" \n",
        "#   plt.savefig(output_path)\n",
        "\n",
        "#   frac=0.8\n",
        "#   r1=(masked_gcam/max)\n",
        "\n",
        "#   r1[np.where(r1<frac*np.max(r1))]=0\n",
        "#   # r1[np.where(r1<np.median(r1))]=0\n",
        "#   plt.imsave(base_path+'nodiff_{0}_{1}.png'.format(frac,t),r1,cmap='jet',vmin=np.min(r1),vmax=np.max(r1))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#   ## fraction mask  map for overlaying GCAM++\n",
        "#   masked_gcam_pp=masked_gcam_pp.numpy()\n",
        "\n",
        "#   frac=0.5\n",
        "\n",
        "#   t='masked_gcam_pp'\n",
        "#   max = 1 #np.amax(masked_gcam_pp)\n",
        "#   r1=(masked_gcam_pp/max)\n",
        "\n",
        "#   r1[np.where(r1<frac*np.max(r1))]=0\n",
        "#   # r1[np.where(r1<np.median(r1))]=0\n",
        "#   plt.imsave(base_path+'nodiff_{0}_{1}.png'.format(frac,t),r1,cmap='jet',vmin=np.min(r1),vmax=np.max(r1))\n",
        "\n",
        "#   frac=0.3\n",
        "\n",
        "#   r1=(masked_gcam_pp/max)\n",
        "#   print(f'Min Max values of Sal+GCAM++ map ={np.min(r1),np.max(r1)}')\n",
        "#   r1[np.where(r1<frac*np.max(r1))]=0\n",
        "#   # r1[np.where(r1<np.median(r1))]=0\n",
        "  \n",
        "#   plt.imsave(base_path+'nodiff_{0}_{1}.png'.format(frac,t),r1,cmap='jet',vmin=np.min(r1),vmax=np.max(r1))\n",
        "\n",
        "#   plt.clf()\n",
        "#   p=plt.imshow(masked_gcam_pp_mat,cmap='jet',vmin=np.min(r1),vmax=np.max(r1))\n",
        "#   plt.colorbar(p)      \n",
        "#   plt.clim(0,1)\n",
        "#   output_path   = base_path+\"masked_gcam_pp_0.3_fig.png\" \n",
        "#   plt.savefig(output_path)\n",
        "\n",
        "\n",
        "#   frac=0.8\n",
        "#   r1=(masked_gcam_pp/max)\n",
        "\n",
        "#   r1[np.where(r1<frac*np.max(r1))]=0\n",
        "#   # r1[np.where(r1<np.median(r1))]=0\n",
        "#   plt.imsave(base_path+'nodiff_{0}_{1}.png'.format(frac,t),r1,cmap='jet',vmin=np.min(r1),vmax=np.max(r1))\n",
        "\n",
        "#   ##\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/fastcam\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nK4Iovf8UiW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# exp='exp_ba'\n",
        "# healthy_path = '/content/drive/My Drive/BA_Estimation/models/{0}/testset.csv'.format(exp)\n",
        "# # ad_path = '/content/drive/My Drive/BA_Estimation/models/{0}/outlier.csv'.format(exp)\n",
        "# hdf = pd.read_csv(healthy_path)\n",
        "# # adf = pd.read_csv(ad_path)\n",
        "# # print(hdf.columns)\n",
        "\n",
        "# sub =  hdf['patient_id'].values.tolist()\n",
        "# # sub =  adf['patient_id'].values.tolist()\n",
        "# # sub.extend(adf['patient_id'].values.tolist())\n",
        "# sub= list(set(sub))\n",
        "# scans= copy.deepcopy(sub)\n",
        "# for i,s in enumerate(sub) :\n",
        "#   if s.startswith('OAS1'):\n",
        "#     s= s[:9] #OAS1_0123_MR1 take first 9 characters\n",
        "#     sub[i] = s.replace('_','')\n",
        "#   elif s.startswith('OAS3'): #OAS31098_MR_d7178 #take just subject id\n",
        "#     sub[i] = s.split('_')[0]\n",
        "# # debug_mode_subject=None\n",
        "# print(f'subjects={sub}')\n",
        "# print(f'scans={scans}')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}