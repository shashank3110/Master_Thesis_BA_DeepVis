{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ba_estimation_network_saliency_maps_gcam_gcam++_notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "_ZpZTNiPCKKx"
      ],
      "toc_visible": true,
      "mount_file_id": "15P8hWSHbXF3iE6hYgBq4JlRArI_1UYzT",
      "authorship_tag": "ABX9TyOu6aThmrOcubqKRM8RC2rT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shashank3110/Master_Thesis_BA_DeepVis/blob/master/colab_notebooks/ba_estimation_network_saliency_maps_gcam_gcam%2B%2B_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuM4VvCQ1UD3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "d04872e1-588d-4f5c-f88d-8cb249131475"
      },
      "source": [
        "#saliency map paper : https://github.com/LLNL/fastcam.git and adapted/modified  to our usecase\n",
        "\n",
        "!git clone https://github.com/LLNL/fastcam.git\n",
        "\n",
        "!pip install pytorch_gradcam "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'fastcam'...\n",
            "remote: Enumerating objects: 191, done.\u001b[K\n",
            "remote: Counting objects: 100% (191/191), done.\u001b[K\n",
            "remote: Compressing objects: 100% (117/117), done.\u001b[K\n",
            "remote: Total 605 (delta 117), reused 137 (delta 73), pack-reused 414\u001b[K\n",
            "Receiving objects: 100% (605/605), 18.88 MiB | 17.66 MiB/s, done.\n",
            "Resolving deltas: 100% (357/357), done.\n",
            "Collecting pytorch_gradcam\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e6/0a/55251f7cbea464581c6fb831813d38a41fdeb78f3dd8193522248cb98744/pytorch-gradcam-0.2.1.tar.gz (6.0MB)\n",
            "\u001b[K     |████████████████████████████████| 6.0MB 7.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from pytorch_gradcam) (4.1.2.30)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_gradcam) (1.18.5)\n",
            "Building wheels for collected packages: pytorch-gradcam\n",
            "  Building wheel for pytorch-gradcam (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytorch-gradcam: filename=pytorch_gradcam-0.2.1-cp36-none-any.whl size=5270 sha256=c84a40a12d1c2f18eedfc4b90a29eb3b4d6ea3f2f94c9d8fb8f2707927285468\n",
            "  Stored in directory: /root/.cache/pip/wheels/e8/1e/35/d24150a078a90ce0ad093586814d4665e945466baa89907300\n",
            "Successfully built pytorch-gradcam\n",
            "Installing collected packages: pytorch-gradcam\n",
            "Successfully installed pytorch-gradcam-0.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCpsLgu6VvJ9",
        "colab_type": "text"
      },
      "source": [
        "#**Compute Saliency,Gradcam,Gradcam++ modules**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAAXXZY0tKrS",
        "colab_type": "text"
      },
      "source": [
        "### This cell contains all the functions to compute the various maps. It also contains functions which combine two different maps eg: Saliency Map + Gradcam++ ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19Xgk5ZOUbTF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "f9c58b13-a602-42f8-b48d-da0a68aa373f"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "%cd fastcam\n",
        "\n",
        "#importing libraries \n",
        "\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import warnings\n",
        "\n",
        "import tensorflow as tf\n",
        "import math\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.utils.data\n",
        "from torch.utils.data import DataLoader,TensorDataset\n",
        "import copy\n",
        "import logging\n",
        "from keras.layers import Input\n",
        "from keras.layers.merge import concatenate\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from datetime import datetime\n",
        "from torch.utils import data\n",
        "import time\n",
        "from scipy import ndimage\n",
        "from skimage.transform import resize\n",
        "import yaml\n",
        "import skimage.io as sio\n",
        "import shutil\n",
        "from random import shuffle\n",
        "from skimage.transform import resize\n",
        "import skimage.io as sio\n",
        "from scipy.io import savemat,loadmat\n",
        "import cv2\n",
        "import mask\n",
        "import draw\n",
        "import norm\n",
        "import misc\n",
        "from torchvision import models\n",
        "from random import shuffle\n",
        "from torchvision.utils import make_grid, save_image\n",
        "import pandas as pd\n",
        "from gradcam.utils import visualize_cam\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "'''''''''\n",
        "A: Saliency Maps \n",
        "'''''''''\n",
        "\n",
        "def get_smoe_map(x,relu=False):\n",
        "\n",
        "  '''\n",
        "  Scaled map order equivalent map computation fumction:\n",
        "  reference from the saliency map paper : https://github.com/LLNL/fastcam.git and adapted/modified  to our usecase\n",
        "\n",
        "  Arguments:  numpy array : x -> intermediate layer output.\n",
        "              bool: relu -> to avoid any negative values for log , \n",
        "              if we pass a relu activated conv. output then this argument can be set to False.\n",
        "          \n",
        "  Returns: np array : smoe_map for the intermediate layer output\n",
        "  '''\n",
        "  print(f' smoe input shape={x.shape}')\n",
        "  if relu:\n",
        "    x=tf.nn.relu(x).numpy()\n",
        "  print(f'x range={np.amax(x),np.amin(x)}')\n",
        "  \n",
        "  m   = np.mean(x,axis=-1)+0.0000001 \n",
        "\n",
        "  \n",
        "  x   = x + 0.0000001\n",
        "\n",
        "  k   = np.log2(m) - np.mean(np.log2(x), axis=-1)\n",
        "  print(f'log of mean={np.log2(m)}, mean of log={np.mean(np.log2(x), axis=-1)}')\n",
        "  print(f'k={k}')\n",
        "  k   = k + 0.0000001\n",
        " \n",
        "  print(np.array_equal(np.zeros(k.shape),k))\n",
        "  print(f'{x.shape,k.shape,np.amin(k)}')\n",
        "  print(f'kmax, kmin={np.min(k),np.max(k)}')\n",
        "  print(f'mean={m}')\n",
        "  smoe_map  = k * m\n",
        "  print(f'smoe map={smoe_map}')\n",
        "  print(f'smoe output shape={smoe_map.shape}')\n",
        "  return smoe_map\n",
        "\n",
        "def get_std_map(x):\n",
        "  '''\n",
        "  STD based map alternative to SMOE.\n",
        "\n",
        "  Arguments:  numpy array : x -> intermediate layer output.\n",
        "          \n",
        "  Returns: np array : m (standard deviation based map for the intermediate layer output)\n",
        "\n",
        "  '''\n",
        "  print(f'before std map shape ={x.shape}')\n",
        "  m = np.std(x,axis=-1)\n",
        "\n",
        "  print(f'std map shape ={m.shape}')\n",
        "\n",
        "  return m\n",
        "\n",
        "def get_norm(x,const_mean=None,const_std=None):\n",
        "  '''\n",
        "  get norm refrence from the saliency map paper : https://github.com/LLNL/fastcam.git and adapted/modified  to our usecase\n",
        "\n",
        "  Arguments:  numpy array : x -> intermediate layer output.\n",
        "              float: const_mean (optional) -> only if a constant mean need to be used\n",
        "              float: const_std (optional) -> only if a constant std. dev. need to be used\n",
        "       \n",
        "\n",
        "  Returns: torch.Tensor: csal_maps (combined saliency maps )\n",
        "  '''\n",
        "  s0      = x.shape[0]\n",
        "  s1      = x.shape[1]\n",
        "  s2      = x.shape[2]\n",
        "\n",
        "\n",
        "  x       = np.reshape(x,(1,s1*s2))\n",
        "  print(f'get norm func x after reshape={x.shape} ')\n",
        "\n",
        "  '''\n",
        "      Compute Mean\n",
        "  '''\n",
        "  if const_mean is None:\n",
        "      m       = np.mean(x,axis=1)\n",
        "      m       = np.reshape(m,(m.shape[0],1))\n",
        "  else:\n",
        "      m       = const_mean\n",
        "\n",
        "  print(f'get norm func x after mean reshape={m.shape} ') \n",
        "  '''\n",
        "      Compute Standard Deviation\n",
        "  '''\n",
        "  if const_std is None:\n",
        "      s       = np.std(x,axis=1)\n",
        "      s       = np.reshape(s,(s.shape[0],1))\n",
        "  else:\n",
        "      s       = const_std\n",
        "  \n",
        "  '''\n",
        "      The normal cumulative distribution function is used to squash the values from within the range of 0 to 1\n",
        "  '''\n",
        "\n",
        "  s=torch.tensor(s)\n",
        "  x       = 0.5*(1.0 + torch.erf((x-m)/(s*torch.sqrt(torch.tensor(2.0)))))\n",
        "  print(x.shape)    \n",
        "\n",
        "  x       = x.reshape(1,s1,s2)\n",
        "\n",
        "  print(f'map after norm={x,x.shape}')\n",
        "  return x\n",
        "\n",
        "\n",
        "def combine_sal_maps(smaps,output_size,weights,map_num,resize_mode='bilinear',do_relu=False):\n",
        "  '''\n",
        "  Combined saliency maps are computed here .\n",
        "  '''\n",
        "  bn  = smaps[0].shape[0]\n",
        "  cm  = torch.zeros((bn, 1, output_size[0], output_size[1]), dtype=smaps[0].dtype, device=smaps[0].device)\n",
        "  ww  = []\n",
        "  \n",
        "  '''\n",
        "      Now get each saliency map and resize it. Then store it and also create a combined saliency map.\n",
        "  '''\n",
        "  for i in range(len(smaps)):\n",
        "   \n",
        "      wsz = smaps[i].shape\n",
        "      w   = np.reshape(smaps[i],(wsz[0], 1, wsz[1], wsz[2]))\n",
        "   \n",
        "      w   = nn.functional.interpolate(w, size=output_size, mode=resize_mode, align_corners=False) \n",
        "      ww.append(w)  \n",
        "      \n",
        "      cm  += (w * weights[i])\n",
        "\n",
        "  '''\n",
        "      Finish the combined saliency map to make it a weighted average.\n",
        "  '''\n",
        "  weight_sum =sum(weights)\n",
        "  cm  = cm / weight_sum\n",
        "  cm  = cm.reshape(bn, output_size[0],output_size[1])\n",
        "  \n",
        "  ww  = torch.stack(ww,dim=1)\n",
        "  ww  = ww.reshape(bn, map_num, output_size[0], output_size[1])\n",
        "  \n",
        "\n",
        "  \n",
        "  return cm, ww\n",
        "\n",
        "\n",
        "\n",
        "def compute_saliency_tf(base_path,inputs,tf_model):\n",
        "  '''\n",
        "   Saliency maps are computed for specicied layers and then combine them.\n",
        "\n",
        "   Arguments: str: base_path -> path to save the  map.\n",
        "              list: inputs -> [input_image_tensor,gender_tensor]\n",
        "              tf model: model -> tensorflow pretrained model\n",
        "       \n",
        "\n",
        "  Returns: torch.Tensor: csal_maps (combined saliency maps )\n",
        "  '''\n",
        "\n",
        "  gender=inputs[1]\n",
        "  gender=tf.reshape(gender,[1,1])\n",
        "  img=inputs[0]\n",
        "  img_chunk=tf.convert_to_tensor(img)\n",
        "  print(img_chunk.shape)\n",
        "  img_chunk = tf.reshape(img_chunk,[1,121,145,6])\n",
        "  layers=[layer.name for layer in tf_model.layers]\n",
        "  outputs=[]\n",
        "\n",
        "  #select all layer activations after conv for eg: if there ae 66 conv layers then there are 66 activation layers.\n",
        "  for l in layers:\n",
        "   \n",
        "    if l.startswith('activation'):\n",
        "    \n",
        "        outputs.append(tf_model.get_layer(name=l).output) \n",
        "\n",
        "  outputs.append(tf_model.output)                                         \n",
        "  test_tf_model=tf.keras.models.Model([tf_model.inputs], outputs)\n",
        " \n",
        "  predictions = test_tf_model([img_chunk,gender])\n",
        "\n",
        "  # Specify or experiment  with layers we want to compute saliency maps for.\n",
        "\n",
        "  # hooks=[predictions[0],predictions[1],predictions[2],predictions[8],predictions[14],predictions[20],predictions[23]\\\n",
        "  #        ,predictions[29],predictions[35],predictions[41],predictions[47],predictions[50],\\\n",
        "  #        predictions[56],predictions[62],predictions[65]]#predictions[:layer_end]\n",
        "  # hooks= [predictions[0],predictions[2],predictions[17],predictions[47],predictions[62]] \n",
        "\n",
        "\n",
        "  #these layers were picked as the outputs have diffrent scale dimensions,  we can experimentwith other layers as well.\n",
        "  hooks=[predictions[0],predictions[2],predictions[14],predictions[47],predictions[65]] \n",
        "  \n",
        "  # choose specific channels / filters\n",
        "  for x in hooks:\n",
        "    print('ouput shapes layerwise')\n",
        "    print(x.shape)\n",
        "\n",
        "  \n",
        "  # sal_maps       = [ get_norm(get_smoe_map(np.expand_dims(np.mean(x.numpy()[:,:,:,:,:],axis=-2)[:,:,:,2],axis=-1))) for x in hooks ]\n",
        "\n",
        "  #smoe saliency map\n",
        "  sal_maps       = [ get_norm(get_smoe_map(np.mean(x.numpy()[:,:,:,:,:],axis=-2))) for x in hooks ]\n",
        "\n",
        "  #std dev saliency maps\n",
        "  # sal_maps       = [ get_norm(get_std_map(np.mean(x.numpy()[:,:,:,:,:],axis=-2))) for x in hooks ]\n",
        "\n",
        "  \n",
        "  for smaps in sal_maps:\n",
        "    print(smaps.shape)\n",
        "    \n",
        "  # all layer scale maps with equal weightage\n",
        "  weights=np.ones(len(hooks))\n",
        "  \n",
        "  # all layer scale maps with progressive increasing weightage\n",
        "  # weights=[i+1 for i in range(len(hooks))]\n",
        "  # weights = [i for i in range(len(hooks),0,-1)]\n",
        "  \n",
        "  map_num=len(hooks)\n",
        "\n",
        "  f, axarr = plt.subplots(1,1,figsize=(10,10))\n",
        "  raw=np.mean(img_chunk[0,:,:,:],axis=-1)\n",
        "  raw= raw/np.max(raw)\n",
        "  r=axarr.imshow(raw,cmap='jet')\n",
        "  axarr.set_title('Input image mean along 3rd dimension')\n",
        "  plt.colorbar(r,fraction=0.01, pad=0.04)\n",
        "  plt.savefig(base_path+'mean_input_chunk.png')\n",
        "  plt.close()\n",
        "\n",
        "  csal_maps,sal_maps = combine_sal_maps(sal_maps,output_size=[in_height,in_width],weights=weights,map_num=map_num)\n",
        "  output_path = base_path +'Map_Combined.png'\n",
        "  f, axarr = plt.subplots(1,1,figsize=(10,10))\n",
        "  csal_map=csal_maps[0,:,:].numpy()\n",
        "  imcs=csal_map/np.max(csal_map)\n",
        "  im = axarr.imshow(imcs,cmap='jet')\n",
        "  axarr.set_title('Combined saliency map')\n",
        "  plt.colorbar(im,fraction=0.01, pad=0.04)\n",
        "  plt.savefig(output_path)\n",
        "  plt.close()\n",
        "\n",
        "  il = [sal_maps[0,i,:,:] for i in range(map_num)] # Put each saliency map into the figure\n",
        "  il.append(csal_maps[0,:,:])                       # add in the combined map at the end of the figure\n",
        "  images        = [torch.stack(il, 0)]          \n",
        "  images        = make_grid(images, nrow=5)\n",
        "  sal_img=images.unsqueeze(1)\n",
        "  output_path=base_path +'Sal_Maps.png'\n",
        "  save_image(sal_img,output_path)\n",
        "\n",
        "  input_path = output_path\n",
        "  f, axarr = plt.subplots(1,1,figsize=(10,10))\n",
        "  im=sio.imread(input_path)\n",
        "  im=axarr.imshow(np.mean(im,axis=-1)/255, cmap='jet');\n",
        "  axarr.set_title('layerwise saliency maps')\n",
        "  plt.colorbar(im,fraction=0.01, pad=0.04)\n",
        "  output_path=base_path +'Sal_Maps_jet.png'\n",
        "  plt.savefig(output_path)\n",
        "  plt.close()\n",
        "  return csal_maps\n",
        "\n",
        "\n",
        "'''''''''\n",
        "B: GradCAM /GradCAM++\n",
        "'''''''''\n",
        "\n",
        "def get_grads(layer_name,tf_model,inputs):\n",
        "  '''\n",
        "  computes gradients for GCAM/GCAM++\n",
        "\n",
        "  Arguments:  str: layer_name -> name of the last convolution activation layer.\n",
        "              tf model: model -> tensorflow pretrained model\n",
        "              list: inputs -> [input_image_tensor,gender_tensor]\n",
        "       \n",
        "\n",
        "  Returns: cam_list,grads,y,weights,output,img_chunk\n",
        "  '''\n",
        "\n",
        "  cam_list=[]\n",
        "  gender= inputs[1] #check the gender tensor dimensions tf.constant([[1]],dtype=tf.float32)\n",
        "  gender=tf.reshape(gender,[1,1])\n",
        "  img=inputs[0]\n",
        "  grad_model = tf.keras.models.Model([tf_model.inputs], [tf_model.get_layer(name=layer_name).output, tf_model.output])\n",
        "\n",
        "  img_chunk=tf.convert_to_tensor(img)\n",
        "  img_chunk = tf.reshape(img_chunk,[1,121,145,6])\n",
        "\n",
        "  cdr_ohe_dict={0:[1.0,0.0,0.0,0.0],0.5:[0.0,1.0,0.0,0.0],1:[0.0,0.0,1.0,0.0],2:[0.0,0.0,0.0,1.0]}\n",
        "  cdr_keys= list(cdr_ohe_dict.keys())\n",
        "  with tf.GradientTape() as tape:\n",
        "      conv_outputs, predictions = grad_model([img_chunk,gender])\n",
        "      print(f'predictions={predictions}')\n",
        "     \n",
        "      y = predictions[0] # in case of an extra dimension [[]]\n",
        "     \n",
        "\n",
        "  output = conv_outputs[0]#[0,:,:,:,100]\n",
        "  print(f'entering tape gradients')\n",
        "\n",
        "  grads = tape.gradient(y, conv_outputs)[0]#[0,:,:,:,100]\n",
        "  print(type(grads))\n",
        "  print(f'Crossed tape gradients')\n",
        "  gate_f = tf.cast(output > 0, 'float32')\n",
        "  gate_r = tf.cast(grads > 0, 'float32')\n",
        "  # now there are 2 choice either use grads(raw grads) or use guided grads)\n",
        "  guided_grads = tf.cast(output > 0, 'float32') * tf.cast(grads > 0, 'float32') * grads\n",
        "\n",
        "  print(f'Entering reduce mean using guided_grads with shape={guided_grads.shape}')\n",
        "  #guided grads\n",
        "  weights = tf.reduce_mean(guided_grads, axis=(0,1,2))\n",
        "\n",
        "\n",
        "  print(f'Computing CAM using output with shape:{output.shape}')\n",
        "\n",
        "  print(f'weights={weights.shape}')\n",
        "  cam = np.zeros(output.shape[0:3], dtype=np.float32)\n",
        "  print(cam.shape)\n",
        "\n",
        "\n",
        "  cam=tf.reduce_sum(tf.multiply(output,weights),axis=-1)\n",
        "  cam_list.append(cam)\n",
        "  return cam_list,grads,y,weights,output,img_chunk\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def compute_gcam_and_gcam_pp(layer_name,model,inputs):\n",
        "  '''\n",
        "  Generates GCAM/GCAM++ maps\n",
        "\n",
        "  Arguments:  str: layer_name -> name of the last convolution activation layer.\n",
        "              tf model: model -> tensorflow pretrained model\n",
        "              list: inputs -> [input_image_tensor,gender_tensor]\n",
        "       \n",
        "\n",
        "  Returns: all numpy arrays: image, gcam_img,gcam_pp_img,y ( y is prediction)\n",
        "  '''\n",
        "  cam_list,grads,y,weights,output,img_chunk = get_grads(layer_name,model,inputs)\n",
        "  \n",
        "  heatmap_list=[]\n",
        "  for i,cam in enumerate(cam_list):#as we are doing chunk wise so this camlist will have only one cam\n",
        "\n",
        "    print(f'cam shape={cam.shape}')\n",
        "    \n",
        "    #gcam\n",
        "    cam_map=resize(cam,(img_chunk.shape[1],img_chunk.shape[2],img_chunk.shape[3]))\n",
        "\n",
        "    cam_map = np.maximum(cam_map,0)\n",
        "    original_image=img_chunk.numpy()\n",
        "   \n",
        "    heatmap = (cam_map - cam_map.min()) / (cam_map.max() - cam_map.min())\n",
        "\n",
        "  \n",
        "    print(original_image.shape)\n",
        "    image=np.mean(original_image[0,:,:,:],axis=-1)\n",
        "    print(image.shape)\n",
        "\n",
        "    mri_img=image#np.squeeze(image)\n",
        "    heatmap_list.append(heatmap)\n",
        "\n",
        "\n",
        "    heatmap_gcam = (cam_map - cam_map.min()) / (cam_map.max() - cam_map.min())\n",
        "\n",
        "      \n",
        "      \n",
        "    gcam_img=(np.mean(heatmap_gcam,axis=-1)* 255).astype(\"uint8\")\n",
        "   \n",
        "    #gcam++\n",
        "    print(f'grads shape ={grads.shape},tf.exp(y) shape={tf.exp(y).shape}')\n",
        "    conv_first_grad = tf.exp(y)[0]*grads\n",
        "    #second_derivative\n",
        "    conv_second_grad = tf.exp(y)[0]*grads*grads\n",
        "    #triple_derivative\n",
        "    conv_third_grad = tf.exp(y)[0]*grads*grads*grads\n",
        "    \n",
        "    global_sum = np.sum(tf.reshape(output,(-1,conv_first_grad[0].shape[2])), axis=0)\n",
        "    print(f'conv_first_grad shape={conv_first_grad.shape},conv_second_grad shape={conv_second_grad.shape} ,  conv_third_grad shape={conv_third_grad.shape}, global_sum.shape={global_sum.shape}  ')\n",
        "    alpha_num = conv_second_grad[0]\n",
        "    # alpha_denom = conv_second_grad[0]*2.0 + conv_third_grad[0]*global_sum.reshape((1,1,conv_first_grad[0].shape[2]))\n",
        "    alpha_denom = conv_second_grad*2.0 + conv_third_grad*global_sum.reshape((1,1,1,conv_first_grad[0].shape[2]))\n",
        "    alpha_denom = np.where(alpha_denom != 0.0, alpha_denom, np.ones(alpha_denom.shape))\n",
        "    alphas = alpha_num/alpha_denom\n",
        "\n",
        "    \n",
        "\n",
        "    alphas_thresholding = np.where(weights, alphas, 0.0)\n",
        "    print(f'alphas_thresholding shape={alphas_thresholding.shape}')\n",
        "    alpha_normalization_constant = np.sum(np.sum(alphas_thresholding, axis=0),axis=0)\n",
        "    alpha_normalization_constant_processed = np.where(alpha_normalization_constant != 0.0, alpha_normalization_constant, np.ones(alpha_normalization_constant.shape))\n",
        "    print(f'alpha_normalization_constant_processed shape={alpha_normalization_constant_processed.shape}')\n",
        "    \n",
        "    # alphas /= alpha_normalization_constant_processed.reshape((1,1,conv_first_grad[0].shape[2]))\n",
        "    alphas /= alpha_normalization_constant_processed.reshape((1,1,3,conv_first_grad[0].shape[2]))\n",
        "    print(f'weights.shape={weights.shape},alphas.shape={alphas.shape}')\n",
        "    weights_alpha=tf.reduce_sum(tf.multiply(weights,alphas),axis=0)\n",
        "    \n",
        "    cam=tf.reduce_sum(tf.multiply(output,weights_alpha),axis=-1)\n",
        "    \n",
        "    cam_map=resize(cam,(img_chunk.shape[1],img_chunk.shape[2],img_chunk.shape[3]))\n",
        "  \n",
        "    \n",
        "    print(f'cam_map={cam_map.shape}')\n",
        "    cam_map = np.maximum(cam_map, 0)\n",
        "\n",
        "    heatmap_gcam_pp = (cam_map - cam_map.min()) / (cam_map.max() - cam_map.min())\n",
        "\n",
        "\n",
        "    gcam_pp_img=(np.mean(heatmap_gcam_pp,axis=-1) * 255).astype(\"uint8\")\n",
        "    \n",
        "    print(img_chunk.shape,mri_img.shape,gcam_img.shape,type(mri_img),type(gcam_img))\n",
        "  \n",
        "        \n",
        "    return image, gcam_img,gcam_pp_img,y\n",
        "\n",
        "\n",
        "'''''''''\n",
        "C: Combine Saliency Maps with GradCAM /GradCAM++\n",
        "'''''''''\n",
        "\n",
        "def combine_sal_gcam(base_path,csmap,gcam_img,gcam_pp_img,image,layer_name='',angle=0,result_path='' ):\n",
        "\n",
        "  '''\n",
        "  Arguments:  str: base_path -> base path to store .mat files for maps\n",
        "              torch.Tensor: csmap -> combined saliency map \n",
        "              numpy array: gcam_pp_img -> gradcam map\n",
        "              numpy array: gcam_pp_img -> gradcam ++ map\n",
        "              numpy array: image -> image with size (121,145) , a mean is performed on third axis to create 2D maps for 3D inputs.\n",
        "              str: layer_name -> name of the last convolution activation layer.\n",
        "              float: angle  -> rotation angle for the final result.\n",
        "              str: result_path -> path to store only final results and exclude supplementary files which are save in base_path\n",
        "\n",
        "  Returns: all lists: scans,labels,gender,ids,cdr\n",
        "\n",
        "\n",
        "  3 kinds of map computed : saliency map , saliency map combined  with GCAM, saliency map combined with GCAM++ \n",
        "\n",
        "  For each map following intermediate output arrays are important in this function block:\n",
        "\n",
        "  - Gray matter:\n",
        "  raw_tensor\n",
        "\n",
        "  -  Saliency Map\n",
        "  csmap\n",
        "\n",
        "  - GradCAM Map\n",
        "  gcam_img\n",
        "\n",
        "  - GradCAM ++ Map\n",
        "  gcam_pp_img\n",
        "  \n",
        "  - Alpha Blending : eg: 0.75*map + 0.25*gray\n",
        "\n",
        "  result_*      (i.e. result_csmap --> only saliency map, result_gcam---> saliency+gradcam,  result_gcam_pp --> saliency + gcam++)\n",
        "  \n",
        "  - Hard Masked top x% pixels\n",
        "  hard_masked_* (i.e. hard_masked_csmap --> only saliency map, hard_masked_gcam---> saliency+gradcam,  hard_masked_gcam_pp --> saliency + gcam++)\n",
        "\n",
        "  - Alpha Mask : gray*map\n",
        "  ***** This is the one we used in our to be published paper and results , we use this and then remove its blue background and overlay on gray *****\n",
        "  masked_*  (i.e. masked_csmap --> only saliency map, masked_gcam---> saliency+gradcam,  masked_gcam_pp --> saliency + gcam++)\n",
        "\n",
        "  '''\n",
        "  print(gcam_img.shape,csmap.shape,gcam_pp_img.shape,image.shape)\n",
        "\n",
        "  '''\n",
        "  I : Only the Saliency Map\n",
        "  '''\n",
        "  raw_tensor=torch.from_numpy(image).unsqueeze(0)\n",
        "\n",
        "  # saving gray matter\n",
        "  \n",
        "  output_path   = base_path+\"raw_img.mat\"\n",
        "  savemat(output_path,{'data':raw_tensor.numpy() ,'shape':raw_tensor.shape})\n",
        "  background_img=loadmat(output_path)['data']\n",
        "\n",
        "  base_path+='_'+layer_name\n",
        "\n",
        "\n",
        "  heatmap_csmap, result_csmap = visualize_cam(csmap, raw_tensor) \n",
        "  getMask                 = mask.SaliencyMaskDropout(keep_percent = 0.1, scale_map=False)\n",
        "  hard_masked_csmap,_       = getMask(raw_tensor.unsqueeze(0),csmap)#.squeeze(0))\n",
        "  hard_masked_csmap        = hard_masked_csmap.squeeze(0)\n",
        "  masked_csmap             = misc.AlphaMask(raw_tensor, csmap.squeeze(0)).squeeze(0)\n",
        "  \n",
        "  \n",
        "\n",
        "  # Supplementary plots not important\n",
        "\n",
        "  vmin=0\n",
        "  vmax=1.0\n",
        "  f, axarr = plt.subplots(2,3,figsize=(20,20))\n",
        "  img_plot = axarr[0][0].imshow(torch.mean(raw_tensor,axis=0),vmin=vmin,vmax=vmax, cmap='jet');\n",
        "  axarr[0][0].set_title('input')\n",
        "  cbar=plt.colorbar(img_plot,fraction=0.046, pad=0.04,ax=axarr[0][0])\n",
        "  cbar.set_clim(0,1)\n",
        "  img_plot = axarr[0][1].imshow(torch.mean(csmap,axis=0),vmin=vmin,vmax=vmax, cmap='jet');\n",
        "  axarr[0][1].set_title('combined saliency map')\n",
        "  cbar=plt.colorbar(img_plot,fraction=0.046, pad=0.04,ax=axarr[0][1])\n",
        "  cbar.set_clim(0,1)\n",
        "  img_plot = axarr[0][2].imshow(torch.mean(heatmap_csmap,axis=0),vmin=vmin,vmax=vmax, cmap='jet');\n",
        "  axarr[0][2].set_title('saliency map')\n",
        "  cbar=plt.colorbar(img_plot,fraction=0.046, pad=0.04,ax=axarr[0][2])\n",
        "  cbar.set_clim(0,1)\n",
        "  img_plot = axarr[1][0].imshow(torch.mean(result_csmap,axis=0),vmin=vmin,vmax=vmax, cmap='jet');\n",
        "  axarr[1][0].set_title('saliency map with alpha blend')\n",
        "  cbar=plt.colorbar(img_plot,fraction=0.046, pad=0.04,ax=axarr[1][0])\n",
        "  cbar.set_clim(0,1)\n",
        "  img_plot = axarr[1][1].imshow(masked_csmap,vmin=vmin,vmax=vmax, cmap='jet');\n",
        "  axarr[1][1].set_title('saliency map with alpha mask')\n",
        "  cbar=plt.colorbar(img_plot,fraction=0.046, pad=0.04,ax=axarr[1][1])\n",
        "  cbar.set_clim(0,1)\n",
        "  img_plot = axarr[1][2].imshow(hard_masked_csmap[0],vmin=vmin,vmax=vmax, cmap='jet');\n",
        "  axarr[1][2].set_title('hard mask')\n",
        "  cbar=plt.colorbar(img_plot,fraction=0.046, pad=0.04,ax=axarr[1][2])\n",
        "  cbar.set_clim(0,1)\n",
        "  plt.savefig(base_path+'saliency_only_fig.png')\n",
        "  plt.close()\n",
        "\n",
        "  print(hard_masked_csmap.permute([2,0,1]).shape)\n",
        "\n",
        "  #IMPORTANT files for Saliency MAP: Actual .mat files.#########################\n",
        "  csmap_img = torch.mean(csmap,axis=0).numpy()\n",
        "  output_path   = base_path+\"csmap.mat\"\n",
        "  savemat(output_path,{'data':csmap_img ,'shape':csmap_img.shape})\n",
        "  output_path   = base_path+\"heatmap_csmap.mat\"\n",
        "  savemat(output_path,{'data':heatmap_csmap.permute([1,2,0]).numpy() ,'shape':heatmap_csmap.permute([1,2,0]).numpy().shape})\n",
        "  output_path   = base_path+\"result_csmap.mat\"\n",
        "  savemat(output_path,{'data':result_csmap.permute([1,2,0]).numpy() ,'shape':result_csmap.permute([1,2,0]).numpy().shape})\n",
        "  output_path   = base_path+\"hard_masked_csmap.mat\" \n",
        "  savemat(output_path,{'data':hard_masked_csmap.permute([1,2,0]).numpy() ,'shape':hard_masked_csmap.permute([1,2,0]).shape})\n",
        "  output_path   = base_path+\"masked_csmap.mat\" \n",
        "  savemat(output_path,{'data':masked_csmap.numpy() ,'shape':masked_csmap.numpy().shape})\n",
        "  masked_csmap_mat = loadmat(output_path)['data']\n",
        "  plt.clf()\n",
        "  # p=plt.imshow(masked_csmap_mat,cmap='jet')\n",
        "  # plt.colorbar(p)      \n",
        "  # plt.clim(0.8,1)\n",
        "  # output_path   = base_path+\"masked_csmap_0.8.png\" \n",
        "  # plt.savefig(output_path)\n",
        "  # plt.close()\n",
        "\n",
        "  ##############################################################################\n",
        "  \n",
        "  # to avoid any divide by zero\n",
        "  if np.max(gcam_img) ==0:\n",
        "    gcam_img = gcam_img+0.0000001\n",
        "  if np.max(gcam_pp_img) ==0:\n",
        "    gcam_pp_img = gcam_pp_img+0.0000001\n",
        "  gcam_img_tensor=torch.from_numpy(gcam_img).unsqueeze(0)\n",
        "  mask_gcam = csmap*(gcam_img_tensor)\n",
        "  mask_gcam=mask_gcam/mask_gcam.max()\n",
        "\n",
        "\n",
        "  \n",
        "  \n",
        "  #save gcam and gcam++ map side by side fig\n",
        "  vmin=np.amin([np.min(gcam_img),np.min(gcam_pp_img)])\n",
        "  vmax=np.amax([np.max(gcam_img),np.max(gcam_pp_img)])\n",
        "\n",
        "  f, axarr = plt.subplots(1,2,figsize=(10,10))\n",
        "  img_plot = axarr[0].imshow(gcam_img,vmin=vmin,vmax=vmax, cmap='jet');\n",
        "  axarr[0].set_title('Gradcam')\n",
        "  img_plot = axarr[1].imshow(gcam_pp_img,vmin=vmin,vmax=vmax, cmap='jet');\n",
        "  axarr[1].set_title('Gradcam++')\n",
        "  plt.colorbar(img_plot,fraction=0.046, pad=0.04)\n",
        "  plt.savefig(base_path+'gcam_gcam++_fig.png')\n",
        "  plt.close()\n",
        "\n",
        "  \n",
        "  \n",
        "  '''\n",
        "  II: Saliency + GRADCAM\n",
        "  '''\n",
        "  \n",
        "  heatmap_gcam, result_gcam = visualize_cam(mask_gcam, raw_tensor) \n",
        "  getMask                 = mask.SaliencyMaskDropout(keep_percent = 0.1, scale_map=False)\n",
        "  hard_masked_gcam,_       = getMask(raw_tensor.unsqueeze(0),mask_gcam)#.squeeze(0))\n",
        "  hard_masked_gcam        = hard_masked_gcam.squeeze(0)\n",
        "  masked_gcam             = misc.AlphaMask(raw_tensor, mask_gcam.squeeze(0)).squeeze(0)\n",
        "  # mx= str(np.max(masked_gcam.numpy()))\n",
        "  # plt.imsave(base_path+'masked_gcam_unnormalized_{0}max.png'.format(mx),masked_gcam.numpy(),cmap='jet')\n",
        "  # masked_gcam              = misc.RangeNormalize(masked_gcam)\n",
        "\n",
        "  # Supplementary plots not important\n",
        "\n",
        "  vmin=0\n",
        "  vmax=1.0\n",
        "  f, axarr = plt.subplots(2,3,figsize=(20,20))\n",
        "  img_plot = axarr[0][0].imshow(torch.mean(raw_tensor,axis=0),vmin=vmin,vmax=vmax, cmap='jet');\n",
        "  axarr[0][0].set_title('input')\n",
        "  cbar=plt.colorbar(img_plot,fraction=0.046, pad=0.04,ax=axarr[0][0])\n",
        "  cbar.set_clim(0,1)\n",
        "  img_plot = axarr[0][1].imshow(torch.mean(csmap,axis=0),vmin=vmin,vmax=vmax, cmap='jet');\n",
        "  axarr[0][1].set_title('combined saliency map')\n",
        "  cbar=plt.colorbar(img_plot,fraction=0.046, pad=0.04,ax=axarr[0][1])\n",
        "  cbar.set_clim(0,1)\n",
        "  img_plot = axarr[0][2].imshow(torch.mean(heatmap_gcam,axis=0),vmin=vmin,vmax=vmax, cmap='jet');\n",
        "  axarr[0][2].set_title('saliency map + gradcam')\n",
        "  cbar=plt.colorbar(img_plot,fraction=0.046, pad=0.04,ax=axarr[0][2])\n",
        "  cbar.set_clim(0,1)\n",
        "  img_plot = axarr[1][0].imshow(torch.mean(result_gcam,axis=0),vmin=vmin,vmax=vmax, cmap='jet');\n",
        "  axarr[1][0].set_title('saliency map+gradcam with alpha blend')\n",
        "  cbar=plt.colorbar(img_plot,fraction=0.046, pad=0.04,ax=axarr[1][0])\n",
        "  cbar.set_clim(0,1)\n",
        "  img_plot = axarr[1][1].imshow(masked_gcam,vmin=vmin,vmax=vmax, cmap='jet');\n",
        "  axarr[1][1].set_title('saliency map+gradcam with alpha mask')\n",
        "  cbar=plt.colorbar(img_plot,fraction=0.046, pad=0.04,ax=axarr[1][1])\n",
        "  cbar.set_clim(0,1)\n",
        "  img_plot = axarr[1][2].imshow(hard_masked_gcam[0],vmin=vmin,vmax=vmax, cmap='jet');\n",
        "  axarr[1][2].set_title('hard mask')\n",
        "  cbar=plt.colorbar(img_plot,fraction=0.046, pad=0.04,ax=axarr[1][2])\n",
        "  cbar.set_clim(0,1)\n",
        "  plt.savefig(base_path+'sal+gcam_fig.png')\n",
        "  plt.close()\n",
        "\n",
        "  print(hard_masked_gcam.permute([2,0,1]).shape)\n",
        "\n",
        "  #IMPORTANT files for Saliency MAP + GradCAM : Actual .mat files.##############\n",
        "  output_path   = base_path+\"gcam_img.mat\"\n",
        "  savemat(output_path,{'data':gcam_img ,'shape':gcam_img.shape})\n",
        "  output_path   = base_path+\"heatmap_gcam.mat\"\n",
        "  savemat(output_path,{'data':heatmap_gcam.permute([1,2,0]).numpy() ,'shape':heatmap_gcam.permute([1,2,0]).numpy().shape})\n",
        "  output_path   = base_path+\"result_gcam.mat\"\n",
        "  savemat(output_path,{'data':result_gcam.permute([1,2,0]).numpy() ,'shape':result_gcam.permute([1,2,0]).numpy().shape})\n",
        "  output_path   = base_path+\"hard_masked_gcam.mat\" \n",
        "  savemat(output_path,{'data':hard_masked_gcam.permute([1,2,0]).numpy() ,'shape':hard_masked_gcam.permute([1,2,0]).shape})\n",
        "  output_path   = base_path+\"masked_gcam.mat\" \n",
        "  savemat(output_path,{'data':masked_gcam.numpy() ,'shape':masked_gcam.numpy().shape})\n",
        "  masked_gcam_mat = loadmat(output_path)['data']\n",
        "  plt.clf()\n",
        "  # p=plt.imshow(masked_gcam_mat,cmap='jet')\n",
        "  # plt.colorbar(p)      \n",
        "  # plt.clim(0.8,1)\n",
        "  # output_path   = base_path+\"masked_gcam_0.8.png\" \n",
        "  # plt.savefig(output_path)\n",
        "  # plt.close()\n",
        "\n",
        "  ##############################################################################\n",
        "  '''\n",
        "  III: Saliency + GRADCAM++\n",
        "  '''\n",
        "  gcam_pp_img_tensor=torch.from_numpy(gcam_pp_img).unsqueeze(0)\n",
        "  mask_gcam_pp = csmap*(gcam_pp_img_tensor)\n",
        "  mask_gcam_pp=mask_gcam_pp/mask_gcam_pp.max()\n",
        "  raw_tensor=torch.from_numpy(image).unsqueeze(0)\n",
        "  heatmap_gcam_pp, result_gcam_pp = visualize_cam(mask_gcam_pp, raw_tensor)\n",
        "\n",
        "  hard_masked_gcam_pp,_       = getMask(raw_tensor.unsqueeze(0),mask_gcam_pp)#.squeeze(0))\n",
        "  hard_masked_gcam_pp         = hard_masked_gcam_pp.squeeze(0)\n",
        "  masked_gcam_pp           = misc.AlphaMask(raw_tensor, mask_gcam_pp.squeeze(0)).squeeze(0)\n",
        "  # mx= str(np.max(masked_gcam_pp.numpy()))\n",
        "  # plt.imsave(base_path+'masked_gcam_pp_unnormalized_{0}max.png'.format(mx),masked_gcam_pp.numpy(),cmap='jet')\n",
        "  # masked_gcam_pp           = misc.RangeNormalize(masked_gcam_pp) # avoid this step as it will normalize to 0 to 1 hence not good while comparing multiple scans\n",
        "\n",
        "  \n",
        "\n",
        "  \n",
        "  \n",
        "  \n",
        "  # Supplementary plots not important\n",
        "\n",
        "  vmin=np.amin([torch.min(raw_tensor),torch.min(csmap),torch.min(heatmap_gcam_pp),torch.min(result_gcam_pp),torch.min(masked_gcam_pp),torch.min(hard_masked_gcam_pp)])\n",
        "  vmax=np.amax([torch.max(raw_tensor),torch.max(csmap),torch.max(heatmap_gcam_pp),torch.max(result_gcam_pp),torch.max(masked_gcam_pp),torch.max(hard_masked_gcam_pp)])\n",
        "\n",
        "  vmin=0\n",
        "  vmax=1.0\n",
        "\n",
        "  f, axarr = plt.subplots(2,3,figsize=(20,20))\n",
        "  img_plot = axarr[0][0].imshow(torch.mean(raw_tensor,axis=0),vmin=vmin,vmax=vmax, cmap='jet');\n",
        "  axarr[0][0].set_title('input')\n",
        "  cbar=plt.colorbar(img_plot,fraction=0.046, pad=0.04,ax=axarr[0][0])\n",
        "  cbar.set_clim(0,1)\n",
        "  img_plot = axarr[0][1].imshow(torch.mean(csmap,axis=0),vmin=vmin,vmax=vmax, cmap='jet');\n",
        "  axarr[0][1].set_title('combined saliency map')\n",
        "  cbar=plt.colorbar(img_plot,fraction=0.046, pad=0.04,ax=axarr[0][1])\n",
        "  cbar.set_clim(0,1)\n",
        "  img_plot = axarr[0][2].imshow(torch.mean(heatmap_gcam_pp,axis=0),vmin=vmin,vmax=vmax, cmap='jet');\n",
        "  axarr[0][2].set_title('saliency map + gradcam++')\n",
        "  cbar=plt.colorbar(img_plot,fraction=0.046, pad=0.04,ax=axarr[0][2])\n",
        "  cbar.set_clim(0,1)\n",
        "  img_plot = axarr[1][0].imshow(torch.mean(result_gcam_pp,axis=0),vmin=vmin,vmax=vmax, cmap='jet');\n",
        "  axarr[1][0].set_title('saliency map+gradcam++ with alpha blend')\n",
        "  cbar=plt.colorbar(img_plot,fraction=0.046, pad=0.04,ax=axarr[1][0])\n",
        "  cbar.set_clim(0,1)\n",
        "  img_plot = axarr[1][1].imshow(masked_gcam_pp,vmin=vmin,vmax=vmax, cmap='jet');\n",
        "  axarr[1][1].set_title('saliency map+gradcam++ with alpha mask')\n",
        "  cbar=plt.colorbar(img_plot,fraction=0.046, pad=0.04,ax=axarr[1][1])\n",
        "  cbar.set_clim(0,1)\n",
        "  img_plot = axarr[1][2].imshow(hard_masked_gcam_pp[0],vmin=vmin,vmax=vmax, cmap='jet');\n",
        "  axarr[1][2].set_title('hard mask')\n",
        "  cbar=plt.colorbar(img_plot,fraction=0.046, pad=0.04,ax=axarr[1][2])\n",
        "  cbar.set_clim(0,1)\n",
        "  plt.savefig(base_path+'sal+gcam++_fig.png')\n",
        "  plt.close()\n",
        "\n",
        "\n",
        "  raw_img = torch.mean(raw_tensor,axis=0).numpy()\n",
        "  output_path   = base_path+\"raw_input.png\"\n",
        "  savemat(output_path.split('.png')[0] +'.mat',{'data':raw_img ,'shape':raw_img.shape})\n",
        "\n",
        "  f, axarr = plt.subplots(1,1,figsize=(10,10))\n",
        "  \n",
        "  r=axarr.imshow(raw_img,cmap='gray')\n",
        "  axarr.set_title('raw gray image')\n",
        "  cbar=plt.colorbar(r,fraction=0.046, pad=0.04)\n",
        "  cbar.set_clim(0,1)\n",
        "  plt.savefig(base_path+'raw_gray_cbar.png')\n",
        "  plt.close()\n",
        "\n",
        "  #IMPORTANT files for Saliency MAP + GradCAM : Actual .mat files.##############\n",
        "  output_path   = base_path+\"gcam_pp_img.mat\"\n",
        "  savemat(output_path,{'data':gcam_pp_img ,'shape':gcam_pp_img.shape})\n",
        "  output_path   = base_path+\"heatmap_gcam_pp.mat\"\n",
        "  savemat(output_path,{'data':heatmap_gcam_pp.permute([1,2,0]).numpy() ,'shape':heatmap_gcam_pp.permute([1,2,0]).numpy().shape})\n",
        "  output_path   = base_path+\"result_gcam_pp.mat\"\n",
        "  savemat(output_path,{'data':result_gcam_pp.permute([1,2,0]).numpy() ,'shape':result_gcam_pp.permute([1,2,0]).numpy().shape})\n",
        "  output_path   = base_path+\"hard_masked_gcam_pp.mat\" \n",
        "  savemat(output_path,{'data':hard_masked_gcam_pp.permute([1,2,0]).numpy() ,'shape':hard_masked_gcam_pp.permute([1,2,0]).numpy().shape})\n",
        "  output_path   = base_path+\"masked_gcam_pp.mat\" \n",
        "  savemat(output_path,{'data':masked_gcam_pp.numpy() ,'shape':masked_gcam_pp.numpy().shape})\n",
        "  masked_gcam_pp_mat = loadmat(output_path)['data']\n",
        "  plt.clf()\n",
        "  # p=plt.imshow(masked_gcam_pp_mat,cmap='jet')\n",
        "  # plt.colorbar(p)      \n",
        "  # plt.clim(0.8,1)\n",
        "  # output_path   = base_path+\"masked_gcam_pp_0.8.png\" \n",
        "  # plt.savefig(output_path)\n",
        "  ##############################################################################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  ### VERY IMPORTANT: Final Result images begin ################################\n",
        "\n",
        "  # Just the Background Removed Mask\n",
        "  im=ndimage.rotate(masked_gcam_pp_mat,angle)\n",
        "  max=1\n",
        "  im = im/max #optional step as in our case max is 1 also use any contant val.\n",
        "\n",
        "  im[im<0.3]=np.nan\n",
        "  plt.imshow(im,cmap='jet')\n",
        "  plt.axis('off')\n",
        "  plt.clim(0,1)\n",
        "  plt.savefig(result_path+'_result.png')\n",
        "  plt.close()\n",
        "  \n",
        "  \n",
        "  '''\n",
        "  These are the images used in the final results the ones inside result_path\n",
        "  '''\n",
        "\n",
        "  # Background Removed Mask + Overlay \n",
        "\n",
        "  plt.clf() # clear existing figure\n",
        "  #mask overlaid on gray matter\n",
        "  print(f'background shape before={background_img.shape}')\n",
        "  im2=background_img[0]\n",
        "  print(f'background shape after={im2.shape}')\n",
        "  im2=ndimage.rotate(im2,angle)\n",
        "  im2=1-im2\n",
        "  gray=plt.imshow(im2,cmap='gray')\n",
        "  plt.axis('off')\n",
        "  im=ndimage.rotate(masked_gcam_pp_mat,angle)\n",
        "  im[im<0.3]=np.nan\n",
        "  heat=plt.imshow(im,cmap='jet')\n",
        "  plt.axis('off')\n",
        "  plt.clim(0,1)\n",
        "  plt.colorbar()\n",
        "  plt.savefig(result_path+'_result_overlay.png')\n",
        "  plt.close()\n",
        "\n",
        "  ######### Final Result images end ############################################\n",
        " \n",
        "\n",
        "  ## Below section is to experiment different masking thresholds################# \n",
        "\n",
        "\n",
        "  ## Saliency only\n",
        "  masked_csmap=masked_csmap.numpy()\n",
        "\n",
        "  t='masked_only_saliency'\n",
        "\n",
        "\n",
        "\n",
        "  max =  1 #or use any other constant\n",
        "  \n",
        "  frac=0.3 #0.5,0.8\n",
        "  r1=(masked_csmap/max)\n",
        "\n",
        "  r1[np.where(r1<frac*np.max(r1))]=0\n",
        "  # r1[np.where(r1<np.median(r1))]=0\n",
        "  plt.imsave(base_path+'nodiff_{0}_{1}.png'.format(frac,t),r1,cmap='jet')\n",
        "\n",
        "  ## GCAM\n",
        "  masked_gcam=masked_gcam.numpy()\n",
        "  t='masked_gcam'\n",
        "\n",
        "  max =  1 #np.amax(masked_gcam)\n",
        "\n",
        "  frac=0.3 # 0.5, 0.8 \n",
        "  r1=(masked_gcam/max)\n",
        "\n",
        "  r1[np.where(r1<frac*np.max(r1))]=0\n",
        "  # r1[np.where(r1<np.median(r1))]=0\n",
        "  plt.imsave(base_path+'nodiff_{0}_{1}.png'.format(frac,t),r1,cmap='jet')\n",
        "\n",
        "\n",
        "\n",
        "  ## GCAM++\n",
        "  ## fraction mask  map for overlaying GCAM++\n",
        "  masked_gcam_pp=masked_gcam_pp.numpy()\n",
        "\n",
        "  \n",
        "\n",
        "  t='masked_gcam_pp'\n",
        "  max = 1 #np.amax(masked_gcam_pp)\n",
        "\n",
        "  frac=0.3 #0.5,0.8\n",
        "  r1=(masked_gcam_pp/max)\n",
        "\n",
        "  r1[np.where(r1<frac*np.max(r1))]=0\n",
        "  # r1[np.where(r1<np.median(r1))]=0\n",
        "  plt.imsave(base_path+'nodiff_{0}_{1}.png'.format(frac,t),r1,cmap='jet')\n",
        "  \n",
        "  \n"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'fastcam'\n",
            "/content/fastcam\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-gWgUmHBPYo",
        "colab_type": "text"
      },
      "source": [
        "# **Tf records loading and parsing utility**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Se5RUfMZtqUF",
        "colab_type": "text"
      },
      "source": [
        "### This section parses through the tfrecords and reads through corresponding cdrs , genders and labels and returns along with the parsed image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87R0vSUNBOVI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_selected_scan_from_subjects(data_path,subject_ids,label_df,selected_scans):\n",
        "    '''\n",
        "    Same as get_scan_from_subjects in case we need specific scan path and not all scans of a patient.\n",
        "    Arguments: str: data_path -> path to tfrecords data\n",
        "               str: subject_ids -> list of subjects\n",
        "              list: label_df -> dataframe of full csv file i.e.  oasis1_oasis3_labels.csv\n",
        "              list: selected_scans -> which scans for the above subjects is needed\n",
        "    Returns: all lists: scans,labels,gender,ids,cdr\n",
        "    '''\n",
        "    scans=[]\n",
        "    labels=[]\n",
        "    gender=[]\n",
        "    cdr=[]\n",
        "    ids=[]\n",
        "    subject_ids = set(subject_ids)\n",
        "    for subject in subject_ids :\n",
        "        path=os.path.join(data_path,subject)\n",
        "        paths=os.listdir(path)\n",
        "\n",
        "        ids.extend([scan_id.split('.')[0] for scan_id in paths  if scan_id.split('/')[-1].split('.')[0] in selected_scans ])\n",
        "        scans.extend([ os.path.join(path,scan_id) for scan_id in paths   if scan_id.split('/')[-1].split('.')[0] in selected_scans ])\n",
        "        \n",
        "    \n",
        "        labels.extend([label_df[label_df['MRI ID']==scan_id.split('.')[0]]['Age'].to_list()[0] for scan_id in paths   if scan_id.split('/')[-1].split('.')[0] in selected_scans ])\n",
        "        gender.extend([label_df[label_df['MRI ID']==scan_id.split('.')[0]]['M/F'].to_list()[0] for scan_id in paths   if scan_id.split('/')[-1].split('.')[0] in selected_scans])\n",
        "        cdr.extend([label_df[label_df['MRI ID']==scan_id.split('.')[0]]['CDR'].to_list()[0] for scan_id in paths  if scan_id.split('/')[-1].split('.')[0] in selected_scans])\n",
        "\n",
        "    return scans,labels,gender,ids,cdr\n",
        "\n",
        "def get_scan_from_subjects(data_path,subject_ids,label_df):\n",
        "    '''\n",
        "    Computes scan path for the subjects passed.\n",
        "\n",
        "    Arguments: str: data_path -> path to tfrecords data\n",
        "               str: subject_ids -> list of subjects\n",
        "              list: label_df -> dataframe of full csv file i.e.  oasis1_oasis3_labels.csv\n",
        "              list: selected_scans -> which scans for the above subjects is needed\n",
        "\n",
        "    Returns: scans,labels,gender,ids,cdr\n",
        "    '''\n",
        "    scans=[]\n",
        "    labels=[]\n",
        "    gender=[]\n",
        "    cdr=[]\n",
        "    ids=[]\n",
        "    subject_ids = set(subject_ids)\n",
        "    for subject in subject_ids :\n",
        "        path=os.path.join(data_path,subject)\n",
        "        paths=os.listdir(path)\n",
        "        ids.extend([scan_id.split('.')[0] for scan_id in paths ])\n",
        "        scans.extend([ os.path.join(path,scan_path) for scan_path in paths  ])\n",
        " \n",
        "        labels.extend([label_df[label_df['MRI ID']==scan_id.split('.')[0]]['Age'].to_list()[0] for scan_id in paths   ])\n",
        "        gender.extend([label_df[label_df['MRI ID']==scan_id.split('.')[0]]['M/F'].to_list()[0] for scan_id in paths  ])\n",
        "        cdr.extend([label_df[label_df['MRI ID']==scan_id.split('.')[0]]['CDR'].to_list()[0] for scan_id in paths ])\n",
        "    #print(labels,gender)\n",
        "           \n",
        "    # shuffle(scans)\n",
        "    \n",
        "    return scans,labels,gender,ids,cdr\n",
        "\n",
        "\n",
        "def get_test_files(label_path,data_path,debug_mode_subject=None,selected_scans=[]):\n",
        "    '''\n",
        "    Primary function to get scans.\n",
        "    Arguments: str: label_path -> path to full csv file i.e.  oasis1_oasis3_labels.csv\n",
        "              str: data_path -> path to tfrecord data (organised as : path_to_tfrecord/subject/scan_id.tfrecord, eg: path_to_tfrecord/OAS30001/OAS30001_MR_d0001.tfrecord )\n",
        "              list: debug_mode_subject -> list of subjects to be used\n",
        "              list: selected_scans(optional) -> which scans for the above subjects is needed\n",
        "\n",
        "    Returns: all lists: test_patients,scan_ids, test_labels,test_gender,test_cdr\n",
        "\n",
        "    '''\n",
        "\n",
        "    data = pd.read_csv(label_path)\n",
        "    data = data.rename(columns={'MR ID':'MRI ID'})\n",
        "    print(data.columns)\n",
        "    \n",
        "    data['M/F'] = encode_gender(data)\n",
        "    \n",
        "    if debug_mode_subject is None:\n",
        "      test_ids = os.listdir(data_path)\n",
        "    else:\n",
        "      test_ids=debug_mode_subject\n",
        "    \n",
        "    shuffle(test_ids)\n",
        "    if len(selected_scans)>0:\n",
        "      test_patients,test_labels,test_gender,scan_ids,test_cdr = get_selected_scan_from_subjects(data_path,test_ids,data,selected_scans)\n",
        "    else:\n",
        "      test_patients,test_labels,test_gender,scan_ids,test_cdr = get_scan_from_subjects(data_path,test_ids,data)\n",
        "   \n",
        "    return test_patients,scan_ids, test_labels,test_gender,test_cdr\n",
        "   \n",
        "def encode_gender(data):\n",
        "    '''\n",
        "    Categorical encoding. for gender required only if the column has string data eg: 'F', 'M'\n",
        "    Female : 0\n",
        "    Male : 1\n",
        "\n",
        "    Arguments:  DataFrame df\n",
        "    Returns: Encoded gender column.\n",
        "    '''\n",
        "    data['M/F'] = pd.Categorical(data['M/F'])\n",
        "    \n",
        "    return data['M/F'].cat.codes\n",
        "\n",
        "def parse_function_image(example_proto):\n",
        "\n",
        "    features = {\n",
        "        'image': tf.io.FixedLenFeature([], tf.string),\n",
        "        'image_shape': tf.io.FixedLenFeature([], tf.string)\n",
        "    }\n",
        "\n",
        "    content = tf.io.parse_single_example(example_proto, features=features)\n",
        "\n",
        "    content['image_shape'] = tf.io.decode_raw(content['image_shape'], tf.int32)\n",
        "    content['image'] = tf.io.decode_raw(content['image'], tf.float32)\n",
        "    content['image'] = tf.reshape(content['image'], content['image_shape'])\n",
        "\n",
        "    return content['image']\n"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgIqdczJWDry",
        "colab_type": "text"
      },
      "source": [
        "# **Visualize maps on BA estimation agenet model on testset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFbUj9C5t9ha",
        "colab_type": "text"
      },
      "source": [
        "### We first use the below config dictionary to access the BA estimation model path along with the tfrecords data path and load the model. \n",
        "\n",
        "### There are in total 3 csv files:\n",
        "**.../BA_Estimation/csv_data/oasis1_oasis3_labels.csv** #csv data for entire dataset\n",
        "\n",
        "**.../BA_Estimation/models/exp_ba/non_outliers.csv** #csv data for non-outliers obtained after cleaning using BA Estimation model\n",
        "\n",
        "**.../BA_Estimation/models/exp_ba/outlier.csv** #csv data for outliers obtained after cleaning using BA Estimation model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGosD0T1mXgL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load model\n",
        "\n",
        "cf={'Pretrained_Model':{'path':'/content/drive/My Drive/BA_Estimation/models/exp_ba/age_net.hdf5'},'Paths':\\\n",
        "      {'labels':'/content/drive/My Drive/BA_Estimation/csv_data/oasis1_oasis3_labels.csv',\\\n",
        "       'test_tfrecord':'/content/drive/My Drive/BA_Estimation/tf_records_data/training_testing_exp4'}}#testing_all_cdr\n",
        "model =  tf.python.keras.models.load_model(cf['Pretrained_Model']['path'],compile=False)\n"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSTo1TKsuR4n",
        "colab_type": "text"
      },
      "source": [
        "### Once the model is loaded we specify the subjects by passing a list argument to the function **get_test_files()** as follows: \n",
        "\n",
        "### **For eg:**\n",
        "\n",
        "### **get_test_files**(label_path,data_path,debug_mode_subject=['OAS31098','OAS31156'],selected_scans=[ ]) \\# gets all scans belonging to these 2 subjects\n",
        "**OR**\n",
        "### **get_test_files**(label_path,data_path,debug_mode_subject=['OAS31098','OAS31156'],selected_scans=['OAS31098_MR_d7178','OAS301156_MR_d0001']) \\# gets only specified scans belonging to these 2 subjects\n",
        "**OR**\n",
        "### **get_test_files**(label_path,data_path,debug_mode_subject=None) \\# gets all scans belonging to all subjects in the tfrecord directory cf['test_tfrecord']\n",
        "\n",
        "**OR**\n",
        "### **sub,scans**=**get_subject_scan_names_from_filtered_data**(df) \\# dataframe: df,  can be either of healthy subject belonging to non_outliers.csv or AD subjects belonging to outlier.csv\n",
        "### **get_test_files**(label_path,data_path,debug_mode_subject=sub,selected_scans=scans) \\# for every subject in list: sub, it gets the corresponding scans in list: selected_scans ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xraNmsrPXr2v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_subject_scan_names_from_filtered_data(df): \n",
        "  '''\n",
        "  Arguments: dataframe df can be either of healthy subject belonging to non_outliers.csv or AD subjects belonging to outlier.csv\n",
        "\n",
        "  Returns: 2 lists : sub,scans\n",
        "\n",
        "  For eg: \n",
        "  sub = ['OAS30756','OAS30756','OAS30020', 'OAS30535']\n",
        "  scans=['OAS30756_MR_d0014', 'OAS30756_MR_d0022','OAS30020_MR_d0092','OAS30535_MR_d0139']\n",
        "\n",
        "  (Note: length of sub and scans will be same : there can be multiple entries for same subject in sub this indicates there are multiple scans for this subject\n",
        "  As we can see here 'OAS30756' is occuring twice in the list : sub, because there are two scans i.e. 'OAS30756_MR_d0014', 'OAS30756_MR_d0022' associated to  'OAS30756' )\n",
        "  '''\n",
        "  sub =  df['patient_id'].values.tolist()\n",
        "  scans= copy.deepcopy(sub)\n",
        "  for i,s in enumerate(sub) :\n",
        "    if s.startswith('OAS1'):\n",
        "      s= s[:9]                  #OAS1_0123_MR1 take first 9 characters\n",
        "      sub[i] = s.replace('_','')\n",
        "    elif s.startswith('OAS3'):  #OAS31098_MR_d7178 #take just subject id\n",
        "      sub[i] = s.split('_')[0]\n",
        "  \n",
        "  print(f'subjects={sub}') \n",
        "  print(f'scans={scans}')\n",
        "  return sub,scans"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbTQb78-OzWo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Main Cell to run and generate the Visualization maps\n",
        "\n",
        "print(tf.__version__)\n",
        "\n",
        "\n",
        "\n",
        "tf_model = model\n",
        "\n",
        "\n",
        "dt_string = datetime.now().strftime('%d-%m-%Y-%H-%M')+'_smoe_maps_blockend_scale_endlayers_equal_weights'\n",
        "\n",
        "# dt_string = '15-09-2020-18-13_smoe_maps_blockend_scale_endlayers_equal_weights'\n",
        "\n",
        "label_path= cf['Paths']['labels']\n",
        "data_path= cf['Paths']['test_tfrecord']\n",
        "\n",
        "\n",
        "exp_prefix='exp_ba'\n",
        "base_path_prefix = '/content/drive/My Drive/BA_Estimation'\n",
        "\n",
        "### select case\n",
        "# case='healthy'\n",
        "case = 'outliers' \n",
        "\n",
        "if case == 'healthy':\n",
        "  #healthy subjects\n",
        "  healthy_path = base_path_prefix+'/models/{0}/non_outliers.csv'.format(exp_prefix)\n",
        "  df = pd.read_csv(healthy_path)\n",
        "  exp='exp_ba_healthy'\n",
        "else:\n",
        "  #Outlier Subjects\n",
        "  ad_path = base_path_prefix+'/models/{0}/outlier.csv'.format(exp_prefix)\n",
        "  df = pd.read_csv(ad_path)\n",
        "  exp='exp_ba_outliers'\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Either Manually specify  Subjects if we need specific subjects\n",
        "# sub= ['OAS30189','OAS30194','OAS30387','OAS30543','OAS30658','OAS31002','OAS31076','OAS30294','OAS30369','OAS30665','OAS30622','OAS30971',\\\n",
        "#                      'OAS31024','OAS30091','OAS30190','OAS30440','OAS30773','OAS30548']\n",
        "\n",
        "\n",
        "# test_patients,scan_ids, test_labels,test_gender,test_cdr = get_test_files(label_path,data_path,debug_mode_subject=sub,selected_scans=[])\n",
        "\n",
        "## Or read through subjects and scans from no_outliers.csv or outliers.csv and use these subjects and its corresponding scans\n",
        "\n",
        "sub,scans= get_subject_scan_names_from_filtered_data(df)\n",
        "\n",
        "test_patients,scan_ids, test_labels,test_gender,test_cdr = get_test_files(label_path,data_path,\\\n",
        "                                                                          debug_mode_subject=sub,selected_scans=scans) #incase we want to do on smaller subsets we can pass sub[:50],scans[:50]\n",
        "\n",
        "tfr=tf.data.TFRecordDataset(test_patients)\n",
        "img_tf=tfr.map(map_func=lambda a:parse_function_image(a))\n",
        "\n",
        "gender_dict={0:'Female',1:'Male'}\n",
        "counter =0\n",
        "\n",
        "for i,im in enumerate(img_tf): \n",
        "    #get tf records\n",
        "    \n",
        "    print(type(im),im.shape)\n",
        "    # if test_cdr[i] !=1 : #if block to only include healthy subjects from testset for visualizations\n",
        "    #   continue \n",
        "    \n",
        "    counter+=1\n",
        "    img=im.numpy()\n",
        "    print(img.shape)\n",
        "  \n",
        "    max_intensity=0\n",
        "    csmap_list=[]\n",
        "    \n",
        "    for chunk_id in [6,7,9,10,11,12]: #specify chunk id between  1 to 20 #range(1,21):\n",
        "\n",
        "      start = (chunk_id-1)*6\n",
        "      end = chunk_id*6\n",
        "      \n",
        "      img_chunk=torch.tensor(img[:,:,start:end])\n",
        "      img_chunk = img_chunk.unsqueeze(0)\n",
        "      input_tensor = img_chunk.unsqueeze(0)\n",
        "\n",
        "      in_height   = input_tensor.size()[2]\n",
        "      in_width    = input_tensor.size()[3]\n",
        "      print(test_gender[i],input_tensor.shape,scan_ids[i])\n",
        "     \n",
        "      n=66 # last conv layer  for gcam/++\n",
        "      layer_name='activation_'+str(n)\n",
        "      conv_path ='conv1_'+str(n)\n",
        "      \n",
        "      cdr_val = str(test_cdr[i])\n",
        "\n",
        "\n",
        "      #axial\n",
        "\n",
        "      base_dir= base_path_prefix+'/results/sal_map_axial/'+dt_string\\\n",
        "      +'_'+exp+'/'+scan_ids[i]+'_cdr'+str(test_cdr[i])\n",
        "      path = base_dir+'/'+str(chunk_id)+'_'+conv_path+'/'\n",
        "      print(path)\n",
        "      if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "      \n",
        "      base_path  = path+scan_ids[i]+'_chunk_'+str(chunk_id)\n",
        "      result_path = base_path_prefix+'/final_results/{0}/'.format(case)+\\\n",
        "      dt_string+'/cdr'+cdr_val+ '/axial/'+str(chunk_id)+'/'\n",
        "\n",
        "      if not os.path.exists(result_path):\n",
        "        os.makedirs(result_path)\n",
        "      \n",
        "      csmap_a=compute_saliency_tf(base_path,inputs=[img[:,:,start:end],test_gender[i]],tf_model=tf_model)\n",
        "      image,gcam_img,gcam_pp_img,pred = compute_gcam_and_gcam_pp(layer_name,tf_model,[img[:,:,start:end],test_gender[i]])\n",
        "      result_path += scan_ids[i]+'_'+ str(pred.numpy()[0])\n",
        "      combine_sal_gcam(path+scan_ids[i]+'_cdr'+str(test_cdr[i])+'_'+gender_dict[test_gender[i]],csmap_a,gcam_img,gcam_pp_img,image,layer_name=layer_name,angle=-270,result_path=result_path ) \n",
        "      \n",
        "      \n",
        "\n",
        "      #sagittal\n",
        "\n",
        "      base_dir= base_path_prefix+'/results/sal_map_sagittal/'+dt_string\\\n",
        "      +'_'+exp+'/'+scan_ids[i]+'_cdr'+str(test_cdr[i])\n",
        "      path = base_dir+'/'+str(chunk_id)+'_'+conv_path+'/'\n",
        "      print(path)\n",
        "      \n",
        "      if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "      base_path  = path+scan_ids[i]+'_chunk_'+str(chunk_id)\n",
        "      img_s= torch.from_numpy(img[start:end,:,:]).permute(2,1,0)\n",
        "      result_path = base_path_prefix+'/final_results/{0}/'.format(case)+dt_string +'/cdr'+cdr_val+'/sagittal/'+str(chunk_id)+'/'\n",
        "      if not os.path.exists(result_path):\n",
        "        os.makedirs(result_path)\n",
        "      \n",
        "      csmap_s=compute_saliency_tf(base_path,inputs=[img_s.numpy(),test_gender[i]],tf_model=tf_model)\n",
        "      image,gcam_img,gcam_pp_img,pred = compute_gcam_and_gcam_pp(layer_name,tf_model,[img_s.numpy(),test_gender[i]])\n",
        "      result_path += scan_ids[i]+'_'+str(pred.numpy()[0])\n",
        "      combine_sal_gcam(path+scan_ids[i]+'_cdr'+str(test_cdr[i])+'_'+gender_dict[test_gender[i]],csmap_s,gcam_img,gcam_pp_img,image,layer_name=layer_name,angle=180,result_path=result_path ) \n",
        "\n",
        "\n",
        "\n",
        "      #coronal\n",
        "\n",
        "      base_dir= base_path_prefix+'/results/sal_map_coronal/'+dt_string\\\n",
        "      +'_'+exp+'/'+scan_ids[i]+'_cdr'+str(test_cdr[i])\n",
        "      # path = base_dir+'/'+str(chunk_id)+'_old_'+conv_path+'/'\n",
        "      result_path = base_path_prefix+'/final_results/{0}/'.format(case)+dt_string+'/cdr'+cdr_val+'/coronal/'+str(chunk_id)+'/'\n",
        "      path = base_dir+'/'+str(chunk_id)+'_'+conv_path+'/'\n",
        "      print(path)\n",
        "      if not os.path.exists(result_path):\n",
        "        os.makedirs(result_path)\n",
        "      \n",
        "      if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "      base_path  = path+scan_ids[i]+'_chunk_'+str(chunk_id)\n",
        "      img_c= torch.from_numpy(img[:,start:end,:]).permute(2,0,1)\n",
        "      img_c=img_c.unsqueeze(0)\n",
        "      img_c = torch.nn.functional.upsample(img_c.unsqueeze(0), size=(121,145,6), mode='nearest') #interpolation required for coronal otherwise we will get 121,121,6 instead of 121,145,6\n",
        "      csmap_c=compute_saliency_tf(base_path,inputs=[img_c.numpy(),test_gender[i]],tf_model=tf_model)\n",
        "      image,gcam_img,gcam_pp_img,pred = compute_gcam_and_gcam_pp(layer_name,tf_model,[img_c.numpy(),test_gender[i]])\n",
        "      result_path += scan_ids[i]+'_'+str(pred.numpy()[0])\n",
        "      combine_sal_gcam(path+scan_ids[i]+'_cdr'+str(test_cdr[i])+'_'+gender_dict[test_gender[i]],csmap_c,gcam_img,gcam_pp_img,image,layer_name=layer_name,angle=180,result_path=result_path ) \n",
        "\n",
        "\n",
        "    print(f'scan count={counter}')\n",
        "\n",
        "     \n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZpZTNiPCKKx",
        "colab_type": "text"
      },
      "source": [
        "# **End of code notebook (the following cells below are only for experimental trying outs.)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNWUvS6W1Idc",
        "colab_type": "text"
      },
      "source": [
        "## **Visualizing mean testset on BA models.**\n",
        "### The mean was computed on the test set at each cdr value for male and female separately and then visualized ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhbPSHIM0O6n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "mat_path = '/content/drive/My Drive/BA_Estimation/means/exp_ba/full/'\n",
        "files = os.listdir(mat_path)\n",
        "\n",
        "# dt_string = datetime.now().strftime('%d-%m-%Y-%H-%M')+'_smoe_maps_blockend_scale_endlayers_equal_weights'\n",
        "\n",
        "label_path= cf['Paths']['labels'] \n",
        "data_path= cf['Paths']['test_tfrecord'] \n",
        "# exp='exp_siam_ad'\n",
        "exp='exp_ba_means'\n",
        "tf_model = model\n",
        "\n",
        "gender_dict={0:'Female',1:'Male'}\n",
        "reverse_gender_dict = {'Female':0,'Male':0}\n",
        "for i,f in enumerate(files): #OAS30686_d0030\n",
        "  # print(type(f),im.shape)\n",
        "  \n",
        "  test_gender = f.split('_')[-1].split('.')[0]\n",
        "  gender_tensor= np.array(reverse_gender_dict[test_gender])\n",
        "  test_cdr = f.split('_')[-2][-3:]\n",
        "  img=loadmat(mat_path+f)['data']\n",
        "  print(img.shape)\n",
        "  csmap_list=[]\n",
        "\n",
        "  for chunk_id in [6,7]:#range(1,21): #select chunks from 1,21 (significant ones are from chunk 6-11)\n",
        "\n",
        "    start = 6*(chunk_id-1)\n",
        "    end = start+6\n",
        "    # img = loadmat(f)['data']\n",
        "\n",
        "    img_chunk=torch.tensor(img[:,:,start:end]).unsqueeze(0)\n",
        "    img_chunk = img_chunk.unsqueeze(-1)\n",
        "    \n",
        "    print(f'input shape={img_chunk.shape}')\n",
        "   \n",
        "    input_tensor = img_chunk\n",
        "\n",
        "    in_height   = input_tensor.size()[1]\n",
        "    in_width    = input_tensor.size()[2]\n",
        "    print(test_gender,input_tensor.shape,f)\n",
        "\n",
        "    a=51\n",
        "    n=35\n",
        "\n",
        "    layer_name='activation_'+str(a)\n",
        "\n",
        "    conv_path ='conv1_'+str(n)\n",
        "\n",
        "\n",
        "    #axial\n",
        "    base_dir= '/content/drive/My Drive/BA_Estimation/means/'+dt_string+ '/sal_map_axial/' \\\n",
        "    +exp+'/'+f+'_cdr'+str(test_cdr)\n",
        "    path = base_dir+'/'+str(chunk_id)+'_'+conv_path+'/'\n",
        "    print(path)\n",
        "    if not os.path.exists(path):\n",
        "      os.makedirs(path)\n",
        "    base_path  = path+f+'_chunk_'+str(chunk_id)\n",
        "    csmap_a=compute_saliency_tf(base_path,inputs=[input_tensor,gender_tensor],tf_model=tf_model)\n",
        "    image,gcam_img,gcam_pp_img = compute_gcam_and_gcam_pp(layer_name,tf_model,[input_tensor,gender_tensor])\n",
        "    combine_sal_gcam(path+f+'_cdr'+str(test_cdr)+'_'+test_gender,csmap_a,gcam_img,gcam_pp_img,image,layer_name=layer_name ) \n",
        "\n",
        "\n",
        "    #sagittal\n",
        "    base_dir= '/content/drive/My Drive/BA_Estimation/means/'+dt_string+'/sal_map_sagittal/' \\\n",
        "    +exp+'/'+f+'_cdr'+str(test_cdr)\n",
        "    path = base_dir+'/'+str(chunk_id)+'_'+conv_path+'/'\n",
        "    print(path)\n",
        "    if not os.path.exists(path):\n",
        "      os.makedirs(path)\n",
        "    base_path  = path+f+'_chunk_'+str(chunk_id)\n",
        "    img_s= torch.from_numpy(img[start:end,:,:]).permute(2,1,0)\n",
        "    csmap_s=compute_saliency_tf(base_path,inputs=[img_s,gender_tensor],tf_model=tf_model)\n",
        "    image,gcam_img,gcam_pp_img = compute_gcam_and_gcam_pp(layer_name,tf_model,[img_s,gender_tensor])\n",
        "    combine_sal_gcam(path+f+'_cdr'+str(test_cdr)+'_'+test_gender,csmap_s,gcam_img,gcam_pp_img,image,layer_name=layer_name ) \n",
        "\n",
        "\n",
        "    #coronal\n",
        "    base_dir= '/content/drive/My Drive/BA_Estimation/means/'+dt_string + '/sal_map_coronal/' \\\n",
        "    +exp+'/'+f+'_cdr'+str(test_cdr)\n",
        "    path = base_dir+'/'+str(chunk_id)+'_old_'+conv_path+'/'\n",
        "    print(path)\n",
        "    if not os.path.exists(path):\n",
        "      os.makedirs(path)\n",
        "    base_path  = path+f+'_chunk_'+str(chunk_id)\n",
        "    # img_c= torch.from_numpy(img[:,58:64,:]).permute(2,0,1)\n",
        "    img_c= torch.from_numpy(img[:,start:end,:]).permute(2,0,1)\n",
        "    img_c=img_c.unsqueeze(0)\n",
        "    img_c = torch.nn.functional.upsample(img_c.unsqueeze(0), size=(121,145,6), mode='nearest') \n",
        "    csmap_c=compute_saliency_tf(base_path,inputs=[img_c,gender_tensor],tf_model=tf_model)\n",
        "    image,gcam_img,gcam_pp_img = compute_gcam_and_gcam_pp(layer_name,tf_model,[img_c,gender_tensor])\n",
        "    combine_sal_gcam(path+f+'_cdr'+str(test_cdr)+'_'+test_gender,csmap_c,gcam_img,gcam_pp_img,image,layer_name=layer_name ) \n",
        "\n",
        "    #coronal\n",
        "    base_dir= '/content/drive/My Drive/BA_Estimation/means/'+dt_string + '/sal_map_coronal/' \\\n",
        "    +exp+'/'+f+'_cdr'+str(test_cdr)\n",
        "    path = base_dir+'/'+str(chunk_id)+'_new_'+conv_path+'/'\n",
        "    print(path)\n",
        "    if not os.path.exists(path):\n",
        "      os.makedirs(path)\n",
        "    base_path  = path+f+'_chunk_'+str(chunk_id)\n",
        "    # img_c= torch.from_numpy(img[:,58:64,:]).permute(2,0,1)\n",
        "    img_c= torch.from_numpy(img[:,end:end+6,:]).permute(2,0,1)\n",
        "    img_c=img_c.unsqueeze(0)\n",
        "    img_c = torch.nn.functional.upsample(img_c.unsqueeze(0), size=(121,145,6), mode='nearest') \n",
        "    csmap_c=compute_saliency_tf(base_path,inputs=[img_c,gender_tensor],tf_model=tf_model)\n",
        "    image,gcam_img,gcam_pp_img = compute_gcam_and_gcam_pp(layer_name,tf_model,[img_c,gender_tensor])\n",
        "    combine_sal_gcam(path+f+'_cdr'+str(test_cdr)+'_'+test_gender,csmap_c,gcam_img,gcam_pp_img,image,layer_name=layer_name ) \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZxWbcYNTsch",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5a7f78db-5018-432c-b8c8-e1bba527bd05"
      },
      "source": [
        "img=loadmat('/content/drive/My Drive/BA_Estimation/results/sal_map_axial/25-08-2020-11-36_smoe_maps_blockend_scale_endlayers_equal_weights_exp_ba/OAS30190_MR_d0082_cdr1.0/9_conv1_66/OAS30190_MR_d0082_cdr1.0_Female_activation_66masked_gcam_pp.mat')\n",
        "\n",
        "img['data'].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(121, 145)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aT_etON1AJoQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image=img['data']\n",
        "image[np.where(image<0.3*np.max(image))]=0\n",
        "im=plt.imshow(image,cmap='jet')\n",
        "plt.colorbar(im)\n",
        "plt.clim(0.6,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLyoVEbgJ2EX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image=img['data']\n",
        "image[np.where(image<0.3*np.max(image))]=0\n",
        "im=plt.imshow(image,cmap='jet')\n",
        "plt.colorbar(im)\n",
        "plt.clim(0.6,0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mobp01JvLzyO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "71d7fa43-f575-43b1-f87c-11a359d035eb"
      },
      "source": [
        "import nibabel\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# nii_img=nibabel.load('/content/sub-OAS30440_ses-d0163_T1w.nii').get_fdata() /content/OAS30070_MR_d0070.tfrecord\n",
        "# nii_img=nibabel.load('/content/sub-OAS30070_ses-d0070_T1w.nii').get_fdata() /content/smwc1sub-OAS30282_ses-d0040_T1w.nii\n",
        "# nii_img=nibabel.load('/content/smwc1sub-OAS30282_ses-d0040_T1w.nii').get_fdata() /content/sub-OAS31035_ses-d5659_run-02_T1w.nii\n",
        "# nii_img=nibabel.load('/content/sub-OAS31035_ses-d5659_run-02_T1w.nii').get_fdata() /content/sub-OAS30310_ses-d0191_T1w.nii\n",
        "# nii_img=nibabel.load('/content/sub-OAS31002_ses-d4948_run-02_T1w.nii').get_fdata()\n",
        "# nii_img=nibabel.load('/content/sub-OAS30102_ses-d0024_T1w.nii').get_fdata()\n",
        "# nii_img=nibabel.load('/content/sub-OAS30383_ses-d0134_run-02_T1w.nii').get_fdata()\n",
        "# \n",
        "# nii_img.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(176, 256, 256)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ehw1ci9DMGZm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "# plt.imshow(nii_img[79,:,:],cmap='gray')\n",
        "# plt.imshow(nii_img[70,:,:],cmap='gray') #79\n",
        "# plt.imshow(nii_img[88,:,:],cmap='gray')\n",
        "# plt.imshow(nii_img[79,:,:],cmap='gray')\n",
        "# plt.imshow(nii_img[67,:,:],cmap='gray')\n",
        "# plt.imshow(nii_img[67,:,:],cmap='gray')\n",
        "# plt.imshow(np.mean(nii_img[70:79,:,:],axis=0),cmap='gray')\n",
        "\n",
        "\n",
        "# plt.imshow(np.mean(nii_img[80:86,:,:],axis=0),cmap='gray')\n",
        "# plt.axis('off')\n",
        "# plt.savefig('sagittal.png')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpacuWx3O7Xs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plt.imshow(nii_img[:,101,:],cmap='gray')\n",
        "plt.imshow(np.mean(nii_img[:,85:91,:],axis=1),cmap='gray')\n",
        "# plt.imshow(nii_img[:,90,:],cmap='gray') #96\n",
        "# plt.imshow(nii_img[:,103,:],cmap='gray')\n",
        "# plt.imshow(np.mean(nii_img[:,103:110,:],axis=1),cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.savefig('coronal.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFMH0X9PPB_F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plt.imshow(nii_img[:,:,101],cmap='gray')\n",
        "# plt.imshow(np.mean(nii_img[:,:,103:110],axis=-1),cmap='gray')\n",
        "plt.imshow(np.mean(nii_img[:,:,116:122],axis=-1),cmap='gray')\n",
        "# plt.imshow(nii_img[:,:,102],cmap='gray') #115\n",
        "# plt.imshow(nii_img[:,:,90],cmap='gray') \n",
        "# plt.imshow(nii_img[:,:,96],cmap='gray')\n",
        "# plt.imshow(nii_img[:,:,103:110],cmap='gray') #102, 108,112,110\n",
        "plt.axis('off')\n",
        "plt.savefig('axial.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-dzL0Br4VMi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nii_img2= nibabel.load('/content/smwc1sub-OAS31002_ses-d4948_run-02_T1w.nii').get_fdata()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0orKlcE84rT9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plt.imshow(nii_img2[54,:,:],cmap='gray') \n",
        "# plt.imshow(nii_img2[36,:,:],cmap='gray') \n",
        "plt.imshow(np.mean(nii_img2[30:36,:,:],axis=0),cmap='gray') \n",
        "# plt.imshow(np.mean(nii_img[70:79,:,:],axis=0),cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.savefig('sagittal_preprocessed.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUAnC5I95BQo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plt.imshow(nii_img2[:,54,:],cmap='gray')\n",
        "plt.imshow(np.mean(nii_img2[:,42:48,:],axis=1),cmap='gray') \n",
        "plt.axis('off')\n",
        "plt.savefig('coronal_preprocessed.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTmYf9FS5XLn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plt.imshow(nii_img2[:,:,36],cmap='gray') #54\n",
        "plt.imshow(np.mean(nii_img2[:,:,36:42],axis=-1),cmap='gray') \n",
        "# plt.imshow(nii_img2[:,:,36],cmap='gray')\n",
        "# plt.imshow(np.mean(nii_img2[:,:,36:42],axis=-1),cmap='gray')  \n",
        "plt.axis('off')\n",
        "plt.savefig('axial_preprocessed.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmRdaTe7AjYb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b6a339f0-5ee2-4d07-e73e-b3ee051bee52"
      },
      "source": [
        "np.max(img['data']),np.max(img['data']),np.min(img['data']),np.min(img['data'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.0, 1.0, 0.0, 0.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    }
  ]
}